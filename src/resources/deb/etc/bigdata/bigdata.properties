# The values from this file are stored in the journal file when the journal is created,
# thus it is hard to change the values, since that involves dumping the data from each
# affected bigdata installation and relaoding it.

# Some features of this file are hence intended as 'future proofing' and
# involve features that are not needed now. This is particularly to do with
# text indexing.

# changing the axiom model to none essentially disables all inference
com.bigdata.rdf.store.AbstractTripleStore.axiomsClass=com.bigdata.rdf.axioms.NoAxioms
com.bigdata.rdf.store.AbstractTripleStore.quads=true
com.bigdata.rdf.store.AbstractTripleStore.statementIdentifiers=false
com.bigdata.rdf.store.AbstractTripleStore.textIndex=true

# The configuration of text indexing:
com.bigdata.search.FullTextIndex.analyzerFactoryClass=com.bigdata.search.ConfigurableAnalyzerFactory

# By default we have no indexing of anything
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer._.analyzerClass=com.bigdata.search.EmptyAnalyzer
# Use a private extension tag for storing vocab data, using a complex indexing scheme
# A key regex we use is this one:
# (?<!^[^\s])(?<!\s[^\s])[\s]
# i.e. a negative look behind for the start of line followed by a not space character.
# and  a negative look behind for a space character followed by a space character
# and  a space character
# This allows us to treat words consisting of a single character such as "A" or "6"
# to join with the following word.

com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.wordBoundary=(?<!^[^\\s])(?<!\\s[^\\s])[\\s]

# The subWord regex expands as follows
#    a)      (?<!\p{L}|\p{N})(?=\p{L}|\p{N})
#
# or b)      (?<!\p{Lu})(?=\p{Lu})
#
# or c)      (?<=\p{N})(?=\p{L})
#
# or d)  

# Another regex used here is (?!) a negative look ahead for nothing - this is false in regex speak.

com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.subWordBoundary=(?<!\\p{L}|\\p{N})(?=\\p{L}|\\p{N})|(?<!\\p{Lu})(?=\\p{Lu})|(?<=\\p{N})(?=\\p{L})
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.softHyphens=[- ]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.alwaysRemoveSoftHyphens=false
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-keyword.analyzerClass=org.apache.lucene.analysis.KeywordAnalyzer
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query.pattern=(?<!^[^\\s])(?<!\\s[^\\s])[\\s]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.wordBoundary=(?<!^[^\\s])(?<!\\s[^\\s])[\\s]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.subWordBoundary=(?!)
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.softHyphens=[- ]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.alwaysRemoveSoftHyphens=true
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.wordBoundary=(?<!^[^\\s])(?<!\\s[^\\s])[\\s]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.subWordBoundary=(?!)

com.bigdata.rdf.sail.bufferCapacity=100000

# turn off automatic inference in the SAIL
com.bigdata.rdf.sail.truthMaintenance=false

com.bigdata.journal.AbstractJournal.bufferMode=DiskRW

com.bigdata.btree.writeRetentionQueue.capacity=4000
com.bigdata.btree.BTree.branchingFactor=512

com.bigdata.rdf.store.DataLoader.commit=Incremental

# Use Stickler's symmetric DESCRIBE (CBD) algorithm, for good integration with pubby
com.bigdata.rdf.sail.describeMode=SCBD
com.bigdata.rdf.sail.describeIterationLimit=10
com.bigdata.rdf.sail.describeIterationStatementLimit=1000
com.bigdata.journal.AbstractJournal.file=/var/lib/bigdata/bigdata.jnl
