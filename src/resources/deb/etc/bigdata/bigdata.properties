# The values from this file are stored in the journal file when the journal is created,
# thus it is hard to change the values, since that involves dumping the data from each
# affected bigdata installation and relaoding it.

# We include version information
com.syapse.bigdata.properties.version=1.0.0

# Some features of this file are hence intended as 'future proofing' and
# involve features that are not needed now. This is particularly to do with
# text indexing.

# changing the axiom model to none essentially disables all inference
com.bigdata.rdf.store.AbstractTripleStore.axiomsClass=com.bigdata.rdf.axioms.NoAxioms
com.bigdata.rdf.store.AbstractTripleStore.quads=true
com.bigdata.rdf.store.AbstractTripleStore.statementIdentifiers=false
com.bigdata.rdf.store.AbstractTripleStore.textIndex=true

# The configuration of text indexing:
com.bigdata.search.FullTextIndex.analyzerFactoryClass=com.bigdata.search.ConfigurableAnalyzerFactory

# By default we have no indexing of anything
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer._.analyzerClass=com.bigdata.search.EmptyAnalyzer
# Use a private extension tag 'x-term' for storing vocab data, using a complex indexing scheme

# We make extensive use of regex's.
# We wish to ensure maximal interoperability between python regex's and Java's.
# This allows the python code to know how a particular search term is being
# split up to access bigdata's rich text indexes.
# We use Unicode versions in both languages, using the regex package instead of re
# and enabling unicode support for regex's in both languages.
# Moreover, we specify groups of characters using the \p{Zs} etc type name
# Where the category is specified at:
#    http://unicode.org/reports/tr18/#General_Category_Property
# this is a nice crib sheet:
#    http://www.fileformat.info/info/unicode/category/index.htm


# A key regex we use is this one:
# (?<!^[^\p{Zs}])(?<!\p{Zs}[^\p{Zs}])\p{Zs}
#
# i.e. a negative look behind for the start of line followed by a not space character.
# and  a negative look behind for a space character followed by a not space character
# and  a space character
# This allows us to treat words consisting of a single character such as "A" or "6"
# as connected with the following word, and we avoid problems to do with single character
# words.

com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}

# The subWord regex is looking inside words.
# A word may start with a single character followed by a space, because of our peculiar treatment of the
# word boundary.
# We are looking for places in the word where we might wish to start matching the user input.
# For example:
# a) after a ' ' or a '-'
# b) After an opening paren [({<
# c) Before an opening paren [({<
# d) Where camelCase kicks in - before the C in camelCase
# e) Where we have a non-letter-or-number followed by a letter-or-number
#    i.e. after a non-letter-or-number, before a letter-or-number
# f) Where we have a number followed by a letter
#    i.e. after a number, before a letter
# Translating this into regex is as follows - noting that normally 'after' translates to
# a look-behind, and 'before' translates into look-ahead.



# a)  after a ' ' or a '-'
#   [\\p{Zs}\\p{Pd}]
#       Note: Zs is Separator, Space
#        and  Pd is Punctuation, Dash
# b)  After an opening paren [({<
#   (?<=\\p{Ps})
#       Note: Ps is Punctuation, Open
# c)  Before an opening paren [({<
#   (?=\\p{Ps})
#       Note: (a) consumes the character whereas (b) and (c) are zero width
#       matches. If (b) were not zero width, then (c) could never match
#       because in all cases where (c) would match so would (b)
#       and then the longest match wins rule would apply.
# d)  Where camelCase kicks in - before the C in camelCase
#   (?<=\\p{Ll})(?=\\p{Lu})
#        A zero-width lookbehind for Ll Lowercase Letter
#        A zero-width lookahead for Lu  Uppercase Letter
# e)  Where we have a non-letter-or-number followed by a letter-or-number
#     i.e. after a non-letter-or-number, before a letter-or-number
#   (?<!\\p{L}|\\p{N})(?=\\p{L}|\\p{N})
#        (?<! is the negative look behind for a \\p{L} Letter | or a \\p{N} number
# f)  Where we have a number followed by a letter
#     i.e. after a number, before a letter
#   (?<=\\p{N})(?=\\p{L})

# Putting that together we get:
# [- ]|(?<=\\p{Ps})|(?=\\p{Ps})|(?<=\\p{Ll})(?=\\p{Lu})|(?<!\\p{L}|\\p{N})(?=\\p{L}|\\p{N})|(?<=\\p{N})(?=\\p{L})
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.subWordBoundary=[\\p{Zs}\\p{Pd}]|(?<=\\p{Ps})|(?=\\p{Ps})|(?<=\\p{Ll})(?=\\p{Lu})|(?<!\\p{L}|\\p{N})(?=\\p{L}|\\p{N})|(?<=\\p{N})(?=\\p{L})

# We also will create indexes for terms removing any dashes or spaces from them
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.softHyphens=[\\p{Zs}\\p{Pd}]
# We use indexes both with and without the dashes
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-term.alwaysRemoveSoftHyphens=false

# We define further private use language tags
# x-keyword, x-query1, x-query2, x-query3, x-query4
# None of these are intended for data being added to the triple store
# They are all intended for the queries being used with bds:search to access the free
# text indexes.
# We are trying to split the query term into fewer items that will be used to access
# relevant indexes. In particular we do not need to create shorter search terms,
# since any match for the longer search term will necessarily be a match for short search terms
# and we take the intersection of the sets of matches.

# x-keyword is very simple: this is the exact term entered: find it's index and use that one
# This may be useful in debugging to see if an index was even created for a particular term.
# Also see the bigdata-log4j.properties file, which has a commented out
# line to enable tracing of the x-term splitting up of a word
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-keyword.analyzerClass=org.apache.lucene.analysis.KeywordAnalyzer

# x-query1 uses the word boundary from x-term to split the input up into words
# and uses those words to find the indexes.
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query1.pattern=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}

# x-query2 is like x-query1 but removes the soft hyphens (spaces and dashes)
#    Note:  (?!) is unicode for do not match (negative lookahead for the empty string).
#           We use this to avoid subword analysis
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.subWordBoundary=(?!)
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.softHyphens=[\\p{Zs}\\p{Pd}]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query2.alwaysRemoveSoftHyphens=true


# x-query3 keeps both the longer form of the index terms with the soft-hyphens, and the shorter form
#    with the soft-hyphens removed.
#    This may be useful for an OR (union) match rather than an AND (intersection) match
#    See bds:matchAllTerms false.
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.subWordBoundary=(?!)
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.softHyphens=[\\p{Zs}\\p{Pd}]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query3.alwaysRemoveSoftHyphens=false

# x-query4 is intended to be identical to x-query1 but uses a different implementation,
# and so may work better or worse.
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query4.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query4.subWordBoundary=(?!)

# x-query 5, 6, 7 are the same as x-query 2, 3, 4, but with subWordBoundary left undefined.
# This is merely a safeguard given the difficulty of changing this file.
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query5.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query5.softHyphens=[\\p{Zs}\\p{Pd}]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query5.alwaysRemoveSoftHyphens=true
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query6.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query6.softHyphens=[\\p{Zs}\\p{Pd}]
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query6.alwaysRemoveSoftHyphens=false
com.bigdata.search.ConfigurableAnalyzerFactory.analyzer.x-query7.wordBoundary=(?<!^[^\\p{Zs}])(?<!\\p{Zs}[^\\p{Zs}])\\p{Zs}


com.bigdata.rdf.sail.bufferCapacity=100000

# turn off automatic inference in the SAIL
com.bigdata.rdf.sail.truthMaintenance=false

com.bigdata.journal.AbstractJournal.bufferMode=DiskRW

com.bigdata.btree.writeRetentionQueue.capacity=4000
com.bigdata.btree.BTree.branchingFactor=512

com.bigdata.rdf.store.DataLoader.commit=Incremental

# Use Stickler's symmetric DESCRIBE (CBD) algorithm, for good integration with pubby
com.bigdata.rdf.sail.describeMode=SCBD
com.bigdata.rdf.sail.describeIterationLimit=10
com.bigdata.rdf.sail.describeIterationStatementLimit=1000
com.bigdata.journal.AbstractJournal.file=/var/lib/bigdata/bigdata.jnl
