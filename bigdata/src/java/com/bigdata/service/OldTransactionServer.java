/**

Copyright (C) SYSTAP, LLC 2006-2007.  All rights reserved.

Contact:
     SYSTAP, LLC
     4501 Tower Road
     Greensboro, NC 27410
     licenses@bigdata.com

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/
/*
 * Created on Nov 1, 2006
 */

package com.bigdata.service;

import java.util.BitSet;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

import com.bigdata.journal.ITx;
import com.bigdata.journal.IsolationEnum;
import com.bigdata.journal.Journal;
import com.bigdata.journal.Options;
import com.bigdata.util.MillisecondTimestampFactory;

/**
 * @deprecated The transaction server is responsible for starting, preparing, and committing
 * transactions, for assignig unique start and commit timestamps to
 * transactions, for determining when a transaction is "dead" (through
 * inactivity), and for coordinating a restart-safe process for releasing
 * resources no longer accessible to any active transaction. The transaction
 * server may either be integrated into an embedded database or run as a
 * replicated service for a distributed database. The transaction start time
 * serves a unique transaction identifier. Unique timestamps are generated by a
 * centralized service with nanosecond precision, which is typically co-located
 * with the {@link OldTransactionServer}.
 * 
 * @todo Define an API for the transaction server. Implement an embedded version
 *       of the server for a single segment and write its test suite. Implement
 *       an embedded version server for multiple segments (handles 2/3 phase
 *       commit protocol on a single host) and write its test suite. Implement a
 *       robust, discoverable, replicated version of the service handling
 *       multiple segments and devise a test strategy. Characterize performance
 *       curves in terms of latency and maximum concurrency.
 * 
 * @todo A centralized transaction service will create a concurrency bottleneck.
 *       There must be 2-3 RPCs to the transaction server per transaction (start ->
 *       prepare | abort -> commit), plus a heartbeat. Some RPC can be bundle a
 *       heartbeat (or visa versa) to minimize traffic. The #of concurrent
 *       client connections to the server will be a limiting factor unless we
 *       use UDP (vs TCP) for the transaction server RPC protocol. The
 *       bottleneck will probably be upwards of 1000s of concurrent
 *       transactions. One limiting factor will be the latency of the commit.
 *       This can be reduced by replicating the journal onto multiple hosts so
 *       that we do not need to synchronize to disk during a commit. I would
 *       expect that 10k concurrent transactions could be the limit, and should
 *       certainly be an internal target. Achieving higher concurrency will
 *       require more localized mechanisms, e.g., single row atomic updates.
 *       There is also a use case for read committed transactions in order to
 *       permit earlier GC with very very long running transactions, which would
 *       otherwise defer GC until their completion.
 * 
 * @todo Concurrent transactions define a dependency graph of (a) transactions
 *       that have written on the committed state of another transaction; and
 *       (b) transaction that can read from the committed state of another
 *       transaction. We can GC transactions that statisfy (a) once tranactions
 *       that satisify (b) have all completed (either aborted or committed).
 *       This information can be further refined by the segments resources that
 *       a transaction has read or written on. Maintaining that dependency
 *       information in a restart safe manner (e.g., by a replicated service)
 *       will have its own cost.
 * 
 * @todo Support readCommitted isolation. A readCommitted transaction performs
 *       reads against the current committed state of the journal and does not
 *       block GC (writes are still buffered by an isolated object index). This
 *       has the consequence that changes committed by concurrent transactions
 *       will be visible and reduces resources otherwise consumed by historical
 *       versions preserved until GC. A readOnly + readCommitted transaction
 *       does not impose a resource burden since it only reads from the current
 *       committed state of the segment and never writes.
 * 
 * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
 * @version $Id$
 */
public class OldTransactionServer {

    /**
     * The service used to generate commit timestamps.
     * 
     * @todo paramterize using {@link Options} so that we can resolve a
     *       low-latency service for use with a distributed database commit
     *       protocol.
     */
    protected final MillisecondTimestampFactory timestampFactory = new MillisecondTimestampFactory();

    /**
     * Class modeling transaction metadata. An instance of this class is used to
     * model a transaction in the {@link OldTransactionServer}. {@link ITx}
     * objects are used to model the transaction local to a {@link Journal}.
     * 
     * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
     * @version $Id$
     */
    static class TxMetadata {

        /**
         * The transaction timestamp.
         */
        final long ts;
        /**
         * True iff the transaction is read-only.
         */
        final boolean readOnly;
        /**
         * True iff the transaction permits reads of updates committed by
         * concurrent transactions.
         */
        final boolean readCommitted;
        /**
         * The timestamp (ms) of the last heartbeat received for the
         * transaction. Timestamps are generated by the clock on which the
         * transaction server is running.
         * 
         * @todo Periodically scan all transactions and abort those that have
         *       not received a heartbeat "recently".
         */
        long heartbeat;
//        /**
//         * The transaction run state (initially active).
//         */
//        RunState runState;
        /**
         * A bit is set for each segment opened by the transaction.
         */
        BitSet openSegments;
        /**
         * A set of active transactions for which this transaction serves as the
         * ground state. This collection is undefined until this transaction
         * commits. Once this transaction commits, any new transactions that
         * start before the next transaction commits will use this transaction
         * as their ground state. Those transactions will be tracked in this
         * collection while they are active. Any transaction that uses this
         * transaction as its ground state and successfully commits will be
         * moved from {@link #active} to {@link #committed}. Once there are no
         * more {@link #active} transactions using this transaction as their
         * ground state, any {@link #committed} transactions for this ground
         * state may be GCd.
         * 
         * @todo Add constraint on [active] that new entries are not permitted
         *       once [committed] is non-empty.
         * 
         * @todo Add constraint on [active] that entries are not permitted until
         *       this transaction is [committed].
         */
        Map<Long,TxMetadata> active = new ConcurrentHashMap<Long, TxMetadata>();
        /**
         * Transactions that emerge from the ground state of this transaction
         * and then commit are tracked here until they can be GCd. They are not
         * GCd until all active transactions that emerge from this ground state
         * have completed (aborted or committed). If this collection has at
         * least one entry, then we are guarenteed that no new transactions will
         * emerge from this ground state.
         */
        Map<Long,TxMetadata> committed = new ConcurrentHashMap<Long, TxMetadata>();
        
        public TxMetadata(long ts,IsolationEnum isolationLevel) {
            
            this.ts = ts;
            
            this.readOnly = isolationLevel == IsolationEnum.ReadOnly
                    || isolationLevel == IsolationEnum.ReadCommitted;

            this.readCommitted = isolationLevel == IsolationEnum.ReadCommitted;
            
//            runState = RunState.Active;
            
            heartbeat = System.nanoTime();
            
            openSegments = new BitSet();
        }
        
        public void openSegment(int segment) {
            
            openSegments.set(segment);
            
        }
        
    }
    
    /**
     * Map containing metadata for active transactions.
     */
    private Map<Long, TxMetadata> transactions = new ConcurrentHashMap<Long, TxMetadata>(
            1000);
    
    /**
     * <p>
     * Map containing metadata for committed transactions. The metadata for a
     * committed transaction is retained until all transactions emerging from
     * the ground state of that committed transaction have completed. We track
     * each active transaction for a given ground state and each transaction
     * that commits for a given ground state. When there are no more active
     * transactions for a given ground state, we GC all transactions that
     * committed for that ground state and remove the transaction metadata for
     * the ground state from this map.
     * </p>
     * <p>
     * Note: By "ground state" I mean a stable state that results on the journal
     * after a transaction commits and that serves as the baseline state for any
     * transactions starting after that commit point and before the next commit
     * point.
     * </p>
     */
    private Map<Long, TxMetadata> groundStates = new ConcurrentHashMap<Long, TxMetadata>();

    /**
     * The timestamp that will serve as the ground state for any new
     * transactions. The groundState is updated each time a transaction commits
     * to the commit time of that transaction. This field is initially 0L.
     * 
     * @todo Provide for bootstrapping this field. For a new database, the field
     *       might be ts0. When re-starting an entire database, the value of the
     *       field is the largest timestamp committed on any segment.
     * 
     * @todo Updates to this field MUST be atomic with respect to the creation
     *       of new transactions.
     */
    private long groundState = 0L;
    
    /**
     * 
     */
    public OldTransactionServer() {
    }

    /**
     * Start a new transaction.
     * 
     * @param isolationLevel
     *            The isolation level for the transaction.
     * 
     * @return The unique transaction start time assigned to the transaction.
     * 
     * @todo support clients that eagerly declare their intention in terms of
     *       {indexName,separatorKey} tuples.
     */
    public long startTx(IsolationEnum isolationLevel) {

        assert isolationLevel != null;
        
        /*
         * Wait for the next distinct millisecond.
         */
        long ts = timestampFactory.nextMillis();
        
        transactions.put(ts, new TxMetadata(ts,isolationLevel));
        
        return ts;
        
    }

    /**
     * Abort a transaction. Notice will be issued to all segments that have been
     * written or read by the transaction. The transaction identifier will be
     * invalidated.
     * 
     * @param ts
     *            The transaction identifier.
     */
    public void abortTx(long ts) {

        TxMetadata tx = transactions.remove(ts);
        
        if( tx == null ) {

            /*
             * @todo differentiate between transactions that were never started
             * and that have been completed by global knowledge of the ordering
             * of assigned timestamps.
             */
            
            throw new IllegalArgumentException("Unknown transaction: "+ts);
            
        }

        /*
         * Notify open segments of tx abort.
         * 
         * @todo Should send messages in parallel and gather responses.
         * 
         * @todo Return to the caller when all segments have been aborted or
         * immediately, letting the transaction server handle the cleanup?
         */
        BitSet openSegments = tx.openSegments;

        for( int i=0; i<openSegments.length(); ) {
            
            int ndx = openSegments.nextSetBit( i );
            
            if( ndx == -1 ) break;
            
            notifyAbort( ndx, ts );
            
            i = ndx;
            
        }
        
    }
    
    /**
     * Commit a transaction. When the transaction is distributed, this prepares
     * the transaction and then commits the transaction according to a
     * multi-phase commit protocol. Notice will be issued to all resources on
     * which the transaction has written. The transaction identifier will be
     * invalidated.
     * 
     * @param ts
     *            The transaction identifier.
     */
    public void commitTx(long ts) {
        
        TxMetadata tx = transactions.remove(ts);
        
        if( tx == null ) {

            /*
             * @todo differentiate between transactions that were never started
             * and that have been completed by global knowledge of the ordering
             * of assigned timestamps.
             */
            
            throw new IllegalArgumentException("Unknown transaction: "+ts);
            
        }

        /*
         * Notify open segments of tx prepare
         * 
         * @todo Should send messages in parallel and gather responses.
         */
        BitSet openSegments = tx.openSegments;

        for( int i=0; i<openSegments.length(); ) {
            
            int ndx = openSegments.nextSetBit( i );
            
            if( ndx == -1 ) break;
            
            notifyPrepare( ndx, ts );
            
            i = ndx;
            
        }
        
        /*
         * @todo Wait for all notified segments to respond.  If one or more
         * does not prepare successfully or it one or more does not respond
         * within a timeout, then abort the transaction.
         */
        
        /*
         * Notify open segments of tx commit.
         * 
         * @todo Should send messages in parallel and gather responses.
         */

        for( int i=0; i<openSegments.length(); ) {
            
            int ndx = openSegments.nextSetBit( i );
            
            if( ndx == -1 ) break;
            
            notifyCommit( ndx, ts );
            
            i = ndx;
            
        }
        
    }
    
    /**
     * Clients issue heartbeats to notify the transaction server that the
     * transaction is still running. A transaction that does not receive a
     * heartbeat within a required interval will be aborted.
     * 
     * @param ts
     *            The transaction identifier.
     */
    public void heartbeat(long ts) {
        
        TxMetadata tx = transactions.get(ts);
        
        if( tx == null ) {
            
            // @todo protocol error.
            
            throw new IllegalArgumentException("transaction: "+ts);
            
        }
        
        tx.heartbeat = System.currentTimeMillis();
        
    }
    
    /**
     * Notice by the client that it will open the segment. Since work may be
     * done on a transaction by multiple processes, we permit multiple "open"
     * requests for the same segment. Segments that are opened by a transaction
     * are tracked and will receive prepare, commit or abort messages for that
     * transaction. Note that there is no sense of "closing" a segment. The set
     * of segments opened by a transaction determines the segments that must
     * receive notices generated by transaction events.
     * 
     * @param ts
     *            The transaction identifier.
     * @param segment
     *            The segment identifier.
     */
    public void openSegment(long ts, int segment) {

        TxMetadata tx = transactions.get(ts);
        
        if( tx == null ) {
            
            // @todo protocol error.
            
            throw new IllegalArgumentException("transaction: "+ts);
            
        }
        
        tx.openSegment(segment);

    }

    /**
     * Send the segment notice that it must abort the transaction.
     * 
     * @param segment
     *            The segment identifier.
     * @param ts
     *            The transaction identifier.
     */
    protected void notifyAbort(int segment, long ts) {

    }

    /**
     * Send the segment notice that it must prepare the transaction.
     * 
     * @param segment
     *            The segment identifier.
     * @param ts
     *            The transaction identifier.
     */
    protected void notifyPrepare(int segment, long ts) {

    }

    /**
     * Send the segment notice that it must commit the transaction.
     * 
     * @param segment
     *            The segment identifier.
     * @param ts
     *            The transaction identifier.
     */
    protected void notifyCommit(int segment, long ts) {

    }

    /**
     * Send the segment notice that it must GC the transaction.
     * 
     * @param segment
     *            The segment identifier.
     * @param ts
     *            The transaction identifier.
     * 
     * @todo Typically, the transaction server will generate GC notices for
     *       multiple transactions at once (one for each transaction that
     *       committed that emerged from a given ground state).  Those notices
     *       could be combined to reduce RPC traffic.
     */
    protected void notifyGC(int segment, long ts) {

    }

//    /**
//     * A description of an index partition used to declare the index partition
//     * as part of the transaction.
//     * 
//     * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
//     * @version $Id$
//     */
//    public static class PartitionMetadata {
//        
//        /**
//         * The index name.
//         */
//        public static final String name;
//        
//        /**
//         * The separator key for the index partition.
//         */
//        public static final byte[] separatorKey;
//        
//    }
    
}

//* 
//* FIXME Detect transaction identifiers that go backwards? For example tx0
//* starts on one segment A while tx1 starts on segment B. Tx0 later starts
//* on segment B. From the perspective of segment B, tx0 begins after tx1.
//* This does not look like a problem unless there is an intevening commit,
//* at which point tx0 and tx1 will have starting contexts that differ by the
//* write set of the commit.<br>
//* What exactly is the impact when transactions start out of sequence? Do we
//* need to negotiated a distributed start time among all segments on which
//* the transaction starts? That would be a potential source of latency and
//* other kinds of pain. Look at how this is handled in the literature. One
//* way to handle it is essentially to declare the intention of the
//* transaction and pre-notify segments that will be written. This requires
//* some means of figuring out that intention and is probably relevant (and
//* solvable) only for very large row or key scans.
//* 
//* @todo What exactly is the impact when transactions end out of sequence? I
//*       presume that this is absolutely Ok.


// /**
// * <p>
// * Deallocate slots for versions having a transaction timestamp less than
// or
// * equal to <i>timestamp</i> that have since been overwritten (or deleted)
// * by a committed transaction having a timestamp greater than
// <i>timestamp</i>.
// * </p>
// * <p>
// * The criteria for deallocating historical versions is that (a) there is
// a
// * more recent version; and (b) there is no Active (vs PENDING or
// COMPLETED)
// * transaction which could read from that historical version. The journal
// * does NOT locally have enough information to decide when it can swept
// * historical versions written by a given transaction. This notice MUST
// come
// * from a transaction service which has global knowledge of which
// * transactions have Prepared or Aborted and can generate notices when all
// * transactions before a given timestamp have been Prepared or Aborted.
// For
// * example, a long running transaction can cause notice to be delayed for
// * many short lived transactions that have since completed. Once the long
// * running transaction completes, the transaction server can compute the
// * largest timestamp value below which there are no active transactions
// and
// * generate a single notice with that timestamp.
// * </p>
// *
// * @param timestamp
// * The timestamp.
// *
// * @todo This operation MUST be extremely efficient.
// *
// * @todo This method is exposed suposing a transaction service that will
// * deliver notice when the operation should be conducted based on
// * total knowledge of the state of all transactions running against
// * the distributed database. As such, it may have to scan the journal
// * to locate the commit record for transactions satisifying the
// * timestamp criteria.
// */
// void gcTx( long timestamp ) {

// // * <p>
// // * Note: Migration to the read-optimized database is NOT a
// pre-condition for
// // * deallocation of historical versions - rather it enables us to remove
// the
// // * <em>current</em> committed version from the journal.
// // * </p>

// /*
// * FIXME Implement garbage collection of overwritten and unreachable
// * versions. Without migration to a read-optimized database, GC by
// * itself is NOT sufficient to allow us to deallocate versions that have
// * NOT been overwritten and hence is NOT sufficient to allow us to
// * discard historical transactions in their entirety.
// *
// * Given a transaction Tn that overwrites one or more pre-existing
// * versions, the criteria for deallocation of the overwritten versions
// * are:
// *
// * (A) Tn commits, hence its intention has been made persistent; and
// *
// * (B) There are no active transactions remaining that started from a
// * committed state before the commit state resulting from Tn, hence the
// * versions overwritten by Tn are not visible to any active transaction.
// * Any new transaction will read through the committed state produced by
// * Tn and will perceive the new versions rather than the overwritten
// * versions.
// *
// * Therefore, once Tn commits (assuming it has overwritten at least one
// * pre-existing version), we can add each concurrent transaction Ti that
// * is still active when Tn commits to a set of transactions that must
// * either validate or abort before we may GC(Tn). Since Tn has committed
// * it is not possible for new transactions to be created that would have
// * to be included in this set since any new transaction would start from
// * the committed state of Tn or its successors in the serialization
// * order. As transactions validate or abort they are removed from
// * GC(Tn). When this set is empty, we garbage collect the pre-existing
// * versions that were overwritten by Tn.
// *
// * The sets GC(T) must be restart safe. Changes to the set can only
// * occur when a transaction commits or aborts. However, even the abort
// * of a transaction MUST be noticable on restart.
// *
// * A summary may be used that is the highest transaction timestamp for
// * which Tn must wait before running GC(Tn). That can be written once
// *
// *
// * Note that multiple transactions may have committed, so we may find
// * that Tn has successors in the commit/serialization order that also
// * meet the above criteria. All such committed transactions may be
// * processed at once, but they MUST be processed in their commit order.
// *
// * Once those pre-conditions have been met the following algorithm is
// * applied to GC the historical versions that were overwritten by Tn:
// *
// * 1. For each write by Ti where n < i <= m that overwrote a historical
// * version, deallocate the slots for that historical version. This is
// * valid since there are no active transactions that can read from that
// * historical state. The processing order for Ti probably does not
// * matter, but in practice there may be a reason to choose the
// * serialization or reverse serialization order
// *
// * ---- this is getting closed but is not yet correct ----
// *
// * All versions written by a given transaction have the timestamp of
// * that transaction.
// *
// * The committed transactions are linked by their commit records into a
// * reverse serialization sequence.
// *
// * Each committed transaction has an object index that is accessible
// * from its commit record. The entries in this index are versions that
// * were written (or deleted) by that transaction. This index reads
// * through into the object index for the committed state of the journal
// * from which the transaction was minted.
// *
// * We could maintain in the entry information about the historical
// * version that was overwritten. For example, its firstSlot or a run
// * length encoding of the slots allocated to the historical version.
// *
// * We could maintain an index for all overwritten versions from
// * [timestamp + dataId] to [slotId] (or a run-length encoding of the
// * slots on which the version was written). Given a timestamp, we would
// * then do a key scan from the start of the index for all entries whose
// * timestamp was less than or equal to the given timestamp. For each
// * such entry, we would deallocate the version and delete the entry from
// * the index.
// *
// * tx0 : begin tx0 : write id0 (v0) tx0 : commit journal : deallocate <=
// * tx0 (NOP since no overwritten versions)
// *
// * tx1 : begin tx2 : begin tx1 : write id0 (v1) tx1 : commit journal :
// * deallocate <= tx1 (MUST NOT BE GENERATED since dependencies exist :
// * tx1 and tx0 both depend on the committed state of tx0 -- sounds like
// * lock style dependencies for deallocation !) tx2 : commit journal :
// * deallocate <= tx2
// *
// * index:: [ tx0 : id0 ] : v0 [ tx1 : id1 ] : v1
// *
// * keyscan <= tx2
// */

// }

// /**
// * The transaction identifier of the last transaction begun on this
// journal.
// * In order to avoid extra IO this value survives restart IFF there is an
// * intervening commit by any active transaction. This value is used to
// * reject transactions whose identifier arrives out of sequence at the
// * journal.
// *
// * @return The transaction identifier or <code>-1</code> if no
// * transactions have begun on the journal (or if no transactions
// * have ever committed and no transaction has begun since restart).
// */
// public long getLastBegunTx() {
//        
// return lastBegunTx;
//        
// }
// private long lastBegunTx = -1;

