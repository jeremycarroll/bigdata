/**

Copyright (C) SYSTAP, LLC 2006-2007.  All rights reserved.

Contact:
     SYSTAP, LLC
     4501 Tower Road
     Greensboro, NC 27410
     licenses@bigdata.com

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/
/*
 * Created on Feb 15, 2007
 */

package com.bigdata.journal;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.LinkedList;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

import org.apache.log4j.Logger;

import com.bigdata.counters.CounterSet;
import com.bigdata.mdi.AbstractResourceMetadata;
import com.bigdata.mdi.IResourceMetadata;
import com.bigdata.rawstore.AbstractRawWormStore;
import com.bigdata.rawstore.Bytes;
import com.bigdata.rawstore.IMRMW;
import com.bigdata.rawstore.IMROW;
import com.bigdata.rawstore.IRawStore;
import com.bigdata.rawstore.WormAddressManager;
import com.bigdata.util.ChecksumUtility;

/**
 * A non-restart-safe store for temporary data that buffers data in memory until
 * a {@link #maximumInMemoryExtent} has been reached and then converts to a
 * disk-based store with a maximum capacity determined by the configuration of
 * the {@link WormAddressManager}. On conversion to a disk-backed store, the
 * disk file is created using the temporary file mechansism and is marked for
 * eventual deletion no later than when the JVM exits and as soon as the store
 * is {@link #close() closed}.
 * 
 * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
 * @version $Id$
 * 
 * @todo add configuration properties.
 * 
 * FIXME Use the {@link DiskOnlyStrategy} here but add an option for lazy
 * creation of the file on the disk, disable forcing of writes or force on
 * commit, and mark the file as "temporary". This will let us write in memory
 * until the write cache overflows and then it will start putting down the data
 * on the disk. This has all of the advantages of the current approach (low
 * latency on startup), plus we get MRMW for the temp store.
 */
public class TemporaryRawStore extends AbstractRawWormStore implements IRawStore, IMROW {

    protected static final Logger log = Logger.getLogger(TemporaryRawStore.class);
    
    protected final static int DEFAULT_INITIAL_IN_MEMORY_EXTENT = Bytes.megabyte32 * 1;

    protected final static int DEFAULT_MAXIMUM_IN_MEMORY_EXTENT = Bytes.megabyte32 * 10;
    
    /**
     * The initial size of the in-memory buffer. This buffer will grow as
     * necessary until {@link #maximumInMemoryExtent} at which point the store
     * will convert over to a disk-based mechanism.
     */
    public final long initialInMemoryExtent;
    
    /**
     * The maximum capacity of the in-memory buffer.
     */
    public final long maximumInMemoryExtent;
    
    /**
     * Whether or not a direct buffer was used for the in-memory store (not
     * recommended).
     */
    public final boolean useDirectBuffers;

    private boolean open = true;
    
    private IBufferStrategy buf;
    
    /**
     * When non-<code>null</code> this is a direct {@link ByteBuffer}
     * allocated using the {@link DirectBufferPool} during
     * {@link #overflowToDisk()} and handed off to the {@link DiskOnlyStrategy}
     * for use as its write cache. When non-<code>null</code> this buffer is
     * {@link DirectBufferPool#release(ByteBuffer)}ed back to the
     * {@link DirectBufferPool} in {@link #finalize()} to avoid a native memory
     * leak.
     */
    private ByteBuffer writeCache = null;
    
    /**
     * Store identifier.
     */
    private UUID uuid = UUID.randomUUID();
    
    /**
     * Note: this timestamp is NOT generated by a centralized time server. 
     */
    private long createTime = System.currentTimeMillis();

    /**
     * Note: Temporary stores do not have persistent resource descriptions.
     */
    public IResourceMetadata getResourceMetadata() {
        
        final File file = buf.getFile();
        
        final String fileStr = file == null ? "" : file.toString();
        
        return new AbstractResourceMetadata(fileStr, buf.getExtent(), uuid, createTime) {
        
            public boolean isJournal() {
                return false;
            }
        
            public boolean isIndexSegment() {
                return false;
            }
        
        };
        
    }
    
    public IBufferStrategy getBufferStrategy() {
        
        return buf;
        
    }

    /**
     * Create a {@link TemporaryRawStore} with an initial in-memory capacity of
     * 10M that will grow up to 100M before converting into a disk-based store
     * backed by a temporary file. These defaults are appropriate for a
     * relatively small number of processes that will write a lot of data. If
     * you have a lot of processes then you need to be more conservative with
     * RAM in the initial allocation and switch over to disk sooner. For
     * example, transactions use smaller defaults in order to support a large
     * #of concurrent transactions without a large memory burden.
     * 
     * @todo the memory growth strategy does not respect the in-memory maximum
     *       without parameterizing and overriding the #of bytes to extent the
     *       store on overflow for {@link TransientBufferStrategy}
     */
    public TemporaryRawStore() {

        this(WormAddressManager.SCALE_UP_OFFSET_BITS);
        
    }
    
    public TemporaryRawStore(int offsetBits) {

        this(offsetBits,
                DEFAULT_INITIAL_IN_MEMORY_EXTENT,
                DEFAULT_MAXIMUM_IN_MEMORY_EXTENT,
                false // useDirectBuffers (NO!)
                );
        
    }

    /**
     * Create a {@link TemporaryRawStore} with the specified configuration.
     * 
     * @param offsetBits
     *            This determines the capacity of the store file and the maximum
     *            length of a record.  The value is passed through to
     *            {@link WormAddressManager#WormAddressManager(int)}.
     * @param initialInMemoryExtent
     *            The initial size of the in-memory buffer. This buffer will
     *            grow as necessary until <i>maximumInMemoryExtent</i> at which
     *            point the store will convert over to a disk-based mechanism.
     * @param maximumInMemoryExtent
     *            The maximum capacity of the in-memory buffer. The actual
     *            maximum may differ slightly based on the buffer growth policy.
     * @param useDirectBuffers
     *            Whether or not the in-memory buffer will be direct. The use of
     *            a direct buffer here is NOT recommended.
     */
    public TemporaryRawStore(int offsetBits, long initialInMemoryExtent,
            long maximumInMemoryExtent, boolean useDirectBuffers) {
        
        super(offsetBits);
        
        buf = new TransientBufferStrategy(offsetBits, initialInMemoryExtent,
                maximumInMemoryExtent, useDirectBuffers);
        
        this.initialInMemoryExtent = initialInMemoryExtent;
        
        this.maximumInMemoryExtent = maximumInMemoryExtent;
        
        this.useDirectBuffers = useDirectBuffers;
        
    }

    /**
     * Closes the store if it gets GCd.
     */
    protected void finalize() throws Throwable {
        
        try {
            
            if(open) {
                
                log.warn("Closing temp store.");
                
                close();
                
            }
            
            if (writeCache != null) {

                INSTANCE.release(writeCache);
                
                writeCache = null;
                
            }
            
        } catch (Throwable t) {
            
            t.printStackTrace(System.err);
            
        }
        
        super.finalize();
        
    }
    
    public File getFile() {
        
        if(!open) throw new IllegalStateException();
        
        return buf.getFile();
        
    }
    
    /**
     * Close the store and delete the associated file, if any.
     */
    public void close() {

        if(!open) throw new IllegalStateException();
        
        open = false;
        
        buf.closeAndDelete();
        
        buf = null;
        
    }

    /**
     * Note: This operation is a NOP since {@link #close()} always deletes the
     * backing file and {@link #deleteResources()} requires that the store is closed as a
     * pre-condition.
     */
    public void deleteResources() {
        
        if(open) throw new IllegalStateException();
        
        /*
         * NOP
         */
        
    }
    
    public void closeAndDelete() {
    
        // Close already deletes the backing file.
        close();
        
    }

    public void force(boolean metadata) {
        
        if(!open) throw new IllegalStateException();
        
        buf.force(metadata);
        
    }

    public long size() {
        
        return buf.size();
        
    }
    
    public boolean isOpen() {
        
        return open;
        
    }

    public boolean isReadOnly() {
        
        if(!open) throw new IllegalStateException();
        
        return false;
        
    }
    
    /**
     * Always returns <code>false</code> since the store will be deleted as soon
     * as it is closed.
     */
    public boolean isStable() {
    
        if(!open) throw new IllegalStateException();
        
        return false;
        
    }
    
    public boolean isFullyBuffered() {
        
        if(!open) throw new IllegalStateException();
        
        return buf.isFullyBuffered(); 
        
    }

    /**
     * FIXME readers and writers are being serialized since in order to ensure
     * that {@link #overflowToDisk()} is invoked during a time when no reader
     * and no other writer is trying to access the store. Examine ways to
     * increase the concurrency here. Both the transient and the disk-only modes
     * are fully {@link IMRMW}. It is only the transition that requires us to
     * serialize access.  Also note that the write task can wait when it needs
     * to {@link #overflowToDisk()} since readers can continue to read against
     * the transient buffer (as long as the write task eventually runs).
     */
    synchronized public ByteBuffer read(long addr) {

        if(!open) throw new IllegalStateException();

        return buf.read(addr);
        
    }

    /**
     * FIXME This method is <code>synchronized</code> so that overflow of the
     * buffer from memory to disk will be atomic. While this provides both
     * {@link IMROW} and {@link IMRMW} guarentees for the
     * {@link TemporaryRawStore} it does so at the expense of serializing calls
     * to {@link #write(ByteBuffer)}.
     * <p>
     * Explore options for greater concurrency here in support of concurrent
     * tasks executing against the same transaction or map/reduce jobs writing
     * on a temporary store from multiple map tasks.
     */
    synchronized public long write(ByteBuffer data) {
        
        if(!open) throw new IllegalStateException();
        
        try {
            
            /*
             * Note: this operation will transparently extend the in-memory
             * buffer as necessary up to the specified maximum capacity.
             */
            return buf.write(data);
            
        } catch(OverflowException ex) {
        
            if(buf instanceof TransientBufferStrategy) {

                overflowToDisk();
                
                return buf.write(data);
                
            } else {
                
                throw ex;
                
            }
            
        }
        
    }

    /**
     * Spills the in-memory buffer onto the disk and replaces the
     * {@link TransientBufferStrategy} with a {@link DiskOnlyStrategy}.
     * <p>
     * Note: The {@link TemporaryRawStore} transitions from a transient store
     * (fully buffered, so interrupts can not cause the channel to be closed) to
     * a disk-only store (already knows how to handle interrupts).
     * <p>
     * The only place where interrupts could be a problem is during a transition
     * from transient to disk-only, i.e., in this method. However, we already
     * force readers and writers to synchronize for an overflow event so there
     * will only be the one writer running when this method is invoked.
     */
    private void overflowToDisk() {

        log.info("TemporaryRawStore: overflow to disk; nbytes="
                + buf.getNextOffset());
        
        TransientBufferStrategy tmp = (TransientBufferStrategy)buf;
        
        File file;
        
        try {

            file = File.createTempFile("bigdata", ".tmpStore");
            
        } catch (IOException ex) {
            
            throw new RuntimeException(ex);
            
        }
        
        /*
         * Set the initial extent to be large enough for the root blocks plus
         * twice the data in the in-memory buffer.
         */
        final long initialExtent = FileMetadata.headerSize0 + tmp.getUserExtent() * 2;
        
        final long maximumDiskExtent = Bytes.gigabyte32 * 2;
        
        final boolean create = false;
        
        final boolean isEmptyFile = true;
        
        final boolean deleteOnExit = true;
        
        final boolean readOnly = false;
        
        // Do not force writes since the store is not restart safe.
        final ForceEnum forceWrites = ForceEnum.No;

        // The store is never pre-existing so we do not have a checksum to validate.
        final boolean validateChecksum = false;
        
        // the local system time.
        final long createTime = System.currentTimeMillis();
        
        // We still need an object to compute the checksum to be stored in the root blocks.
        final ChecksumUtility checker = new ChecksumUtility();
        
        /*
         * Create a unique store file and setup the root blocks. The file will
         * be pre-extended to the requested initialExtent.
         * 
         * @todo There is a bug in the release of large temporary direct
         * ByteBuffers. For regular journals that overflow, the write cache is
         * allocated once and handed off from journal to journal. However, there
         * is no such opportunity for temporary stores. Also, the overflow
         * operation itself will cause a "temporary" direct buffer to be
         * allocated and thereby create a memory leak.
         * 
         * The current workaround uses a JVM-wide pool of direct ByteBuffers.
         * During overflow, the data is transferred from the heap ByteBuffer
         * backing the TransientBufferStrategy onto a direct ByteBuffer, and
         * from there onto disk using a sequence of writes until all data has
         * been transferred. At that point the direct ByteBuffer is either
         * released back to the pool or a reference is saved on the temporary
         * raw store and the direct byte buffer is handed off to the disk only
         * strategy for use as a write cache. (In fact, the operations must be
         * performed in a slightly different sequence since we need to hand the
         * write cache buffer to the disk only strategy before we transfer the
         * data onto the disk).
         * 
         * @see http://bugs.sun.com/bugdatabase/view_bug.do;jsessionid=8fab76d1d4479fffffffffa5abfb09c719a30?bug_id=6210541
         * 
         * @todo use a read cache when converting to a DiskOnlyStrategy?
         */
        
        try {

            writeCache = INSTANCE.acquire(2000, TimeUnit.MILLISECONDS);
            
        } catch(Exception ex) {
        
            throw new RuntimeException("Could not allocate buffer: " + ex, ex);
        
        }
        
        FileMetadata fileMetadata = new FileMetadata(file, BufferMode.Disk,
                useDirectBuffers, initialExtent, maximumDiskExtent, create,
                isEmptyFile, deleteOnExit, readOnly, forceWrites,
                getOffsetBits(), 0/* readCacheCapacity */, 0/*readCacheMaxRecordSize*/,
                writeCache, validateChecksum, createTime, checker);
        
        // Open the disk-based store file.
        DiskOnlyStrategy diskBuf = new DiskOnlyStrategy(Bytes.gigabyte * 2,
                fileMetadata);

        try {

            /*
             * Transfer the data from the in-memory buffer to the disk.  The
             * write begins immediately after the file header.
             */
            
//            // setup the transfer source.
//            ByteBuffer b = tmp.getBuffer();
//            b.limit((int)tmp.nextOffset);
//            b.position(0);
//            
//            diskBuf.writeOnDisk(b, 0L);
//            
////            // write the data on the channel.
////            diskBuf.getChannel().write(b,diskBuf.getHeaderSize());

            /*
             * This transfers the data from the heap buffer backing the
             * TemporaryRawStore onto a direct byte buffer that will also be
             * used for the write cache by the DiskOnlyStrategy in a sequence of
             * operations, each operation transferring at most one "write cache"
             * worth of data onto the disk.
             * 
             * Note: We go through this hassle with the [writeCache] because it
             * is a _direct_ ByteBuffer and Java therefore WILL NOT allocate a
             * "temporary" direct buffer for these operations.
             */
            
            // the heap buffer for the TransientBufferStrategy.
            final ByteBuffer data = tmp.getBuffer();

            // should be a heap buffer.
            assert data.hasArray();

            // setup to transfer all bytes from [0:tmp.nextOffset].
            data.limit((int)tmp.nextOffset);
            data.position(0);

            // #of bytes to transfer.
            final int nbytes = data.remaining();

            // position the file channel after the root blocks.
            diskBuf.getChannel().position(diskBuf.getHeaderSize());

            int count = 0;
            int nwrites = 0;

            while (data.remaining() > 0) {

                // reset the direct buffer used to manage the transfers.
                writeCache.rewind();

                // #of bytes to copy from the heap buffer to the direct buffer.
                final int nxfer = Math.min(data.remaining(), writeCache
                        .capacity());

                // copy from the heap buffer to the direct buffer.
                writeCache.put(data.array(), data.arrayOffset() + count, nxfer);
                
                // advance by the #of bytes copied from the heap buffer.
                data.position(data.position() + nxfer);
                
                // prepare the direct buffer for writing.
                writeCache.flip();

                // write the direct buffer on the disk, updating the channel
                // position.
                count += diskBuf.getChannel().write(writeCache);

                nwrites++;

            }

            if (count != nbytes) {

                throw new RuntimeException("Expecting to write " + nbytes
                        + " bytes, but wrote " + count + " bytes in " + nwrites);

            }

            /*
             * Reset the write cache to make sure that it is empty before the
             * DiskOnlyStrategy begins to use this buffer.
             */
            
            writeCache.rewind();

            /*
             * Increment the offset - this is where the next write will be made
             * on the backing file.
             */

            diskBuf.nextOffset += tmp.nextOffset;
            
        } catch(Throwable t) {
            
            try {

                diskBuf.close();
                
                if (writeCache != null) {

                    INSTANCE.release(writeCache);
                    
                    writeCache = null;
                    
                }
                
            } catch (Throwable ex2) {

                log.warn(ex2, ex2);
                
            }
            
            throw new RuntimeException(t);
            
        }
        
        this.buf = diskBuf;
        
    }
    
    /**
     * The maximum length of a record that may be written on the store.
     */
    final public int getMaxRecordSize() {

        return ((AbstractRawWormStore) buf).getAddressManger()
                .getMaxByteCount();

    }

    synchronized public CounterSet getCounters() {

        if (root == null) {

            root = new CounterSet();

        }

        return root;

    }
    private CounterSet root;

    /**
     * An instance of this class manages a JVM-wide pool of direct (aka native)
     * {@link ByteBuffer}s. Methods are provided to acquire a
     * {@link ByteBuffer} from the pool and to release a {@link ByteBuffer} back
     * to the pool.
     * <p>
     * Note: There is a bug in the release of large temporary direct
     * {@link ByteBuffer}s which motivates this class. For regular journals
     * that overflow, the write cache is allocated once and handed off from
     * journal to journal. However, there is no such opportunity for temporary
     * stores. Unfortunately it is NOT an option to simply disable the write
     * cache for temporary stores since NIO will allocate (and fail to release)
     * an "temporary" direct buffer for the operation which transfers the data
     * from the {@link TransientBufferStrategy} to disk. Therefore the data is
     * copied into a temporary buffer allocated from this pool and then the
     * buffer is either handed off to the {@link DiskOnlyStrategy} for use as
     * its write cache (in which case the {@link TemporaryRawStore} holds a
     * reference to the buffer and releases it back to those pool when it is
     * finalized) or the buffer is immediately released back to this pool.
     * 
     * @see http://bugs.sun.com/bugdatabase/view_bug.do;jsessionid=8fab76d1d4479fffffffffa5abfb09c719a30?bug_id=6210541
     * 
     * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
     * @version $Id$
     */
    static class DirectBufferPool {
 
        /**
         * Note: This is NOT a weak reference colletion since the JVM will leak
         * native memory.
         */
        final private BlockingQueue<ByteBuffer> pool; 
        
        /**
         * Used to recognize {@link ByteBuffer}s allocated by this pool so that
         * we can refuse offered buffers that were allocated elsewhere (a
         * paranoia feature which could be dropped).
         * <p>
         * Note: YOU CAN NOT use a hash-based collection here. hashCode() and
         * equals() for a {@link ByteBuffer} are very heavy operations that are
         * dependent on the data actually in the buffer at the time the
         * operation is evaluated!
         * <p>
         * Note: if you set [allocated := null] in the ctor then tests of the
         * allocated list are disabled.
         */
        final private List<ByteBuffer> allocated;
 
        /**
         * The number {@link ByteBuffer}s allocated (must use {@link #lock} for
         * updates or reads to be atomic).
         */
        private int size = 0;
        
        /**
         * The maximum #of {@link ByteBuffer}s that will be allocated. 
         */
        private final int poolCapacity;
        
        /**
         * The capacity of the {@link ByteBuffer}s managed by this pool.
         */
        private final int bufferCapacity;

        /**
         * Lock used to serialize access to the other fields on this class.
         */
        private final ReentrantLock lock = new ReentrantLock();
        
        /**
         * Condition used to await a buffer release.
         */
        private final Condition bufferRelease = lock.newCondition();
        
        /**
         * The capacity of the buffer as specified to the ctor.
         */
        public int getPoolCapacity() {
            
            return poolCapacity;
            
        }

        /**
         * The approximate #of {@link ByteBuffer}s currently managed by this
         * pool.
         */
        public int getPoolSize() {
            
            lock.lock();
            
            try {
                
                return size;
                
            } finally {
                
                lock.unlock();
                
            }
            
        }
        
        /**
         * The capacity of the {@link ByteBuffer}s managed by this pool as
         * specified to the ctor.
         */
        public int getBufferCapacity() {

            return bufferCapacity;
            
        }
        
        /**
         * Create a direct {@link ByteBuffer} pool.
         * <p>
         * Note: When the <i>poolSize</i> is bounded then {@link #acquire()}
         * MAY block. This can introduce deadlocks into the application. You can
         * use a timeout to limit the sensitivity to deadlocks or you can use an
         * unbounded pool and accept that {@link OutOfMemoryError}s will arise
         * if there is too much concurrent demand for the buffers supplied by
         * this pool.
         * 
         * @param poolCapacity
         *            The maximum capacity of the pool. Use
         *            {@link Integer#MAX_VALUE} to have a pool with an unbounded
         *            number of buffers.
         * @param bufferCapacity
         *            The capacity of the {@link ByteBuffer}s managed by this
         *            pool.
         */
        private DirectBufferPool(int poolCapacity, int bufferCapacity) {
            
            if (poolCapacity <= 0)
                throw new IllegalArgumentException();
            
            if (bufferCapacity <= 0)
                throw new IllegalArgumentException();

            this.poolCapacity = poolCapacity;
            
            this.bufferCapacity = bufferCapacity;
            
            this.allocated = null; // Note: disables assertion
//            this.allocated = new LinkedList<ByteBuffer>();
            
            this.pool = new LinkedBlockingQueue<ByteBuffer>(poolCapacity);
            
        }
        
        /**
         * Return a direct {@link ByteBuffer}. The capacity of the buffer is
         * determined by the configuration of this pool. The position will be
         * equal to zero, the limit will be equal to the capacity, and the mark
         * will not be set.
         * <p>
         * Note: This method will block if there are no free buffers in the pool
         * and the pool was configured with a maximum capacity. In addition it
         * MAY block if there is not enough free memory to fulfill the request.
         * 
         * @return A direct {@link ByteBuffer}.
         * 
         * @throws InterruptedException
         *             if the caller's {@link Thread} is interrupted awaiting a
         *             buffer.
         * @throws TimeoutException 
         */
        public ByteBuffer acquire() throws InterruptedException, TimeoutException {

            return acquire(Long.MAX_VALUE, TimeUnit.MILLISECONDS);
            
        }
        
        public ByteBuffer acquire(long timeout, TimeUnit unit) throws InterruptedException, TimeoutException {

            log.info("");

            lock.lock();
            
            try { 

                if(pool.isEmpty()) {
                    
                    allocate(timeout,unit);
                    
                }
                
                // the head of the pool must exist.
                final ByteBuffer b = pool.take();
                
                assert b != null;
                
                assert b.capacity() == bufferCapacity;

                assertOurBuffer( b );
                
                b.rewind();
                
                b.limit(bufferCapacity);
                
                return b;
            
            } finally {
                
                lock.unlock();
                
            }
            
        }
        
        /**
         * Release a direct {@link ByteBuffer} allocated by this pool back to
         * the pool.
         * 
         * @param b
         *            The buffer.
         *            
         * @throws InterruptedException
         */
        public void release(final ByteBuffer b) throws InterruptedException {
            
            release(b, Long.MAX_VALUE, TimeUnit.MILLISECONDS);
            
        }
        
        public void release(final ByteBuffer b, long timeout, TimeUnit units) throws InterruptedException {
            
            log.info("");
            
            if (b == null)
                throw new IllegalArgumentException();
            
            lock.lock();
            
            try {

                assertOurBuffer( b );
                
                // add to the pool.
                pool.offer(b, timeout, units);
                
                /*
                 * Signal ONE thread that there is a buffer available.
                 * 
                 * Note: There is the potential for this signal to be missed if
                 * the thread waiting in [allocate] allows itself to be
                 * interrupted once the signal has arrived and before it has
                 * returned to the caller. Once the buffer is in the caller's
                 * hands it is up to the caller to ensure that it is released
                 * back to the pool, e.g., in finalize().
                 * 
                 * Note: Another way to handle this is to signalAll() and then
                 * have the thread check to see if the pool is empty and restart
                 * its wait (after subtracting out the time already elapsed). This
                 * is doubtless more robust.
                 */
                bufferRelease.signal();
                
            } finally {
                
                lock.unlock();
                
            }
            
        }
        
        /**
         * Attempts to allocate another direct {@link ByteBuffer}. If
         * successful then it will add the buffer to the {@link #pool}.
         * 
         * @throws InterruptedException 
         * @throws TimeoutException 
         * 
         * @throws
         */
        private void allocate(long timeout, TimeUnit unit) throws InterruptedException, TimeoutException {
            
            assert lock.isHeldByCurrentThread();

            log.info("");

            try {

                if (size >= poolCapacity) {

                    /*
                     * Wait for a free buffer since the pool is at its capacity.
                     */

                    log.warn("Pool is at capacity - waiting for a free buffer");
                    
                    awaitFreeBuffer(timeout, unit);
                    
                }

                // allocate a buffer
                final ByteBuffer b = ByteBuffer.allocateDirect(bufferCapacity);

                // update the pool size.
                size++;
                
                // add to the set of known buffers
                if (allocated != null) {

                    allocated.add(b);
                    
                }

                // add to the pool.
                pool.add(b);
                
                /*
                 * There is now a buffer in the pool and the caller will get it
                 * since they hold the lock.
                 */
                
                return;
                
            } catch(OutOfMemoryError err) {
                
                log.error(
                        "Not enough native memory - will await a free buffer: "
                                + err, err);

                awaitFreeBuffer(timeout,unit);
                
            }
            
        }

        private void awaitFreeBuffer(long timeout, TimeUnit unit)
                throws InterruptedException, TimeoutException {

            // await a buffer to appear in the pool.
            if (!bufferRelease.await(timeout, unit)) {
                
                throw new TimeoutException();
                
            }
            
            /*
             * There is now a buffer in the pool and the caller will get it
             * since they hold the lock.
             * 
             * Note: From here until the caller gets the buffer either (a)
             * do NOT allow the current thread to be interrupted. Failure to
             * adhere to this advice can result in a buffer remaining the
             * pool but no thread awaiting that released buffer noticing it
             * there!
             */

            assert ! pool.isEmpty();
            
            return;

        }

        private void assertOurBuffer(ByteBuffer b) {
            
            assert lock.isHeldByCurrentThread();
                        
            if (allocated == null) {

                // test is disabled.
                
                return;
                
            }
            
            for(ByteBuffer x : allocated) {
                
                if( x == b ) return;
                
            }
            
            throw new IllegalArgumentException(
                    "Buffer not allocated by this pool.");
            
        }
        
    }

    /**
     * A JVM-wide pool of direct {@link ByteBuffer}s used for
     * {@link TemporaryRawStore}s.
     * <p>
     * Note: allocate() requests will block once the pool capacity has been
     * reached until a buffer is released().
     */
    private final static DirectBufferPool INSTANCE = new DirectBufferPool(//
            
            /*
             * This configuration will never block but is not bounded in how
             * many buffers it will allocate.
             */
            
//            Integer.MAX_VALUE, //poolCapacity
//            Bytes.megabyte32 // bufferCapacity
            
            /*
             * This configuration will block if there is a concurrent demand for
             * more than [poolCapacity] buffers.
             * 
             * This is a pretty reasonable configuration for deployment. It will
             * serialize (or timeout) concurrent operations requiring more than
             * [poolCapacity] buffers in aggregate demand and each buffer is
             * modestly large so that the write cache will have good
             * performance. The total native memory demand for temporary stores
             * is capped at [poolCapacity * bufferCapacity] bytes, which is
             * again a reasonable value.
             */
            100, // poolCapacity
            1 *Bytes.megabyte32 // bufferCapacity
            
            /*
             * This configuration may be useful for stress testing.
             */
//            1, // poolCapacity
//            Bytes.kilobyte32
            );

}
