============================================================

Notes on store level record checksums and record compression.

1. many record compression schemes will fail if the data are corrupt,
   but logically you compress first and then checksum the record.

   compression is often a technique using a stream of blocks.

   checksum is a streaming technique.

   // IRawStore#write()
   write(ByteBuffer b) : addr

   // AbstractJournal#write()

   if(compress) {

      b = compress(b)

   }

   int chksum;
   if(useChecksum) {

      bytesRequired = b.remaining() + 4;

      chmsum = computeChecksum( b );

   } else bytesRequired = b.remaining();

   bufferStrategy.write(b,chksum,useChecksum)

   Note: buffer strategy write() probably needs to have the checksum
   value pass along in addition to the record to avoid re-allocation
   of the ByteBuffer just to tack on the additional 4 bytes.  We could
   either always write those additional 4 bytes or optionally write
   them if checksums are enabled.

2. the root block needs to hold the critical data indicating whether
   or not checksums in use and what record compression technique, if
   any, to apply.  We need this on hand before we can either read or
   write a record on the store.

3. we need 4 bytes (int32) for the checksum.  this should be at the
   end of the record, so the size in the store is extended by 4 bytes
   and the address for the record on the store is adjusted to also
   include those 4 bytes.  However, when you read from the store it
   will give you a slice WITHOUT those four bytes.  Further, if it is
   using compression then it will decompress the slice, resulting in a
   new slice that can be much larger than the record on the store
   whose size is encoded within the address.  This will probably break
   a variety of asserts that assume that the returned ByteBuffer will
   be exactly the size of the byte count encoded in the address.

4. Compression should run on the byte[] not on the slower ByteBuffer.
   Serialization generally writes on a byte[], but sometimes that is
   wrapped up as a ByteBuffer - and it can even be a slice() onto a
   larger array (NodeSerializer does this since it returns a view onto
   an internal buffer).

    /**
     * The {@link Adler32} checksum. This is an int32 value, even through the
     * {@link Checksum} API returns an int64 (aka long integer) value. The
     * actual checksum is in the lower 32 bit.
     */
    static final int SIZEOF_CHECKSUM = Bytes.SIZEOF_INT;

    /**
     * Offset of the int32 value that is the {@link Adler32} checksum of the
     * serialized node or leaf. The checksum is computed for all bytes exclusing
     * the first 4 bytes, on which the value of the computed checksum is
     * written.
     */
    static final int OFFSET_CHECKSUM = 0;

    /**
     * When <code>true</code>, checksums will be generated for serialized
     * nodes and leaves and verified on read. Checksums provide a check for
     * corrupt media and make the database more robust at the expense of some
     * added cost to compute a validate the checksums.
     * <p>
     * Computing the checksum is ~ 40% of the cost of (de-)serialization.
     * <p>
     * When the backing store is fully buffered (it is entirely in RAM) then
     * checksums are automatically disabled.
     * 
     * @deprecated See {@link #setUseChecksum(boolean)}
     */
    public final boolean getUseChecksum() {return useChecksum;}

============================================================

    - Tune indices

      - The ids index should benefit from value compression since the
        values are the serialized terms.  This will require custom
        code to break the values into symbols and then use huffman
        encoding.  Alternatively, simply treat each value as a symbol
        and code from that (assuming that value reuse is common - if
        not then at least URIs can be broken down into common
        symbols).

      - The terms (term:id) index is on the order of 5x larger than
        the ids (id:term) index.  Presumably this is because updates
        are distributed more or less randomly across the terms index
        as new terms become defined but are strictly append only for
        the ids index since new ids are always larger than old ids.
	
         - A larger branching factor may benefit the ids index.

	 - A compacting merge of the terms index should greatly reduce
           its size.

	 - Nearly ALL _read_ time between the SPO and TERMS index is
           reading the TERMS index (99%).

	 - Nearly ALL _write_ time between the SPO and the TERMS index
           is writing the SPO index (99%).  Statements are more likely
           to be distinct than terms, so it makes sense that we write
           on the statement index more often.  However, note that this
           is true even though the TERMS index is 3x larger than the
           SPO index.

    - BTree

     - The RecordCompressor as utilized by the NodeSerializer is NOT
       thread-safe as it relies on a single cbuf field.  Either the
       static buffer pool (if direct buffers are performant for this),
       a heap buffer pool, dynamic heap allocations for
       (de-)compression, or a serialized access to an instance per
       NodeSerializer instance (and hence per BTree instance).

     - Change checksums to be at the store/record level.  Interpret
       the record length as having 2 additional bytes for read/write
       of the checksum.  Put it at the end of the record.
       Enable/disable at the store level.

       Add an option for read-back validation of writes?
       
       Add an option for a fully synchronized raw store interface on
       the Journal?

     - IAutoboxBTree

       - Write tests of the autobox API for BTree, FusedView,
         ClientIndexView, and DataServiceIndex.

       - Should be able to instantiate a resource that is a BigdataMap
         or BigdataSet, so perhaps make these classes extend
         AbstractResource?  Same for SparseRowStore?

       - Need [isNull] for ClientIndexView and DataServiceIndex impls
         to reconstruct the object by allowing reconstruction of the
         ITuple.

	 Could modify the ResultBuffer to provide this additional
         information as an option and specify an appropriate
         constructor for the point test to get back that metadata.

	 Really, should define crudTuple() methods and rework the
	 batch crud methods in terms of tuples.  That is the general
	 framwork.  Bit flags can be used to indicate that certain
	 information (keys, vals, etc). are not required for a given
	 op.  (keys are always available on the client for these ops
	 so there is never a need to send them with the data: just
	 {val, isNull, isDeleted} and the option to read deleted
	 tuples.

	 BigdataMap and BigdataSet will not scale-out until this issue
	 is resolved.

    - Distributed file repository

         - handle overflow of blocks to the index segments during MOVE

	 - provide streaming socket api on data service for reading
           blocks (low level in the DiskOnlyStrategy - if in the write cache
           then return directly else return buffered input stream reading on
           the disk file and interrupt if journal is closed).

	 - range delete

	 - logical row scan for headers of documents in a key range.

         - Write test for forward and reverse scans starting at the
           fence posts around a partition boundary.

    - (**) Map/Reduce demo jobs.

      - Rework the map/reduce implementation to use local writes and
        distributed gathers.

      - Download, prepare, extract.

      - Concurrent RDF data load as a map/reduce job.

    - Tune network IO

      - huffman encoding is appropriate for network IO, but hu-tucker
        is not required since we have to decompress keys to get them
        inserted into the btree.

      - tokenization needs to be specified for RDF Value types for the
        purposes of compression.  In fact, we are guarenteed that
        values are NOT duplicated in a given batch so tokenization
        needs to uncover common symbols.  This is easy for URIs but
        less so for literals and impossible for BNodes (which do not
        really need to be in the lexicon anyway).

    - Try jini federation using only the terms index to assign
      consistent term identifiers, bulk loading into local SPO-only
      indices, and then range partitioning the indices into global
      SPO, POS, and OSP orders and bulk loading the global statement
      indices.  The data loader should be concurrent and a filter
      should be applied such that each "host" loads only the files
      that hash MOD N to that host.  (note that only AddTerms and
      AddIds go across the network API in this case.)

    - The temp triple store supports concurrent read only but not
      concurrent write, so it is not appropriate for a concurrent bulk
      loader.

    - An extended transaction model can be used for truth maintenance.
      The focus store is built up within isolated indices (that do not
      actually correspond to persistent indices, they only exist on
      the per-tx per-dataservice TemporaryStore).  The application can
      simply combine sets of assertions or retractions within a single
      transaction.  Either the application or an extension of the
      transaction manager MUST serialize the commits.  Within the
      commit processing, first do retractions then do assertions.

      - Provide for transaction local indices.  The index is dropped
        when the tx completes.

      - Provide for registration of a global index within a
        transaction, but the transaction will fail if the index
        already exists when it commits.

      - For full transactions, explore a synchronous overflow variant
        from a managed journal hosting named indices (as isolated by
        the tx) backed by a transient buffer to a managed journal
        backed by a disk buffer that would let us keep full
        concurrency.  The overflow should be a buffer -> disk transfer
        and then the disk file should be allowed to grow without
        bounds (or to the resource limit of the tx).  Asynchronous
        overflow processing for transaction journals would add a layer
        of complexity throughout as the MDI would need to be
        instantiated on a per-tx basis.

	The WriteExecutorService for the transaction would identify
	and support synchronous overflow exactly as it does now for
	unisolated journals.

     - Raw temporary stores such as are used by the index manager must
       be handled differently since (a) there are no indices in use;
       and (b) the use is always single threaded (no write executor
       service).  This case requires a direct buffer to disk transfer,
       but the API can be declare an assumption that the caller is
       single threaded and the writer can simply block during that
       transfer.

     * Some of the buffer strategy implementations appear to assume
       that by synchronizing one method, such as truncate() or
       transferTo(), that concurrent writers are automatically
       synchronized for those operations.  This is NOT true unless the
       write() method is also synchronized, and it is not for at least
       the DirectBufferStrategy.  This could show up as a concurrency
       problem with the indices when the store is used in a mode that
       is in fact concurrent and an overflow is triggered.

Short term tasks:

   - (*) Builds and releases.
   
      - Change over to subversion so that the edit trail does not get
        lost (complex process).

      - add alternative license.

      - Maven 2.x build
      
         - Start doing snapshot releases.

	 - Start periodic project documentation builds, perhaps on SF.
           Publish on the www.bigdata.com site.

         - Change the dependency to dsiutils.  I tried to do this with
           dsiutils-1.0.4 and ran into problems with
           (de-)serialization when compared to the lgpl-utils versions
           of the same classes.  Try this again and pay close
           attention to the lgpl-utils versions of the classes now
           located in dsiutils and see if I can isolated the problem.
           The problem was demonstrated by the bigdata-rdf test suites
           for both the temp and local triple stores but not for the
           bigdata test suites.

	 - Done. Update the Sesame 2.x dependency.

	 - Put all properties into the com.bigdata namespace.

   - Counters

     - Done. Work the counter path, name, and date(s) into the table
       which shows the counters history values so that it can all get
       copied easily into a worksheet.

     - Done. #commit is not being encoded property and shows up as a
       URL anchor and not as part of the PATH parameter.

     - Done. Counter XML MUST persist the HISTORY in the XML so that
       the log files can be useful for post-mortem.
       
     - Done. Write a final log file ('-final.xml') when the LBS
       terminates.

     - Done. This is now a configuration property.  The load balancer
       is not writing its counters into the correct location (logDir).
       The directory needs to be relative to the service directory, so
       a method needs to expose that directory to the service.

     - Done.  (Modified to accept samples out of timestamp order and
       to record the #of and total of samples falling within a given
       period.)  Loosing some samples through reporting w/in the same
       period.  Round up to the next period if this period is filled.
       An alternative is to sum the samples in the period and report
       their average by also tracking the #of samples in the period!

     - Done. When writing the path in the table rows, only write the
       path from the selected root.

     - Done. Problem with double-decoding of URL in NanoHTTP.

     - Done. (Can be a bit odd when also using a regex filter.) Add
       depth query parameter to limit the #of levels resolved from the
       path.

     - Done. (Currently using engineering notation, should be query
       parameter).  Set to 6 digits precision, not {3,6} after the
       decimal.  Or right justify decimal value with fixed N digits
       after the decimal (could be query param).

     - Done. (Also added the timestamp itself.) When converting to
       minutes, hours, and days in httpd make sure to have a few
       digits after the decimal -- otherwise false boundaries.

     - Done. (uses wildcards before and after and ORs together.) The
       filter needs to accept regex characters or prefix and post-fix
       with ".*".  Since things are quoted, right now nothing is
       actually matched.

     - Done. Since the log files provide post-mortem, there should be
       a way to view the files through the same httpd tool - a mode
       where it reads a single named counter XML file and then lets
       you browse it.  This will make it easy to find interesting
       views.

     - Done. The IndexManager should report the #of index views open
       concurrently.  Either sample once per second and take a moving
       average track the total number and compute the instanteous
       average per minute.
 
     - Done (reports the #of stores in the weak cache). Likewise, the
       StoreManager should report the #of open journals and index
       segments.

     - Done. Anything with "%" or "percent" in the name should be
       formatted as a percentage in [0.00:1.00].

     - Done.  The data service should report its configuration
       properties under "Info".

       Done. This should be done for the other services as well.
       Refactor the code in DataService, moving it into the counters
       package.

       Note: Servers should add their Jini configuration information
       as well.  This probably has to be done explicitly for the
       configuration items of interest.

     - Done. Compute average response time.  Throughput is 1/average
       response time.

     - Done. Add counters for #of index partition split, move, and
       join operations (OverflowManager).

       Done. Also report #of errors during asynchronous overflow
       processing.

       Note: There should also be a counter of the #of index
       partitions moved onto a data service.  However there is no
       place in the code to easily note this on the target data
       service since the move is made atomic by an action on the
       metadata service.

     - Done. Add counter to the write service that reports the #of
       tasks which have their locks and are actually doing their work
       concurrently (LockManager defines such a counter but we need
       its moving average not the instantaneous value).  This is the
       real concurrency of the tasks.  The #of active tasks in the
       write service is a red herring since those tasks could be
       waiting for their locks.

     - Done. Add per-process counters for GarbageCollectorMXBeans.

     - Done. (NanoHTTPD was not reporting errors in the serve() method
       anywhere and was failing to send back an error to the client.)
       For some reason a query for the hostname on host3 does not
       return the counters in the browser.  Response is fast both
       beneath that level at at the root.  Maybe the problem is in the
       /host/CPU and /host/Info counter sets - those appear to hang
       while /host/service is fine.... that does not seem to pay out
       either.

     - Done.  (I am assuming that Format was not thread safe - it was
       being used concurrently by the Sar collector and the pidstat
       collector, even with only one service). pidstat : Problem
       parsing [02:08:24 PM] as a time for input string "".  This is
       odd.  I can test this out and it works for the specified
       format.  And it is the only error reported for pidstat parsing.
       Ah.  Format is doubtless not thread-safe.

     - Done. Fixed issue where sar and pidstat would overflow the
       field, eating into whitespace to the right.  The data lines are
       now split based on whitespace after first skipping over a date
       field (based on the ISO date format).

     - Done. The per-process counters for linux are not being reported
       under "service" but instead directly under the service UUID.

     - Done. Group services under their service type in the counters.

     - Done (also fixed a bug where the LDS was not sending a join
       message to the LBS and modified notify(), warn(), and urgent()
       to invoke join() on the behalf of remote clients). The LBS
       should add counters for the host scores.  This will provide
       transparency in how it interprets the data from the various
       hosts.

     - Done. The client can discover the LBS and report data every so
       often.  This would result in redundent reporting when there is
       more than one client if the counter reflects the database
       state, but there is no harm in that.

     - Done. Could report the #of files read, #of triples processed,
       triples in the db, average throughput rate for that client (or
       all clients), etc

       - (**??) tps appears low as reported by the client to the LBS
         when compared to the final value computed by the client.
         This may be a function of the outstanding writers that have
         not yet completed, in which case the loader clearly needs to
         force the report of the final counter values when a load
         completes.

         Maybe this is reporting the upper bound for statements?  That
         does not make sense though since only deleted entries or
         views with an index segment cause the upper bound to be
         higher than the actual entey count.

       - Compute bytes per statement in the db (requires a db op to
         correlate the journal size with the #of stmts or #of terms)

       - Done. report success and errors from the concurrent data
         loader.

       - Done. incremental evaulate futures for the concurrent data
         loader.

     - Done. Report response time measures on the client, which will
       require a class similar to TaskCounters that is intimate with
       the ClientIndexView.  That will give a client perspective on
       the latency of tasks, which will aggregate across the data
       services that it uses and include the costs of RMI, in contrast
       to a data service perspective, which aggregates across the
       clients using that service and discount RMI.

       Note: The LDS does not use RMI - it submits tasks directly to
       the data service queues.

     - Done. Need to aggregate statistics for the partitions of an
       index as reported to the LBS for analytics.

     - Need to remove index partitions which are known to be stale
       from the LBS after a bit, or at least allow them to be hidden.
       The data will eventually grow beyond what can be held by an LDS
       if we do nothing.

     - Done. Show metadata about the open index segments in the
       IndexManager

     - Done. Send stale locator notices to the LBS and replace the
       counters (or nest them under) on the LBS when the index
       partition is reported as stale.

       Done. Note: having a local httpd for the data service would
       make it much easier to inspect the indices.
    
     - (**) The IndexManager should report the #of open indices.  We
       can have an exact count of that if we use a static atomic
       integer in AbstractBTree.
       
       Likewise, we can get the exact count of the #of open journals
       vs index segment stores and BTree vs IndexSegments using the
       same technique.

       Done. The statistics that are used by the overflow manager to
       compute which indices are move candidates are not being exposed
       via the counters to the LBS.  This includes all of the
       per-index bytes read, bytes written, etc. data.

     - Done. The IndexManager should report the index partitions on the
       data service, at least until this exceeds 100s of indices.
       This should be done not via counters but rather via the httpd
       service itself making an RMI request to the data service and
       listing out the named indices. Present additional information
       when the service is a metadata service, e.g., by listing out
       the tuples of the index, which are in fact the locators for the
       index partitions.  Also, provide some aggregation over the MDI,
       including the total #of partitions and tuples.

     - The counters are overflowing to days before midnight.  Check
       the locale and see when timestamp causes an overflow to the
       next hour and the next day in some unit tests.

     - Done. When restoring the LBS counters from XML, the history on
       the counters is being ignored.

     - (****) Make it possible to have more than 60 minutes in the
       buffer but still overflow after 60 minutes onto the hours.
       This will allow a longer reachback at a given level of
       aggregation.

     - Add UI elements to set the filter(s), depth, decimalFormat,
       etc.  These should be a FORM with a GET action.

     - May be loosing some samples by running multiple typeperf's at
       once.  Explore.  If true, then trying combining all w/in same
       JVM using reference counter for process or identifying one
       process in the JVM which will have responsibility for those
       counters.

     - syslogd integration so that I see ERROR and FATAL messages for
       the hosts in the federation.

     - Done. Add option to NOT run typeperf and use for the unit tests
       of the services when performance counters are not required.

     - Done. Add reporting by the client on the indices that it is
       using.

     - Done. Add reporting to the concurrent data loader for #errors.

     - Done. The CDL tps counter needs to stop counter time once the
       load is complete.  As it is the rate continues to drop with
       elapsed non-load time.  This makes the value reported to the
       load balancer wrong! (Even the value available from the client
       is wrong since it can be off by up to 60 seconds of load time).

     - Done. Problem w/ correlated view of counters. Was plotting a
       String[] rather than its elements.

     - Add counters to the client index view showing the times for
       each operation and also showing the times for querying the
       metadata index to split an key[] operation or map a key-range
       operation.  This will be help identify if/when the MDI is a
       bottleneck for the client.

     - On a long run I begin to see assertion failures in
       com.bigdata.counters.History#859 ( assert size <= capacity :
       "size=" + size; ).  The size appears to grow by one every
       minute, causing assertion failures once it exceeds the buffer
       capacity.  (The run may have been out of disk space by the time
       these errors emerged.)

   - Admin UI
   
     - It would be nice to be able to drill down into the index data,
       but that should be an admin UI not the counters UI.

     - Expose the known triple stores, a view on the global sparse row
       store, etc.

     - Offer commands to force overflow of a data service.

   - Sparse row store support.

     - JSON API

       - Add a web application that let's people easily write on or
         read from the sparse row store using JSON or the like.
    
       - It should be easy to view and modify the data in the global
         row store, which is where locatable resources store their
         configuration metadata.

       - The JSON API should be compatible to the extent possible with
         HBASE and GAE.

       - This web application will have to be distributed in order to
         eliminate bottlenecks.  One approach is to re-direct HTTP
         clients to an embedded web service co-located with the data
         service on which the row resides.  HTTP clients can continue
         to address that server until they receive a redirect.

     - Add a BLOB reference column type.  There are at least two
       design options for this.  I think that we should support at
       least (1) and (2).

       (1) the blocks are stored locally and hence are always
           available from the same data service as the BLOB reference
           column value - this might limit the maximum effective blob
           size (in bytes) since the data will have to fit in the same
           index partition and hence be co-located on a single host.
           In fact, the blocks will be in the same index segment as
           the column value once the journal overflows.  One advantage
           of this approach is the block updates can be atomic with
           block metadata updates - a feature that is not otherwise
           available without full transactions.
       
       (2) the blob reference includes the name of the scale-out index
           on which the blocks for that blob are stored - in this
           model the blocks can reside anywhere and splits of the
           blocks will have no relevance to splits of the metadata.
           This also makes it easier to locate the partitions of the
           index containing the blocks on data services that are
           specifically provisioned for large data blocks.

       (3) the blob reference contains the primary key for the blob
           and the blob is stored either in the same index or in
           another index.  I am not sure that this variant adds value
           over (1) and (2).

     - Refactor the BigdataRepository to use the BLOB reference type.

   - IndexSegment

     - Done. Verify that there is an atomic commit point for the
       IndexSegment so that partial index segment writes can be
       recognized.

     - Done. The addrLeaves and addrNodes can not be expressed as a
       single long since they are regions spanning many records and a
       long would limit their byteCount to whatever was allowed by the
       offsetBits.

     - Done. The logic to buffer the nodes was actually examining the
       extent of the leaves.

     - Done. Added checksum to the index segment store checkpoint
       record.

     - Done (the problem was failing to flush the write cache to the
       disk before initiating the channel to channel transfer - since
       the data were not on the channel they naturally were not being
       transferred.)  Stress test of U100 and very large runs of
       TestIndexSegmentBuilderWithLargeTrees (m=32, nentries=m**4)
       cause corrupt leaves in an index segment build.

     - Done. Modify IndexSegmentBuilder to support fast reverse scan,
       at least in the data and in DumpIndexStore.

     - Done. IndexSegmentBuilder should be refactored to implement
       Runnable/Callable.  The ctor can do the setup and the index
       build will run in run()/call().  The return can be a status code
       for the operation or statistics on the operation.  Throw an
       exception for an error.

     - Done. Modify IndexSegmentBuilder to support fast forward scan,
       at least in the data and in DumpIndexStore.

     - An index segment build that could operate without the actual #of
       entries would avoid one pass over the data.  See how expensive
       that traversal is (it is done in one location) and decide
       whether it is worth trying to operate without that information
       on hand.  Eg, by using the upper bound on the entry count and
       then allowing leaves and nodes to underflow.

     - Done. Support transparent byte[] <=> value (de-)serialization
       using a serializer object associated with the index metadata.

     - Done. Add Map and Set impls. based on the BTree.

     - Done (IUpdateStore). I need to create an interface extending
       IRawStore, put those methods on that interface, and then declare
       that interface on TemporaryRawStore in order to be able to
       access these methods.

   - DiskOnlyStrategy

     - Done. write tests of transferTo.  I did find a bug in
       writeAll(), but that was not the problem (it was writing each
       pass at the same offset in the file when a write required
       multiple IOs).

     - Done. Refactor to create a Journal using a Temporary BufferMode.

     - Done. Refactor DiskOnlyStrategy to permit lazy creation of the
       backing file.

     - Done. Refactor of TemporaryRawStore to use DiskOnlyStrategy with
       lazy creation of the backing file.

     - Done. Found a bug in DiskOnlyStrategy where it was always
       reading a record three times....  Probably there was little
       performance impact since the read would have come from the OS
       cache after the first time, but still....

     - Evaluate effect of the write cache capacity.  If 1M is as good
       as 10M then just use the DirectBufferPool for the write cache
       for the live journal, which will simplify some things.

     * Add counters reporting the #of bytes written/commit.

     * Test suite for Temporary mode journals.

   - DirectBufferPool

     - Done. Static config via System#getProperties() for the direct buffer pool

     - Done. Counters for reporting out the pool state.

     - Done. Report "bytesUsed" for the DirectBufferPool.

   - Transaction support.

     - Overhaul transaction processing and support full, 2-/3- phase
       transactions

     - A problem is reported by StressTestConcurrentTx.  Revisit this
       when I overhaul the full transaction support.

     - Transaction identifiers need to be "symbols" that respect the
       timestamp ordering for historical reads and the transaction
       start time.  Since the timestamps are discrete it is possible
       that the factory will have to wait until it can assign a
       transaction identifier for the interval implied by some desired
       historical start time.

     - ** Change tx timestamps to negative and use positive timestamps
       for historical reads.  Changes to AbstractTask, ITx,
       ITransactionManager, StoreFileManager, IsolationEnum, and the
       post-processing tasks.  This will greatly simplify thinking
       about historical read operations since they will simply use the
       actual commit time while transactions will use a free
       (-timestamp) value selected by the transaction manager.

     - AbstractResourceManagerTask - documents a potential problem
       with MDI updates without 2-phase commits.  Look into this
       further and see if this problem can be addressed without using
       a full transaction.  If not, then we will need to use a full
       transaction to avoid this issue.

  - Support hash partitioned indices.  The index would be marked in
    the IndexMetadata as being hash partitioned, including the #of
    index partitions (N) and a hash function (can be defaulted).  A
    data service UUID is assigned to each index partition.  Write a
    ClientHashPartitionedIndex (vs the ClientIndexView, which could be
    renamed as KeyRangePartitionedIndex)

  - Iterator refactor

     * Drive SLICE (offset as well as limit) through the IRangeQuery
       API and the ITupleIterator implementations so that we can
       efficiently process a slice without having to materialize the
       elements that lie before the desired offset.
       
       This will also require changes to the AbstractAccessPath,
       specifically it must drive both the offset and limit through to
       the ITupleIterator.

     * Change the striterator heirarchy into an implementation
       heirarchy (StriteratorImpl) for co-varying generics and a use
       hierarchy (IStriterator and Striterator) in which only the
       element type is generic. This should be significantly easier to
       use and understand.

     - Modify the procedure logic to abstract a 'next key/val'
       iterator using a shared buffer for de-compression in order to
       minimize heap churn on the data server.

     - Support copy in/out of keys and vals in lookup(), insert(),
       remove(), and rangeIterator so that we can (a) be more
       efficient in handling keys and vals by copying; (b) handle keys
       and vals that are byte aligned or bit aligned in the node or
       leaf; (c) reduce GC by converting to a compacting record for
       the node/leaf; and (d) expose the version counter and deletion
       marker for fused views of indices with isolation.

     - Turn off sendVals for rangeIterators if we recognize the value
       serialized as the NoDataSerializer?

     - Write unit test for read-consistent semantics for key-range,
       key-array, and rangeIterator (PartitionedRangeQueryIterator).
       The test would perform concurrent writes and verify that those
       writes were not visible to the operation.
       
       A stress test variant should also force concurrent overflow
       operations and verify that the index is reading from a
       read-consistent view of the metadata index and hence does not
       see the locator updates.

   - ScaleOutTripleStore

     - ConcurrentDataLoader

       - ? stagger the entrance of the first few tasks to help stagger
         the nature of the their work.

       - retry long running tasks (map/reduce style).  In fact, this
         already happens because the ClientIndexView times out the
         request to the data service which results in a
         CancelledException and the task is marked as an error and
         then retried.

       - More cleanup.

       - Reconcile with m/r architecture and bigdata repo.

   - OverflowManager

      - Could optionally convert from  a fully-buffered to a disk-only
        store  in  order to  reduce  the  memory  footprint for  fully
        buffered  stores,  but in  that  case  this conversion  should
        happen once asynchronous overflow handling was complete.

   - StoreManager / IndexManager

      - Done. Add counter for bytes under management on the
        StoreManager.  I want to see bytes placed under management,
        bytes for stores that have been deleted, and bytes for stores
        that are remaining.  It would also be great to see the bytes
        remaining on the volume where the data are stored in the same
        view.

      - Modify  LRU  to  purge  entries  older than  a  specified  age
        (including an asych  daemon thread to make sure  that they get
        purged even if the LRU is not being touched).  Do this for the
        index segment cache in the IndexManager as well.

      - Done. Better concurrency for openIndex, openStore, getJournal,
        and getIndexOnStore

      - Modify WeakValueCache to use ConcurrentHashMap and support an
        atomic putIfAbsent operation.  This will reduce the latency
        imposed when we need to re-open an index segment from a store.

      - Should recognize a "disk full" situation and shutdown the data
        service cleanly.

   - LockManager

       - Use a WeakValueCache to purge unused resources.  The size of
         its internal map from resource name to resource queue will
         grow without bound on a data service as index partitions are
         split and moved around.  There are notes on this issue in the
         LockManager class.

   - DiskOnlyStrategy
   
     - Done. Lazy creation of the backing file.

     - Done (No performance change for small stores - I still need to
       review the data for large stores.  Of interest, the write cache
       on a large store is nearly never a hit when trying to read a
       record - this suggests that a read cache will be of no
       benefit).  An LRU read cache for records.

       This could be a big win for the DiskOnlyStrategy.  Either make
       this its own layer that can be interposed between the journal
       and the DiskOnlyStrategy or add directly to the
       DiskOnlyStrategy since a read cache is not required for the
       fully buffered modes. Regardless, allow configuration of the
       cache size.

       Also, efficient nextLeaf could improve read performance by
       reducing node reads.

       Write through to the write cache and flush through to the disk.
       On read, test the read cache.  If not found, read the write
       cache, then the disk.  These are simple layering semantics.

       Use an LRU with a capacity of ~5k records.  The records are
       read-only so we do not need to worry about a canonicalizing
       mapping.

       The read cache is specific to a journal.  Each journal gets its
       own read cache.  Historical journals might have a smaller read
       cache capacity, or maybe 2k records is enough for any journal.
       Experiment and find out.

       (***) Look at the effect [host3] on readSecs, on the ratio of
       readSecs to writeSecs, and on IOWait, especially as the size of
       the journal grows.  If the LRU is not paying its way then
       disable it by default.

     - CounterSets

       - Add counters designed to give insight into whether the write
         cache tends to full up completely or only partly before the
         next group command and the #of bytes that tend to be written.
         What I want to understand is whether the cache is too large
         and whether an asynchronous of the cache to the disk would be
         a benefit.

	 *** #bytes/commit (measured delta in offset from commit to
              commit).

	      Also, #flushes / commit - when ~ 1:1 the write cache is
	      at least large enough.

	 Note that writes which would exceed the remaining cache size
         cause the existing cache to be flushed while writes that
         exceed the cache capacity are written directly to the disk -
         the cache itself is always dense in terms of the bytes
         written on the address space.

   - Done. Full text indexing for KB.

       - Done. Analyzers are not thread-safe.

       - Compare performance with lucene and mg4j on indexing and
         search, at least for the RDF DB application.

       - Try out an mg4j integration for an alternative text indexer
         and search.

   - Done.  Either never retry an error task when the queue is likely
     to be full or make the retry itself robust.  Otherwise the CDL
     risks reporting fatal error for a task which could have been run
     successfully.

   - Done (uses a static pool). Provide option to pass in a write
     cache buffer for a temporary store and use that buffer as the
     in-memory store before it overflows onto the disk.

   - Consider dropping the BasicRioLoader, PresortRioLoader, etc.  All
     of the benefit is in the use of the StatementBuffer.  These
     loaders just obscure the RIO mechanism and make them harder to
     configure.

     The DataLoader might be a utility class.

     The ConcurrentDataLoader is certainly a useful utility class.

   - Done.  Correctness testing for scale-out with index partition
     split, move, and join.  See services/StressTestConcurrent. It can
     be parameterized for this purpose.
 
   - write performance test drivers and run on cluster.

      - rdf concurrent query (rdf lubm is not designed to test with
        concurrent loads).

      - (****) Write script to allocate services to nodes.

        - N data services; 1 MDS; 1 LBS; 1 TS, etc.

	- The script needs to start the services on a LOCAL disk on
          each machine (I am currently setup on NAS so that means the
          DISK is REMOTE).  This means replicating the environment
          onto the local host (at least the configuration) and then
          starting the service.  The classpath could be resolved on
          NAS or replicated onto the local host and resolve there. (I
          just need to copy [policy.all,
          bigdata-rdf/src/resources/logging/log4j.properties, and
          bigdata-rdf/src/resources/config/standalone ->
          .../src/resources/config/standalone {create the directory
          path first}].  I could also copy the classpath resources,
          but presumably they will be fetched quickly enough and
          become stable - or maybe not?

	- (***) Get clusterondemand account.

	- Support downloadable code in the configuration, including a
          an optional security model.

        - Make sure that yum-updatesd does not run on the servers.  It
          absorbs an entire CPU for quite a while.

	- Still an annoying problem with the service names as
          displayed by the jini browser....  The problem is that we do
          not have an httpd server fronting for the JARs and that the
          CODEBASE is not being set.
 
============================================================

	Looks like virtuoso is running a clustered triple store!

	http://virtuoso.openlinksw.com/wiki/main/Main/VOSArticleLUBMBenchmark

	http://www.openlinksw.com/weblog/oerling/?id=1336

	http://www.openlinksw.com/weblog/oerling/?id=1335

	http://docs.openlinksw.com/virtuoso/clusterprogrammingsqlexmod.html

============================================================

    - Done. (There was a fence post when the releaseTime was less than
      the first commit time for any journal.) Saw "no data for release
      time" error.  Twice.  This will prevent overflow from succeeding
      since it occurs during synchronous overflow.  I have changed the
      configuration for the data services to set [minReleaseAge = 0],
      which is probably more appropriate for this test, but this needs
      to be debugged.

    - Done. Get the basic overflow tests running.

    - Done. ClientIndexView : retry count exceeded - need to report
      the underlying cause(s)

    - Done. (Added more detailed warnings and made robust to such
      failures) Fence post for DefaultSplitHandler (#ntuples == 0)

    - Done (DataService needed to notify() the LBS during startup).
      Jini client is not reporting counters on either machine.  The
      problem is the client configuration.

    - Done. Dynamically refresh the httpd view for the data service to
      make the counter set for the index manager live.

	Done. Modify to report the counters retained by the
	concurrency manager as they are longer lived.

	Done. Report partition metadata for the view, including the
	checkpoints for the index segments.

	Done. Report stale locators.

	*** I am not seeing StaleLocatorExceptions for read-committed
            views, at least not in the counter set generated by the
            concurrency manager.  Part of the problem is that the fast
            overflow rate is making the views update very quickly.

============================================================

**** The group commit behavior when interrupted during shutdown needs
     to be reviewed with respect to the recent changes to AbstractTask
     and Name2Addr.

ERROR: 397768 pool-1-thread-559   commitCounter=397 com.bigdata.resources.SplitIndexPartitionTask$AtomicUpdateSplitIndexPartitionTask [test_POS#18, test_POS#40, test_POS#41] 0 waitingOnCommit  com.bigdata.journal.WriteExecutorService.groupCommit(WriteExecutorService.java:1102): Problem with commit? : java.lang.InterruptedException
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1878)
	at com.bigdata.journal.WriteExecutorService.waitForRunningTasks(WriteExecutorService.java:1230)
	at com.bigdata.journal.WriteExecutorService.groupCommit(WriteExecutorService.java:1024)
	at com.bigdata.journal.WriteExecutorService.afterTask(WriteExecutorService.java:655)
	at com.bigdata.journal.AbstractTask.doUnisolatedReadWriteTask(AbstractTask.java:1638)
	at com.bigdata.journal.AbstractTask.call2(AbstractTask.java:1546)
	at com.bigdata.journal.AbstractTask.call(AbstractTask.java:1437)


============================================================

This indicates passing an old locator that could not be found in the
MDI.  I've modified the code to report back the old locator in the
exception.

Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:205)
	at java.util.concurrent.FutureTask.get(FutureTask.java:80)
	at com.bigdata.service.MetadataService.splitIndexPartition(MetadataService.java:280)
	at com.bigdata.resources.SplitIndexPartitionTask$AtomicUpdateSplitIndexPartitionTask.doTask(SplitIndexPartitionTask.java:805)
	at com.bigdata.journal.AbstractTask$InnerWriteServiceCallable.call(AbstractTask.java:1829)
	at com.bigdata.concurrent.LockManagerTask.call(LockManagerTask.java:325)
	at com.bigdata.journal.AbstractTask.doUnisolatedReadWriteTask(AbstractTask.java:1605)
	at com.bigdata.journal.AbstractTask.call2(AbstractTask.java:1546)
	... 6 more
Caused by: java.lang.NullPointerException
	at com.bigdata.mdi.PartitionLocator.equals(PartitionLocator.java:231)
	at com.bigdata.service.MetadataService$SplitIndexPartitionTask.doTask(MetadataService.java:502)
	... 10 more

============================================================

Observed once: clearly a timing issue.

ERROR: 62 pool-1-thread-5         com.bigdata.resources.StoreManager$Startup.run(StoreManager.java:895): Problem during startup? : java.lang.IllegalStateException
java.lang.IllegalStateException
	at com.bigdata.resources.ResourceManager.getConcurrencyManager(ResourceManager.java:340)
	at com.bigdata.resources.StoreManager$Startup.start(StoreManager.java:963)
	at com.bigdata.resources.StoreManager$Startup.run(StoreManager.java:888)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:417)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)
	at java.lang.Thread.run()V(Unknown Source)

============================================================

1. Run U10, U100 on host3.

2. Write script and run U10, U100, U1000 on host{1,2,3}.

   - Done. pidstat is reporting under /host/client/UUID not
     /host/service/iface/UUID

   - Done. sar/pidstat parsing problem.

   - verify syslogd reporting and configure on host{2,3}.
   
     I need to look further into how the stuff gets logged by syslog
     and what, if anything, needs to be configured for this to work.
     This is only interesting to obtain a combined log of the services
     - and primarily to obtained a combined log of their ERROR level
     messages.

   - Done. reduce log levels (review log4j config).

   - Done. Reduced the branching factor default for the indices as it
     was overflowing the maximum record size.

   - document setup.

   - **** jini class setup, httpd, and codebase property.
   
   - Done. The various server setups either all need to be copied into
     appropriate locations on the host on which they will run or they
     need to specify a dataDir that is local to the host on which they
     will run, e.g., /var/bigdata/DataServer0

   - Done. verify jini using nio.

   - timestamp service should notify the load balancer.  this will be
     extended to be the transaction service and that will have things
     to report.

   - Startup should be event driven.

      - The server startup for bigdata should be more event driven.
        You should be able to discover jini itself and then any of the
        services in any order.  some services clearly must wait for a
        join (e.g., the client and the data service must wait for the
        timestamp service) while others can come and go as they like
        (if the load balancer is not there then things should run
        anyway but centralized reporting will not work and index
        partition moves will not happen).

      - Done? Modify to have an observable event or callback that
        assigns the service UUID and that indicates when the resource
        manager is running and refactor the LDS and DS startup logic
        to use that to configure the reporting of counters and an
        optional httpd service (at least for the LDS). The relevant
        Jini method is ServiceIDNotify().  For the moment I have
        disabled the httpd for the LDS.

   - Done. review jdk (1.6.0_03), sysstat (8.0.3) {version 7 on
     host{1,2}, solved using rpm -U to update rather than install},
     /etc/hosts, /etc/fstab{/NAS vs /nas}, jini (not really required
     on all hosts since we are bundling the jars) for consistency.
     also emacs install.

   - Done. problem with multicast. solved using unicast to
     host3. (multicast issue on the servers has since been resolved.)

   - Run multiple clients as well as multiple servers specifying
     nclients=3 and clientNum={0,1,2}

   - (*) Ala log4j, use a set named property model for property
     values.  This will let us warn people when the property value is
     not defined.
   
LDS U10 13.6k

JF host3 U10 7.7k

JF host3 U10 startAll 6.7k

====================
jrockit:

LDS U10 SIDS=true nthreads=10 bufferCapacity=100000 wrkstn : 6.6k

LDS U10 SIDS=false nthreads=10 bufferCapacity=100000 wrkstn : 7.2k

LDS U10 SIDS=false nthreads=10 bufferCapacity=100000 wrkstn 1G : 7.5k

LDS U10 SIDS=false nthreads=20 bufferCapacity=100000 wrkstn 1G : 8.4k

LDS U10 SIDS=false nthreads=30 bufferCapacity=100000 wrkstn 1G : 7.8k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 wrkstn 1G : 8.6k

LDS U10 SIDS=false nthreads=20 bufferCapacity=100000 wrkstn 1G noText : 10.8k, 11.6k, 11.3k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 wrkstn 1G noText : 11.6k, 12.7k

LDS U10 SIDS=false nthreads=30 bufferCapacity=200000 wrkstn 1G noText : 11.8k

LDS U10 SIDS=false nthreads=40 bufferCapacity=200000 wrkstn 1G noText : 11.9k

LDS U10 SIDS=false nthreads=20 bufferCapacity=300000 wrkstn 1G noText : 12.0k

LDS U10 SIDS=false nthreads=20 bufferCapacity=400000 wrkstn 1G noText : 12.3k

LDS U10 SIDS=false nthreads=20 bufferCapacity=500000 wrkstn 1G noText : 12.7k

LDS U10 SIDS=false nthreads=20 bufferCapacity=300000 wrkstn 1G : 9.1k

LDS U10 SIDS=false nthreads=30 bufferCapacity=1000 wrkstn : 4.5k

jdk 1.6.0_03 -server

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText : 14.5k, 14.4k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText localData : 14.6k, 15.0k

LDS U100 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText localData : 16.4k
	 Run saved as bigdata-rdf/host3-U100-LDS-countersfinal.xml (13M stmts, 3M terms)

LDS U100 SIDS=false nthreads=20 bufferCapacity=200000 host2 2G noText localData : 16.2k

LDS U1000 SIDS=false nthreads=20 bufferCapacity=200000 host2 2G noText localData : 11.4k
    #terms=32,905,188; #stmts=133,613,894; rate=11412; 68G journal.
    Run saved as: U1000-host2-countersfinal.xml

    - Done. Add moving average w/ and w/o locks.  Perhaps there is a
      queue but it is before the locks are obtained?

      Done. Also add the commit wait time and commit service time
      measures.

    - The LockManager could report the queue size and queue waiting
      time per resource.  This would let us know which resources are
      the bottlenecks.

    - Done. The LockManager could report the total #of waiting tasks,
      which is not showing up anywhere right now.

    - (*) Per-procedure/index/isolation counters {#submitted,
      #completed, task service time (queue waiting times are always
      shared by a queue but lock waiting times and task service times
      can differ by task)}.

(**) Note: Compare the performance for LDS against 16k tps with
     [autoFlush=false] (before sids and before the text indexing).
     Experiment more with buffer sizes, combining writes, etc.

============================================================

Main issues:

============================================================

(*) map/reduce processing.

    (-) If the ConcurrentDataLoader was a map/reduce job then I could
        start the whole thing by running a single master.  I would of
        course have to have map and reduce services running on the
        cluster.

    (-) ...

============================================================

(*) Index and other performance tuning.

    (-) Replace use of "immutable nodes" throughout.

    (-) Run an Experiment driver with variables for the branching
        factor, node compression, leave compression, and custom SPO
        compression.  Examine performance when index segments are
        built from the views as well.

    (-) The best branching factor for an Index Segment is probably
        limited by the best branching factor for query (or closure)
        benchmarks.  For the triple store, this looks like it is 256
        since closure performance takes a beating after that.

    (*) Try co-threading the forward index writes for the statements
	with the reverse index writes for the term identifiers.

============================================================

(*) Scale-out performance

    - Estimate parameters for the scale-out model.

      Note: Concurrency and throughput SHOULD NOT increase as indices
      are broken down into index partitions on a single server since
      we are CPU bound in the unisolated index tasks.  However, an
      increase SHOULD be observed with or without index partition
      splits (and with or without overflow) when running on more than
      one host since we have more CPU resources.

      Note: Caching by the disk controller, the OS, and the B+Tree
      keep the IO costs quite low when the depth is small and the
      B+Tree is CPU bound in that regiem.  The B+Tree does become IO
      bound as the depth of the B+Tree increases.

      Find the LDS baseline for U100.

      Find the EF baseline w/ one data service and no overflow for
      U100.

      Find the EF baseline w/ two data services and no overflow for
      U100.      

      Find the intercept for a linear scale-out model using JF with
      two data services (and hence RMI) on U100 w/o overflow.
      
      Find the slope of the linear scale-out using JF where one of
      data services is located on a second machine, still w/o
      overflow.

      Done. (Multicast configuration issue was resolved.)  There is
      still a problem with multicast which is preventing scale-out
      runs.

      Note: Ideally the client will also be distributed but that is
      not critical to proving the point as the client is faster than a
      single host can service.


All runs:

    -DtextIndex=true -DstatementIdentifiers=true -Xmx=2G -Dnthreads=20
    -DbufferCapacity=200000

    Note: EF runs use -DoverflowEnabled=false

    Note: JF runs configure overflowEnabled=false in
    bigdata.properties for DataService4 on host3.

LDS-U100-host3-noText-noSids : 16784 (798910 ms (13m)) 13M stmts.

LDS-U100-host3 : 16783

EF-U100-host3-1DS-noOverflow: 12877

EF-U100-host3-2DS-noOverflow: 11332

JF-U100-host3-1DS-noOverflow: 8528

JF-U100-host3-2DS-noOverflow: 

JF-U100-host23-2DS-noOverflow: 

	*** Why does EF run so much slower than LDS?  Is the overhead
            the MDI?  The cost of setup for the client index
            operations (ClientIndexView vs DataServiceIndex)?
            Removing the existing journal files (try the EF runs with
            the [test] directory pre-deleted)?

      Retest all of the above on U1000 (requires use to use host1 or
      host2 for the additional disk space).

LDS-U1000-host2
EF-U1000-host2-1DS-noOverflow
EF-U1000-host2-2DS-noOverflow
JF-U1000-host2-2DS-noOverflow
JF-U1000-host12-2DS-noOverflow

============================================================

(*) Dynamic index partitioning

    - What cost is associated with overflow processing?

      Evaluate for:

      (a) EF with one data service;

EF-U100-host3-1DS-5M: 5965

	Note: This used a 5M initial extent and 5M maximum extent.
	There were 15 overflows in 46 minutes (a stress test run).
	The initial and maximum extent were configured in the test
	suite code.  Run was successful.  The only reported errors
	were index partition split tasks that were still executing
	when the run was terminated.

EF-U100-host3-1DS: 5922 (this is not the final tally since the client
		         died during shutdown).

        w/ 200M initial extent and 200M maximum extent.

	--------------------

      (b) for JF with one data services with on one machine; 

JF-U100-host3-1DS: 5543

	Note: This run came close to using all RAM on the machine
	80%).  The RAM was mostly going to the sole data service.  In
	fact, the data service RSS was 2G, which is maxed out.

	Note: Some overflow tasks were cancelled! (timeout).  

	Several index partition split tasks began but all were
	cancelled due to timeout.  I have increased the default
	timeout and I will run again.  I have also added counters to
	report failed and cancelled async overflow tasks.

	* Once splits start, look for the overhead of the MDS (there
          is still an MDS overhead since we need to find the locator
          to decide that there are no splits)

	* Look at the LBS host and service scores.

	* Look for index _moves_.

	* Network counters begin to become interesting.

	--------------------

      (c) for JF with two data services with on one machine; and

JF-U100-host3-2DS:

	--------------------
      
      (d) for JF with two data services on two machines.

JF-U100-host23-2DS:  ******** RUNNING NOW *********

	Note: I am only running a single client for this test.  The
	client is on host3.  This should be Ok since we are data
	service bound.  If the client can not keep up with the data
	services on two machines then that's good news :-)

	--------------------

      Choose runs where we have the data w/o overflow from above.

      Do at least one run with post-facto validation turned on.

      Note: It is important to also save the service nohup.out files
      since they show interesting data about the asynchronous index
      partition overflow tasks and any errors reported by the service
      during such tasks (those errors do not make it back to the
      clients since the tasks are run by the services themselves).

    --------------------

    Note: It is best to run EF with one data service to test index
    partitioning questions and JF to test marshalling, robustness, and
    index move questions.

    Running JF U100 on host3 right now to get some data on queue
    behavior with dynamic index partitioning.  Some questions are:

    - Change the default split point and verify build and split
      behavior on both the workstation and the server using U100 and
      one data service.

    - Do I need to increase the client timeout for Jini?  It seems
      that I probably do.  Perhaps double it to 40 seconds?  Or
      perhaps make the default much longer (1 minute, 5 minutes or
      infinite) since tasks could be queued up.

    - Are good decisions being made with regard to build and split of
      index partitions?

    - Are good decisions being made with regard to index partition
      moves?

    * Configure to hold more indices open per data service.  This
      should be done in the bigdata.properties files for each data
      service.

    * Observe the metadata service response time and verify that it
      does not become a bottleneck since the current implementation is
      NOT caching.

    * Verify that we use read-committed or read-historical operations
      whenever possible (e.g., for asynchronous overflow processing,
      joins, metadata service reads, etc).

    - Should report the #of tasks, action on each index, and the
      duration of overflow processing for each event, but that event
      oriented data does not fit well within the counters model.

(*) Load-balancing

    * Watch the load balancer and see how host utilization and service
      response time change as the run progresses, for different #of
      client threads, and as index splits occur, and as index moves
      occur.

    * Review the LBS host and service scores.  Can they predict host
      and service load well enough to move index partitions around
      without the host-based physical disk counters under linux?

    - Try U10000 reading the data from NAS with 2 clients, 10 threads
      each and 2 or 3 servers.  See if scale-out holds as we increase
      the data size.  The point of comparison is the 1B run that we
      did on server2 (single host, non-scale-out architecture,
      non-concurrent load).

    - Delay start of some data services, either on each host or on one
      of the hosts and then see how the load changes once we start
      additional data services (this could be expanded into a variety
      of hardware add and hardware fail tests).

============================================================


- Scale-out scripts

    - Script to collect nohups, config files, and counters in a
      directory and tarball for post-mortem.

- Service and host statistics:
      
   - **** There are no majorFaultsPerSec or percentFreeDiskSpace
          numbers on a per-host basis so only defaults are being used
          for those values when computing the host score.  I need to
          write a new SAR collector to get those data.

    ** The per-host physical disk counters for linux are not being
       collected, including the major page faults per second for the
       _host_.  This is one of the primary clues so we need that.

       Write the Sar, iostat, or vmstat utility to collect these data.
       This is a bit more complex under Linux since the data are
       reported by device and the relationship of the devices to the
       file system should be explicated.

       Use [df] to report the % free space remaining?  There should be
       one value for the logical disk (perhaps), and there should be a
       report of the % free space remaining on the volume on which the
       dataDir is located and the volume on which the tmpDir is
       located.

       Note: The StoreManager also reports the free space on the
       volume for both the data dir and the temp dir.

   *** IP Addr shows up for host2 but not host1 or host3.

       192.168.20.27 is showing up as a host for DataServer3 but no
       host statistics are being reported for that IP addr (they are
       reported for the hostname instead) with the result that the IP
       addr is getting the default values for the metrics used to
       compute the host scores.

       There is still the problem with how that IP addr is getting
       reported and with whether or not any services are understood to
       be running on that host (they are not).
       
       *** A host without services running on it effects the ranking
           of the hosts and the host with the highest score. Does it
           also effect any recommendations made by the LBS?

   - Done. Modified host score to interpret high IO Wait as high
     utilization.

   - Done (mostly). The counter names need to be symbolic to avoid
     edits causing counters to not be found during analysis.

- Overflow processing

   *** If overflow processing is taken so long then there is a
       problem.  Perhaps there needs to be an alternative that lies
       between an index partition "copy" and a full compacting build,
       e.g., an incremental build that lets us discard the old
       journal.  It would generate an index segment having just the
       last committed state for the BTree absorbing writes for that
       index partition on the old journal.  The view of the index
       partition on the new journal would be updated when the task was
       complete.  A full build would have the effect of combining the
       history from several such incremental builds.

       Likewise, we may need to trade off how many splits we perform
       choosing to do incremental builds instead to keep down the
       total processing time/costs for asynchronous overflow
       processing.

       Can an analysis of the queue concurrency with locks held help
       decide whether some index partition should be moved to another
       data service?

   - Done. Asynch overflow needs to report the index and task for each
     failure as part of the exception.

   - Done. Metadata service needs to report the scale-out index name
     (or the index partition name) for "No such locator" errors.

   - Done. Add the createTime to the live journal counters.

   - Done. Move the LBS counters from /var/log/bigdata to
     /var/bigdata.  Update scripts in CVS and on the server and the
     script documentation.

   * It would be useful to have AND as well as OR semantics for
     "filter=".

   * Change the TITLE for the httpd counter view to the hostname and
     the last component of the path, e.g.:

	  hostname  ... serviceIFace ... lastComponent

     Or use the last 60 characters of the path, etc.  The point is to
     have titles that are somewhat easier to figure out.

   * It could be useful to have a view by serviceIface rather than
     host.  This could be assembled dynamically by a scan of the
     services across the hosts.

   - The IndexManager view of the LBS needs to aggregate some key
     statistics by index across the index partitions including the #of
     index entries on the data service and the time spent on the index
     (perhaps broken down by IO, serialization, key search, etc., but
     definately the aggregate time).  I am just not getting enough
     information from this view and digging down makes it too
     difficult to get the gestalt state of the indices without copying
     a correlated view of the counters into Excel.

   - Done. Review the per-service scores, but I really need to have
     more than one service on a host for this.  It should probably be
     using a response time measure, e.g., averageQueuingTime.

   - Done (problem was timestamp parsing since only the time of day
     was being reported, not the UTC time - it now uses the system
     clock). Now I am not seeing any host CPU scores aggregated by the
     load balancer.

   - Done. The normalized [score] is not being computed for hosts or
     services (it is always zero).

 - TemporaryRawStore abuse.  
      
   * BigdataClient temporary raw store to cache information locally.
     This should periodically be dropped as it can grow without bound.

   * The StoreManager uses either a temporary raw store for the
     indices it maintains for the resources that is is managing.

 - Resource locators

   - Finish the TestDefaultResourceLocator

   - Address issue with read-committed BTree views.

============================================================

Index allocation:

    The initial index allocation appears to assign much more of the
    effort to host3.  Either try random assignment or reconsider the
    2-host assignment behavior.

log files:

    The log files do not interleave the logs by timestamp.  Clearly
    there is no way to do this exactly in a distributed system.
    However it might be done better if it all went through syslog.
    Rather than an elapsed ms (or in addition) I need the UTC time in
    a field that I can readily identify.  With that I could even merge
    sort the logs together.

DataServer3:

The problem here is that there is no entry under the leftSeparatorKey
for the partition in the MDS.  I am not clear why.  I have added a
test for this condition and an exception which will provide more
information.

Caused by: java.lang.NullPointerException
	at com.bigdata.mdi.PartitionLocator.equals(PartitionLocator.java:231)
	at com.bigdata.service.MetadataService$MoveIndexPartitionTask.doTask(MetadataService.java:803)

What led up to this was:

testSPO#0	 = willBuild(name=testSPO#0)
testterm2id#0	 = willSplit(name=testterm2id#0)

and

testSPO#0	 = willMove(name=testSPO#0,target=ba2214f9-b220-43f5-9f50-8f1095ce3ec6)
testterm2id#1	 = willBuild(name=testterm2id#1)
testterm2id#2	 = willBuild(name=testterm2id#2)

and the exception was for the move.

--------------------

DataServer4:

Caused by: java.lang.RuntimeException: Expected

oldLocator={ partitionId=1, dataServices=[ba2214f9-b220-43f5-9f50-8f1095ce3ec6], leftSeparator=[], rightSeparator=null}, but
    actual={ partitionId=0, dataServices=[2eed9964-6c1c-40ee-8b3f-ceb5b30278d5], leftSeparator=[], rightSeparator=null}
	at com.bigdata.service.MetadataService$SplitIndexPartitionTask.doTask(MetadataService.java:519)

This is what was happening at the time.

__global_namespace_index#0	 = wasCopied(name=__global_namespace_index#0)
testOSP#1	 = willBuild(name=testOSP#1)
testOSP#2	 = willBuild(name=testOSP#2)
testPOS#1	 = willBuild(name=testPOS#1)
testPOS#2	 = willBuild(name=testPOS#2)
testSPO#1	 = willSplit(name=testSPO#1)
testid2term#0	 = willBuild(name=testid2term#0)
testjust#0	 = wasCopied(name=testjust#0)
testsearch#0	 = willBuild(name=testsearch#0)

So this looks like a cascade of the move problem.  So we need some
compensating action for the failed move since it seems to have been at
least partly effective even through there was an exception thrown.

--------------------

This was in the client's stack trace.  i've added the index name to
the stack trace, but again it looks linked to the problem with the SPO
MOVE failure.

Caused by: java.lang.NullPointerException
	at com.bigdata.service.ClientIndexView.splitKeys(ClientIndexView.java:1751)
	at com.bigdata.service.ClientIndexView.submit(ClientIndexView.java:877)
	at com.bigdata.rdf.store.SPOIndexWriter.call(SPOIndexWriter.java:280)
	at com.bigdata.rdf.store.SPOIndexWriter.call(SPOIndexWriter.java:73)
	... 5 more

============================================================

   - Monitor the [executorService] queue for {Journal, TemporaryStore}
	 
   - ScaleOutTripleStore {LDS, EDS, JDS}

         Note: You CAN place indices onto specific data services
         running on a set of machines and set [enableOverflow :=
         false] such that the indices never become partitioned. In
         that case you can have optimized joins for some relations on
         one data service and for other relations on another data
         service. E.g., locating the statement indices for the triple
         store on one data service, the lexicon on another, and a repo
         on a third. This will give very good performance for Query
         and Truth Maintenance since the JOINs will be mostly
         executing against live index objects.

       - *** The LDS is running each round as a separate procedure
         submitted to the concurrency manager.  Why not run all rounds
         as a single procedure?

	 Ah.  This was being done so that we could update the read
	 behind point after (or before) each round of closure.
	 However, we do NOT need to do that if we are using
	 UnisolatedReadWriteIndex.

	 If I go this way, then need to change AbstractRelation to use
	 the UnisolatedReadWrite index in this case as well.  However,
	 that could decrease performance if there are point tests
	 since the locks would be requested per point test.

	 *** Perhaps this could be an option to the AbstractTask?
   	     I.e., whether or not the procedure itself will use
   	     concurrent threads and therefore needs the unisolated
   	     indices to be thread-safe.

       - Modify TM to remove constraints on scaling imposed by the use
         of fully buffered iterators to avoid concurrency problems.

	 Consider the use of magic sets as an alternative to "fixing"
	 justifications tracking for scale-out.

============================================================
SPARQL query evaluation and native rule engine optimizations:

  - ** Sesame 2 TCK (integration tests).  This will give us confidence
       that we are handling all of SPARQL with our native rule
       execution layer.

       (temp fix) You should add the following URL as a maven
       repository to your maven settings.xml file:

       http://repo.aduna-software.org/maven2/releases/

  x. *** Native rules have several capabilities that are not being
         exploited by the SAIL.

       - Define custom operators corresponding to the native rule
         constructs (step, rule, program, predicate, etc).

       - Rewrite the tupleExpr into an equivalent tuplExpr that uses
         our custom operators.

       - Modify the execution (BigdataEvaluationStrategyImpl) to have
         methods for our custom operators and to trap any non-standard
         operators that we do not define.  The base class will provide
         standard Sesame semantics for any operators that we do not
         rewrite.
      
  x. Publish on statement level provenance and truth maintenance for
     SPARQL end points.

  x. Defer "named-graph" style quad store for now.

  x. resolution of terms to term ids and visa versa using JOINs?
     (batch resolution is done, but not by joins to the lexicon).

  x. filters for various kinds of things, especially those that can be
     computed directly from the bit markings on the term identifiers.

  x. filters that require JOINs to the lexicon and ordered scans by
     datatype literals.

  x. LUBM Query 9 is an example where a JOIN can be eliminated given
     the ontology. Given (?y ub:teacherOf ?z) we can infer (?z
     rdf:type ub:Course) from the ontology.  Introduce such JOIN
     eliminations into the query rewrite, maybe w/ the Sesame people
     since it does not depend on anything in the bigdata layer.

============================================================
Snapshot release:

  - web app for row store & how to

  - how to for Sesame 2.

  - publish current javadoc.

  - Move the ant build to the bigdata module and also the startup kit
    and its documentation.

============================================================

  - (defer) Optimize by assigning variables in a rule a positional
    index and use a long[] for bindings for SPORelation self-joins.

  - Verify that the distinct term scan can correctly advance across
    index partition boundaries.  One way to do this is by setting a
    very small split point and then loading a known data set,
    computing its closure, and comparing it to ground truth.

  - performance testing for owl:sameAs processing at scale.

============================================================

x. Full text index performance.

   - Do not re-index terms found in the forward index?  This is
     definately faster but it lacks the robust guarentee of the
     unisolated write pattern (all clients write on both all indices
     to guarentee consistent index states).

x. GOM style "rows" for IRelation yeilding schema flexible JOINs.
   Could even just use GOM for this, but I would also have to extend
   JOINs to link vs attribute JOINs and make some decisions about
   object state caching, invalidation and update (only applies if you
   want an updatable view of the object).
   
   There is also a strong relationship to the solutions generated by
   the rules, which are basically binding sets.

x. Map/reduce harvest pipeline and info arch changes w/ MikeP towards
   open sourcing the "web 3" framework.

   *** FileVersionDeleter is not quite correct yet.  Make sure that we
       have good tests for the fence posts on this one.

   *** Block API support is not complete for scale-out.

       - iterators need to be verified for passing through the
         sourceIndex.

       - block read needs to be verified, including the behavior
         during synchronous overflow.

       - block write needs to be tuned up.

   *** Text indexer for the repo.

       - define a schema property for the text index.  if the property
         exists for a file then index the file when it is written
         (only file at once, not block-based).

       - perf test the text indexer.

       * Handle "delete" from the full text index.  We need to do this
         when a document is deleted whose indexText property was set.

	 One solution is to filter the results by whether the document
	 is still in the file metadata index.  That might not be too
	 bad.

       - consider alternative integration using mg4j and lucene for
         text indexing.

       * MetadataSchema#IndexText may be too blunt a device.  We may
         want to specify a variety of metadata for the text indexer,
         including the URI of the source document, the text index to
         be used (there can be several, each corresponding to a
         collection), tokenization preferences (local to the text
         index I guess), etc.

       - Focus on two CONOPS: incremental updates (crud) and map /
         reduce style index builds (bulk write).   

x. Resource lock manager

   - ZooKeeper integration for resource lock manager?

   - Jini smart proxy for ResourceLock.
	    
     The state is just the lock UUID, so this can be done easily
     enough.

============================================================

Probable concurrency problem.  I suspect that the iterator needs to
re-seek since there has been an intervening writer on the B+Tree.

Caused by: java.lang.RuntimeException: De-serialization problem: addr={nbytes=232,offset=9492165} from store=C:\DOCUME~1\BRYANT~1\LOCALS~1\Temp\bigdata44921.tmp : cause=java.lang.RuntimeException: Child is not persistent: index=6
	at com.bigdata.btree.AbstractBTree.readNodeOrLeaf(AbstractBTree.java:2460)
	at com.bigdata.btree.Node.getChild(Node.java:2116)
	at com.bigdata.btree.ChildIterator.next(ChildIterator.java:163)
	at com.bigdata.btree.ChildIterator.next(ChildIterator.java:1)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:59)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:56)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:56)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:58)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at com.bigdata.btree.AbstractNode$PostOrderEntryIterator.hasNext(AbstractNode.java:657)
	at com.bigdata.btree.ResultSet.<init>(ResultSet.java:896)
	at com.bigdata.btree.filter.ChunkedLocalRangeIterator.getResultSet(ChunkedLocalRangeIterator.java:123)
	at com.bigdata.btree.UnisolatedReadWriteIndex$ChunkedIterator.getResultSet(UnisolatedReadWriteIndex.java:700)
	at com.bigdata.btree.filter.AbstractChunkedTupleIterator.rangeQuery(AbstractChunkedTupleIterator.java:305)
	at com.bigdata.btree.filter.AbstractChunkedTupleIterator.hasNext(AbstractChunkedTupleIterator.java:461)
	at com.bigdata.btree.FusedTupleIterator.hasNext(FusedTupleIterator.java:197)
	at cutthecrap.utils.striterators.Resolverator.hasNext(Resolverator.java:48)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at com.bigdata.striterator.ChunkedWrappedIterator.hasNext(ChunkedWrappedIterator.java:162)
	at com.bigdata.relation.rule.eval.LocalNestedSubqueryEvaluator.apply1(LocalNestedSubqueryEvaluator.java:189)
	at com.bigdata.relation.rule.eval.LocalNestedSubqueryEvaluator.call(LocalNestedSubqueryEvaluator.java:136)
	at com.bigdata.relation.rule.eval.RunRuleAndFlushBufferTask.call(RunRuleAndFlushBufferTask.java:47)
	at com.bigdata.relation.rule.eval.RunRuleAndFlushBufferTask.call(RunRuleAndFlushBufferTask.java:1)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)
Caused by: java.lang.RuntimeException: Child is not persistent: index=6
	at com.bigdata.btree.AddressSerializer.putChildAddresses(AddressSerializer.java:70)
	at com.bigdata.btree.NodeSerializer.putNode2(NodeSerializer.java:517)
	at com.bigdata.btree.NodeSerializer.putNode(NodeSerializer.java:475)
	at com.bigdata.btree.AbstractBTree.writeNodeOrLeaf(AbstractBTree.java:2345)
	at com.bigdata.btree.AbstractBTree.writeNodeRecursive(AbstractBTree.java:2235)
	at com.bigdata.btree.DefaultEvictionListener.evicted(DefaultEvictionListener.java:111)
	at com.bigdata.btree.DefaultEvictionListener.evicted(DefaultEvictionListener.java:1)
	at com.bigdata.cache.HardReferenceQueue.evict(HardReferenceQueue.java:273)
	at com.bigdata.cache.HardReferenceQueue.append(HardReferenceQueue.java:235)
	at com.bigdata.btree.AbstractBTree.touch(AbstractBTree.java:2122)
	at com.bigdata.btree.AbstractNode.<init>(AbstractNode.java:321)
	at com.bigdata.btree.Leaf.<init>(Leaf.java:159)
	at com.bigdata.btree.BTree$NodeFactory.allocLeaf(BTree.java:1197)
	at com.bigdata.btree.NodeSerializer.getLeaf(NodeSerializer.java:930)
	at com.bigdata.btree.NodeSerializer.getNodeOrLeaf(NodeSerializer.java:415)
	at com.bigdata.btree.AbstractBTree.readNodeOrLeaf(AbstractBTree.java:2456)
	at com.bigdata.btree.Node.getChild(Node.java:2116)
	at com.bigdata.btree.ChildIterator.next(ChildIterator.java:163)
	at com.bigdata.btree.ChildIterator.next(ChildIterator.java:1)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:59)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:56)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:56)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Appenderator.hasNext(Appenderator.java:52)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at cutthecrap.utils.striterators.Expanderator.hasNext(Expanderator.java:58)
	at cutthecrap.utils.striterators.Striterator.hasNext(Striterator.java:55)
	at com.bigdata.btree.AbstractNode$PostOrderEntryIterator.hasNext(AbstractNode.java:657)
	at com.bigdata.btree.ResultSet.<init>(ResultSet.java:896)
	at com.bigdata.btree.filter.ChunkedLocalRangeIterator.getResultSet(ChunkedLocalRangeIterator.java:123)
	at com.bigdata.btree.UnisolatedReadWriteIndex$ChunkedIterator.getResultSet(UnisolatedReadWriteIndex.java:700)
	at com.bigdata.btree.filter.AbstractChunkedTupleIterator.rangeQuery(AbstractChunkedTupleIterator.java:305)
	at com.bigdata.btree.filter.AbstractChunkedTupleIterator.hasNext(AbstractChunkedTupleIterator.java:461)


------

  - bigdata-sail/TestSearchQuery#test_restart() is failing?!?

  * Re-compare performance of fast vs full and serial vs parallel
    closure on a server platform and when the joins are using parallel
    subquery evaluation.  How does this differ by platform and data
    set?  What is a good default for the various configuration
    variables?  What about [maxParallelSubqueries]?  Try an
    'experiment' driver for an LUBM data set with a variety of
    interesting conditions?

  * We need a pattern for producing tasks that are run on either a
    local executor service or (map/reduce) on a distributed executor
    service.  The maximum concurrency imposed on the service by the
    producer should be limited, at least for some producers.  Others
    producers will just add tasks directly to the service, e.g., in
    order to avoid livelock/deadlock conditions which might otherwise
    arise.  The existing map/reduce system has something which does
    this but it needs to be refactored for more general reuse.  Other
    users include closure of a rule set and parallel subquery
    evaluation for joins.

  - Is there a small variation in the exact statement count for U10
    between runs with parallel subquery evaluation enabled!?!

     exactStatementCount 1598981 vs 1598986.
    
*** LUBM 50

    - ant script to build and modify runlubm to execute on server.

    - Query 9

      - Appears to benefit from caching with a 3x speedup on the 2nd
        presentation.  Is that caching of the lexicon lookups?

    - Query 14

      - Use a native long hash set from mg4j for Longs during lexicon
        operations (might be worth 2-4%); but hard to get that since
        we promote to Long for the LRUCache - unless fastutil has one
        of those too? - no, don't see it there, but I could write it
        of course.

	In fact, the term cache does VERY poorly for query 14 - it
	seems that nearly all terms are distinct so the term cache is
	just overhead.

	Also, 10/12ths of the cost of sorting is the comparison of the
	term identifiers by indirection and sorting is 1/3 of the
	total cost of the batch lookup of the term identifiers.

   * Mutation count is busted.  

     1. Modify flush() to either reset the counter or to accept a
        boolean parameter to optionally reset the counter (if the
        StatementBuffer is otherwise unhappy).

     2. Modify RuleStats#add() to be transparent - it just rolls up
        the mutation counter.

     3. The per-round mutation delta should still be correct.

   * Modify the sub-query joins to allocate their buffer based on the
     expected cardinality of the largest sub-join.  This should wind
     up being a lot smaller than 20k for most joins and will help to
     reduce allocation that drives GC in the nursery.

   - bigdata-rdf/embedded federation test suite has errors.  Mostly
     can't find 'testXX' lexicon.  Also some in TestTruthMaintenance
     for LocalDataServiceFederation - maybe the problem with
     read-committed BTree semantics?

   ** reduce byte[] allocation for DoNotAddFilter. It is
      single-threaded in use, other than the instance on the
      InferenceEngine.  It could copy the key out of the KeyBuilder
      into a per-instance buffer and avoid a lot of allocation!

      This is an example of the general case where we would do better
      to copy the key / key buffer on demand rather than eagerly.

(14% 1879) com.bigdata.btree.keys.KeyBuilder.getKey [KeyBuilder.java:294]
(98% 1850) com.bigdata.rdf.spo.SPOTupleSerializer.statement2Key [SPOTupleSerializer.java:341]
(76% 1413) com.bigdata.rdf.axioms.BaseAxioms.isAxiom [BaseAxioms.java:354]
(100% 1413) com.bigdata.rdf.rules.DoNotAddFilter.accept [DoNotAddFilter.java:117]
(100% 1413) com.bigdata.rdf.rules.DoNotAddFilter.accept [DoNotAddFilter.java:1]

  ** Read-committed semantics for BTree are broken.  The
     read-committed view of the BTree does not automatically update
     after a commit.  This has consequences throughout the system,
     including in the DefaultResourceLocator and IndexManager, since
     we can not cache the read-committed BTree object as it becomes
     stale after every commit.

     Could have ReadCommitted BTree variant that was notified of (or
     simply noticed) commits and re-loaded itself from the new
     checkpoint.  This could be done in getRoot() and in a few
     additional methods that return fields (index metadata,
     entryCount, etc).

     Could also lookup the last commit time (or the last closure time)
     and use that timestamp rather than specifying READ_COMMITTED.

     Could copy over the root reference and immutable nodes/leaves
     from the hard reference queue of the most recently committed
     unisolated view of the btree.  This would reduce the need to
     re-read and de-serialize those data from the disk.  We can't keep
     anything from the read-committed BTree's hard reference queue
     since nodes and leaves may have been written and flushed by the
     unisolated view and no longer exist on the queue but have still
     been modified since the read-committed view.

     - DefaultResourceLocator should cache read-committed resource
       views.

     - IndexManager should cache read-committed IIndex views.

     - AbstractTripleStore#asReadCommittedView() is broken for the
       LocalTripleStore as a result of this issue.  This also effects
       the BigdataSail and
       com.bigdata.rdf.store.TestLocalTripleStoreTransactionSemantics.
       The problem is that the BTrees are not truely read-committed
       views.  They are views as of the last commit time.  However
       asReadCommittedView() is a singleton so the view never
       advances.

** Concurrent programming and Java.

   http://www.ibm.com/developerworks/forums/forum.jspa?forumID=176&start=0       

============================================================

Priority list:

x. *** Get 1-2B scaling numbers on the DPP cluster for DaveL and post
       at http://esw.w3.org/topic/LargeTripleStores.

       * Running U8000 (1B) or U50000 (7B) will require either a
         machine with a lot of (local preferred) disk or a larger
         closure and more join optimizations (for JDS closure and
         query).

       * Increase the journal chunk size (config files) and split
         point (done).

       * Initially, disable overflow for EDS, JDS.

       - Note the time writing on the statement indices during closure
         and compare it with the time reading on those indices.  What
         takes more time?  For which rules?  Enable the load balancer
         and httpd reporting for at least shakedown runs.

       - First, load lubm with RDFS++ closure.

	    - Without compression this will have to be on more than
	      one machine or using NAS.

	    - Without overflow processing the triple store will take
              up more space due to the WORM nature of the store.

	    * leading prefix compress can help to compenate for this,
              but it has not been implemented yet.

       - Then run LUBM benchmarks
       
            - Done: rewrite Sesame2 queries to native JOINs.

       Do this for U100, U1000, and U8000 on one machine and then for
       the same data sets on three machines using MONOLITHIC indices.
       Put the statement indices on one host (make sure that optimized
       joins are enabled) and the lexicon on another.  The full text
       index can be on a third.  Read the source data from NFS.

      * EDS/JDS - Support an option to constrain the placement of the
        SPO indices onto a specific data service and run with (much
        of) the same efficiency as the LTS or LDS.  Overflow can be
        allowed for this condition IF index partition MOVEs are
        disabled.

      * The LDS should be able to run the entire closure program as a
	single task on the concurrency manager -- refactor until it
	does!
	
	LDS U10 Load rate w/o closure on d620 with 10 threads and 100k
	statement buffer.  Not bad.

	Database: #terms=315059, #stmts=1272953, rate=12355.0 in 103031 ms.

       - Once I have these numbers, go back and try again to work
         through dynamic partitioning, load balancing.

       - Compute the database-at-once closure once the data are safely
         loaded (verify!) using dynamic partitioning, run some LUBM
         benchmarks.  (This will force validation of the scale-out
         joins, including serialization, the async iterator, and
         efficiency).

       - Then run the LUBM benchmarks again against the distributed,
         key-range partitioned indices.

   - Modify SerializerUtil to optionally collect a histogram of
     serialization size/time by class.  That will be useful for
     examining JDS costs attributable to Serialization.  Tune
     serialization for elements materialized by high-level query (it
     is using java default serialization). (extSer already has a
     profiler but it does not handle object graph uniquification yet).

   - Add custom serialization for the IAsynchronousIterator via
     IJoinNexus and RemoteChunkIterator.  extser would actually work
     here just fine since we can in effect send along the dictionary.
     so would gom style data records.  however, we should also
     eliminate common values -- there will be a LOT of duplicate of
     values in binding sets.  In fact, since Java default
     serialization uniquifies an object graph and since we do not
     clone the constants, just the binding sets, it might do pretty
     well.

	    unit tests for RemoteChunk (de-)serialization - these
	    exist, right?

	    unit tests for ISolution (de-)serialization and efficient
	    impls.

   - A scale-out system may well choose to disable the (x type
     resource) expander, or at least the all unbound variant.

   * Get numbers for LTS (1B, not enough disk) and JDS (3 servers,
     let us do ~1B).

   - Bulk loads on the DPP (U100, U1000, U8000) and LUBM query tests.

      - Test w/ Sesame 2 custom lubm benchmarking extensions - look
        for other places where we can boost performance.

      * EDS, JDS

        - Either verify overflow or disable overflow for EDS, JDS.

	- During verification of scale-out data load (JDS U10)

Caused by: java.lang.IllegalStateException
	at com.bigdata.rdf.spo.SPO.setStatementType(SPO.java:653)
	at com.bigdata.rdf.spo.BulkCompleteConverter.convert(BulkCompleteConverter.java:135)
	at com.bigdata.rdf.spo.SPOConvertingIterator.convert(SPOConvertingIterator.java:59)
	at com.bigdata.rdf.spo.SPOConvertingIterator.hasNext(SPOConvertingIterator.java:93)
	at com.bigdata.rdf.store.ConcurrentDataLoader$VerifyStatementBuffer.incrementalWrite(ConcurrentDataLoader.java:1637)
	at com.bigdata.rdf.rio.StatementBuffer.flush(StatementBuffer.java:377)
	at com.bigdata.rdf.rio.PresortRioLoader.success(PresortRioLoader.java:71)
	at com.bigdata.rdf.rio.BasicRioLoader.loadRdf2(BasicRioLoader.java:214)
	at com.bigdata.rdf.rio.BasicRioLoader.loadRdf(BasicRioLoader.java:145)
	at com.bigdata.rdf.store.ConcurrentDataLoader$ReaderTask.readData(ConcurrentDataLoader.java:1493)
	at com.bigdata.rdf.store.ConcurrentDataLoader$ReaderTask.run(ConcurrentDataLoader.java:1404)


============================================================

Reduce GC drivers for U1000

  * Reduce byte[] allocation, which is one of the main drivers of the
    heap and hence of time lost to GC.

    Create an abstraction for a buffer containing ordered (byte[] key,
    byte[] val) tuples that is in fact backed by a direct buffer
    allocated from our DirectBufferPool.  The KeyBuilder will write
    onto the buffer, rather than allocating a byte[] for each key.
    Likewise, a DataOutputBuffer can be (re-)used and the data copied
    onto the direct buffer for each byte[] value written. When writing
    on the buffer would cause an overflow, trigger the desired
    operation (batch lookup, batch insert, etc) for just those data in
    the buffer.  The operation should use a socket to blast across the
    nio buffer to the server (just like the block API) and transfer
    the other parameters via RMI.  The server should allocate a direct
    buffer from the pool to receive the data and apply the operation
    to those data.

      We should be able to apply leading key compression as part of
      this abstraction as the data are being written on the buffer.

      Applying dictionary based or other compression techniques is
      more tricky -- there is an impedence mismatch there that I still
      have not resolved to my satisifaction.

      Modify the batch operation implementations to use the direct
      buffer, possibly with one DataOutputBuffer for the key and
      another for the value to minimize allocation when, for example,
      we are just doing lookups (or conditional inserts coded as
      lookup + insert).  On insert, we need to copy the key and value
      into the leaf.

      There should be some abstraction, perhaps parallel to
      CharSequence such as ByteSequence, which allows us to operate on
      byte[] data or on a slide of a byte[] or on a slice of a direct
      buffer.  This would allow us to keep the BTree API for insert,
      lookup, contains and delete simple while increasing the
      flexibility such that we can avoid allocation when copying keys
      into the BTree.

    Immutable B+Tree nodes are being converted to normal nodes on
    de-serialization.  This is a historical artifact and immutable
    nodes should be scrapped.

    - Search on the immutable key buffer is a significant part of the
      costs for the BTree during query.

    - Try compression alternatives analysis again after re-factoring
      out ImmutableKeyBuffer since that introduces additional
      overhead.

    The node and leaf need a GOM like data structure to minimize
    allocation where they are compacted and/or reallocated only as
    required.

  - Size chunks by expected end result cardinality for subqueries
    (this is a bit difficult to get right).

  - Disable the GC overhead limit.

  - Tune GC parameters.

  - Examine the performance during closure for U1000.

    What is going on with the CPU, GC, and work queues during rule
    executions?

    Is there any easy way to mark the events corresponding to the
    execution timeline for correlation with the performance counters
    from the OS, JVM, and application?

    Does more parallelism help?  It will doubtless increase GC
    problems but might reduce latency for closure and keep up the CPU
    utilization.

    We would do better to maintain a blocking queue of tasks to be run
    from which a thread pool draws so that we can keep the pace up.
    Right now each set of subquery tasks runs to a barrier and then we
    issue a new set of subquery tasks.

  - Optimize JOINs when SPORelation is locked onto a data service.

  - Setup the other servers and try 2-server runs on U100 and U1000.
    Look for throughput multipler for data load even if closure is not
    optimized.

  - Test advisory locks on NFS mount.

============================================================

- ResourceManager does not reveal read-historical indices (or
  read-committed?), just those where we write on the index.  This
  makes the index metadata unavailable during read-only runs, such as
  the lubm benchmark.

* There is a lot of reading on the globalRowStore.  This is all
  related to locating the TripleStore resource and its contained
  SPORelation and LexiconRelations.

  (a) We do not read against the appropriate (historical) view of the
      global row store.  We need to obtain that view from the
      federation, which can only return the current view.

  (b) We do not cache recently read property sets for historical reads
     (because we are always doing read-committed property set reads).

  (c) We should read the properties sets for the container
      (tripleStore) and all contained resources (lexicon, text index,
      and spo relation) from the property store using a single
      operation.  Use a logical row scan to build up the property set
      for these resources in one go and then return the appropriate
      layered Properties object on request.  (We need to layer the
      property sets so that you can override properties on a contained
      resource, but in fact the contained resources that we are using
      always have exactly the same property set as their container,
      which is a bit of redundency that we don't really need.)

  (d) Defer. We should recognize unknown properties, much like log4j.

* Did not handle disk full gracefully. Force client disconnect?

* 1st presentation of query 2 is very slow on U50 and used nearly NO
  CPU. What's that about?  Disk caching?

* WorkAddressManager's packAddr() and unpackAddr(), the
  IAddressSerializer impls, Name2Addr.Entry's serializer, and
  CommitRecordSerializer need to be reconciled and tested out at scale
  for packed addresses.  Also, review the code for anything else that
  might write out store addresses.    

* Consider introduction of a constrainable allocation policy for index
  allocations.  The policy would clearly need access to the federation
  and the namespace of the container as well as a means to identify
  the services on which any existing indices were registered.  It
  should also carry (or re-discover) state about allocations that are
  made in order to be able to either group or distribute the index
  registrations as necessary.  Should also provide an extensible
  ability for definiting the initial index partitions.

  A policy along these lines might either be imposed by a client on
  the federation session or on the container and then imposed on all
  allocations by contained resources.  Since containers can be nested,
  the allocation policy would have to use a delegation pattern.

- Done. Run 3 machines w/ one on NAS.

  - Analyze run and decide how to statically place the indices so as
    to avoid one machine becoming a bottleneck.  Try that run (but we
    are running out of disk anyway).

  - Try a run w/ dynamic partitioning, but I will need to also do
    incremental builds for that to be effecient.

============================================================

- Seeing "Ignoring sample WAY out of timestamp order" messages in the
  load balancer log.  This is probably a parsing / format error for
  the sysstat package.

- Done (The problem was that the MetadataServer0 instance had not been
  killed so there was an attempt to connect to an old instance; kill
  -9 fixed this).  Seeing "object not in table" errors during
  concurrent data load.  This causes the load to fail.

============================================================

New priorities:

    - improve JDS closure and query performance (latency, per above;
      serialization costs; etc).

    - magic predicate for search in native rule eval. We also need a
      unit test for this when there is at least one join.  The object
      MUST be a constant.  This predicate need to be evaluated first.

    - Native rule ORDER_BY support (custom IKeyBuilderFactory).
      Verify that a descending sort order is accomplished by the
      bit-wise negation of a field in the key - is this also true for
      Unicode sort keys?

*** Get a SYSTAP (~100 documents) and NGA benchmark (~1000+) data set
    and queries from MikeP.  Add to the lubm test harness in CVS.  Add
    delete test for (a) delete specific entities; and (b) delete
    specific documents.
    
    - delete entity is an ELM command so I really need the generated
      delete sets or I need to capture the code for that command and
      run it and then run the delete.

*** Annotator as first class KB citizen.

  - Map/reduce processing:

    * Parallel KB load (CDL refactor).  Allows easy distribution of
      the load tasks across a federation.

    - harvest and extractor.

*** Global "do not extract" and mention level false positive handling,
    plus dropping data structures no longer required in the content
    repository.

  - Defer. Content repository change over (must handle splits for
    sparse row store and content repo, plus text index for content
    repo).

  - TruthMaintenance performance should be optimized and re-vetted.

    - Remove use of deprecated classes.

    - Use ordered reads and writes for operations on the temporary
      stores.

    - Ordered operations for statements identifiers.

    - Replace the use of fully buffered iterators with incremental
      chunked iterators.

    - Handling TM at scale is its own issue and might be best solved
      using: (a) a magic sets integration; and (b) periodic map/reduce
      style updates with closure.  (Or database at once closure on a
      new data set, which is similar to how scale-out text indices are
      built.)

    - Test w/ APSTARs data set (incremental loads).

    * Review performance for sameAs processing during query.  Note
      that transitive for owl:same1b was moved to forward closure.
      Test with the old classes and owl:sameAs1b backward vs the new
      rule-based expander and the owl:sameAs1b forward.

    - Defer. tune up justifications.

    * Fix TruthMaintenance#applyExistingStatements() - should use bulk
      filter not point tests!

    * Closure for StatementIdentifers should reuse the same
      TemporaryStore and close() vs closeAndDelete().

    * TruthMaintenance should reuse the same TemporaryStore (at least
      for a given closure) and close() vs closeAndDelete().

============================================================ 

EOSSYS ranker dataset.

  - query times, load times, properties to use (code), and #of query
    results, updated CVS tag for checkout.

  - run sails and bigdata test suites first.

  - compare answers to native sesame execution first.	
  
  - write unit tests for slice at the irule level (independent of the
    sail).  verify slices with non-zero offsets.

  - broken something for bigdata-rdf federation runs having to do with
    access to the global row store from a read-only timestamp.
    perhaps a deadlock due to how the abstract task accesses the
    global row store index?

loadTime(ms)=325078, loadRate(tps)=12317, toldTriples=4004108,
#terms=1694934, nextOffset: 1475898492, bytes/triples=

  - Re-run JDS {1,2,3} with Prefix+Prefix+Fast @m=256.  Try LTS with
    those same settings on {1 or 2} and see what we get.

    - A run with TERM2ID on NAS is taking a MAJOR IOWAIT penalty - up
      to 20% in the 1st hour.  I am going to restart and see how the
      indices are distributed and what impact that has.

*** Fix PrefixSerializer so that it is efficient enough to be used for
    smaller branching factors; drop ImmutableKeyBuffer.

FIXME AbstractJournal#getIndex(String,long ) is receiving calls from
      {@link IIndexStore#getIndex(String, long)} and from methods that
      assume that [commitTime] is a timestamp NOT a commitTime. The
      culprits are the {@link GlobalRowStoreHelper} and {@link
      AbstractTask}'s interior {@link IJournal} implementations of
      {@link IIndexStore#getGlobalRowStore(long)}.  The problem
      emerged when I was modifying the code to pass a timestamp when
      obtaining the global row store.  In fact, timestamp ==
      -commitTime right now so this is totally busted!

FIXME Tune the default LRU cache capacity for the resource locator
      (10).  A larger value would be nice, but there needs to be an
      time-based expire on the resources in the cache since they will
      cause their indices to be held open.

      Configure and tune the access path cache capacity for the
      SPORelation.
