package com.bigdata.bop.rdf.joinGraph;

import java.io.File;
import java.util.Properties;
import java.util.UUID;

import org.openrdf.rio.RDFFormat;

import com.bigdata.bop.BOp;
import com.bigdata.bop.BOpUtility;
import com.bigdata.bop.Constant;
import com.bigdata.bop.IPredicate;
import com.bigdata.bop.IVariable;
import com.bigdata.bop.NV;
import com.bigdata.bop.Var;
import com.bigdata.bop.IPredicate.Annotations;
import com.bigdata.bop.joinGraph.rto.JoinGraph;
import com.bigdata.journal.ITx;
import com.bigdata.journal.Journal;
import com.bigdata.rdf.model.BigdataLiteral;
import com.bigdata.rdf.model.BigdataURI;
import com.bigdata.rdf.model.BigdataValue;
import com.bigdata.rdf.model.BigdataValueFactory;
import com.bigdata.rdf.spo.SPOPredicate;
import com.bigdata.rdf.store.AbstractTripleStore;
import com.bigdata.rdf.store.DataLoader;
import com.bigdata.rdf.store.LocalTripleStore;
import com.bigdata.rdf.store.DataLoader.ClosureEnum;
import com.bigdata.rdf.vocab.RDFSVocabulary;

/**
 * Unit tests for runtime query optimization using {@link JoinGraph} and the
 * "bar data" test set.
 * <p>
 * Note: When running large queries, be sure to provide a sufficient heap, set
 * the -server flag, etc.
 * 
 * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
 * @version $Id: TestJoinGraph.java 3918 2010-11-08 21:31:17Z thompsonbry $
 * 
 * @see GenerateBarData, which may have been used with <code>200000 16 8</code>
 *      when generating the data set against which this query was originally
 *      run.
 */
public class TestJoinGraphOnBarData extends AbstractJoinGraphTestCase {

    /**
     * 
     */
    public TestJoinGraphOnBarData() {
    }

	/**
	 * @param name
	 */
	public TestJoinGraphOnBarData(String name) {
		super(name);
	}

    /**
     * The {@link UUID} of a {@link Journal} resource used by this test.
     */
    private static final UUID resourceId = UUID
            .fromString("15ebea90-2360-11e0-ac64-0800200c9a66");
	
	@Override
	public Properties getProperties() {

		final Properties p = new Properties(super.getProperties());

//		p.setProperty(Journal.Options.BUFFER_MODE, BufferMode.Transient
//				.toString());

		p.setProperty(AbstractTripleStore.Options.QUADS_MODE, "true");

        p.setProperty(AbstractTripleStore.Options.VOCABULARY_CLASS,
                RDFSVocabulary.class.getName());

		/*
		 * Don't compute closure in the data loader since it does TM, not
		 * database at once closure.
		 */
		p.setProperty(DataLoader.Options.CLOSURE, ClosureEnum.None.toString());

		return p;

	}

	final private String namespace = "bardata";
    
    protected String getNamespace() {

        return namespace;
        
    }

    /**
     * When true, the test uses hardcoded access to an existing Journal already
     * loaded with some a larger data set (you need to run against a moderately
     * large data set to assess the relative performance of the static and
     * runtime query optimizers).
     */
    private final static boolean useExistingJournal = true;
    
    protected Journal getJournal(final Properties properties) throws Exception {

        final File file;
        if(useExistingJournal){
            /*
             * Use a specific file generated by some external process.
             */
            file = new File("/data/bardata/bigdata-bardata.WORM.jnl");
        } else {
            /*
             * Use a persistent file that is generated once and then reused by
             * each test run.
             */
            final File tmpDir = new File(System.getProperty("java.io.tmpdir"));
            final File testDir = new File(tmpDir, "bigdata-tests");
            testDir.mkdirs();
            file = new File(testDir, resourceId + ".jnl");
        }
        
        properties.setProperty(Journal.Options.FILE, file.toString());

//      properties.setProperty(Journal.Options.BUFFER_MODE,BufferMode.DiskRW.toString());

//      file.delete();

        if (!file.exists()) {

            final Journal jnl = new Journal(properties);

            final AbstractTripleStore tripleStore = new LocalTripleStore(jnl,
                    namespace, ITx.UNISOLATED, properties);

            // Create the KB instance.
            tripleStore.create();

            /*
             * This file being loaded here was generated using the following
             * command and then gzip'd.  It has 183195 statements.
             * 
             * GenerateBarData 20000 16 8
             */
            tripleStore.getDataLoader().loadFiles(
                    new File("bigdata-rdf/src/resources/data/barData/barData.trig.gz"),
                    null/* baseURI */, RDFFormat.TRIG, null/* defaultGraph */,
                    null/* filter */);

            // Truncate the journal (trim its size).
            jnl.truncate();
            
            // Commit the journal.
            jnl.commit();

            // Close the journal.
            jnl.close();
            
        }

        // Open the test resource.
        return new Journal(properties);

    }
    
	/**
	 * Loads LUBM U1 into a triple store.
	 */
	protected void setUp() throws Exception {
		
		super.setUp();

	}

	protected void tearDown() throws Exception {

		super.tearDown();
		
	}

	/**
	 * Sample query for the synthetic data set. The query is arranged in a known
	 * good order.
	 * <p>
	 * Note: The runtime optimizer estimate of the cardinality of the edge [5 4]
	 * in this query is a lower bound, which makes this an interesting test
	 * case. The runtime optimizer detects this lower bound and replaces [nout]
	 * with the sum of the range count of the as-bound predicates for the join,
	 * which leads to an efficient query plan.
	 * 
	 * <pre>
	 * SELECT ?f (COUNT(?d) AS ?total) WHERE {
	 * ?a <http://test/bar#beverageType> "Beer" .
	 * ?value <http://test/bar#orderItems> ?a.
	 * ?value <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://test/bar#Order> .                            
	 * ?a <http://test/bar#beverageType> ?d.                               
	 * ?value <http://test/bar#employee> ?b.                             
	 * ?b <http://test/bar#employeeNum> ?f.
	 * } GROUP BY ?f
	 * </pre>
	 * 
	 * Note: Mike suggests that it is easier to read the query like this:
	 * 
	 * <pre>
	 * SELECT ?employeeNum (COUNT(?type) AS ?total)
	 * WHERE {
	 *         ?order <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://test/bar#Order> .
	 *         ?order <http://test/bar#orderItems> ?item .
	 *         ?item <http://test/bar#beverageType> "Beer" .
	 *         ?item <http://test/bar#beverageType> ?type .
	 *       
	 *         ?order <http://test/bar#employee> ?employee .
	 *      
	 *         ?employee <http://test/bar#employeeNum> ?employeeNum .
	 * } GROUP BY ?employeeNum
	 * </pre>
	 * 
	 * @throws Exception
	 */
	public void test_barData_query() throws Exception {

        final String namespace = getNamespace();

        final AbstractTripleStore database = getDatabase(namespace);

		/*
		 * Resolve terms against the lexicon.
		 */
		final BigdataValueFactory valueFactory = database.getLexiconRelation()
				.getValueFactory();

		final BigdataURI rdfType = valueFactory
				.createURI("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");

		final BigdataLiteral beer = valueFactory.createLiteral("Beer");

		final BigdataURI beverageType = valueFactory
				.createURI("http://test/bar#beverageType");

		final BigdataURI orderItems = valueFactory
				.createURI("http://test/bar#orderItems");

		final BigdataURI Order = valueFactory
				.createURI("http://test/bar#Order");

		final BigdataURI employee = valueFactory
				.createURI("http://test/bar#employee");

		final BigdataURI employeeNum = valueFactory
				.createURI("http://test/bar#employeeNum");

		final BigdataValue[] terms = new BigdataValue[] { rdfType, beer,
				beverageType, orderItems, Order, employee, employeeNum };

		// resolve terms.
		database.getLexiconRelation()
				.addTerms(terms, terms.length, true/* readOnly */);

		{
			for (BigdataValue tmp : terms) {
				System.out.println(tmp + " : " + tmp.getIV());
				if (tmp.getIV() == null)
					throw new RuntimeException("Not defined: " + tmp);
			}
		}

		final IPredicate[] preds;
		final IPredicate p0, p1, p2, p3, p4, p5;
		{
//			a, value, d, b, f
			final IVariable<?> a = Var.var("a");
			final IVariable<?> value = Var.var("value");
			final IVariable<?> d = Var.var("d");
			final IVariable<?> b = Var.var("b");
			final IVariable<?> f = Var.var("f");
			
			final IVariable<?> g0 = Var.var("g0");
			final IVariable<?> g1 = Var.var("g1");
			final IVariable<?> g2 = Var.var("g2");
			final IVariable<?> g3 = Var.var("g3");
			final IVariable<?> g4 = Var.var("g4");
			final IVariable<?> g5 = Var.var("g5");
			

			// The name space for the SPO relation.
			final String[] spoRelation = new String[] { namespace + ".spo" };

			// The name space for the Lexicon relation.
			final String[] lexRelation = new String[] { namespace + ".lex" };

			final long timestamp = database.getIndexManager().getLastCommitTime();

			int nextId = 0;

//			 ?a <http://test/bar#beverageType> "Beer" .
			p0 = new SPOPredicate(new BOp[] { a,
					new Constant(beverageType.getIV()),
					new Constant(beer.getIV()), g0 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);
						
			// ?value <http://test/bar#orderItems> ?a.
			p1 = new SPOPredicate(new BOp[] { value,
					new Constant(orderItems.getIV()), a, g1 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?value <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://test/bar#Order> .                            
			p2 = new SPOPredicate(new BOp[] { value,
					new Constant(rdfType.getIV()),
					new Constant(Order.getIV()), g2 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?a <http://test/bar#beverageType> ?d.                               
			p3 = new SPOPredicate(new BOp[] { a,
					new Constant(beverageType.getIV()), d, g3 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			  ?value <http://test/bar#employee> ?b.                             
			p4 = new SPOPredicate(new BOp[] { value,
					new Constant(employee.getIV()), b, g4 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?b <http://test/bar#employeeNum> ?f.
			p5 = new SPOPredicate(new BOp[] { b,
					new Constant(employeeNum.getIV()), f, g5 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

			// the vertices of the join graph (the predicates).
			preds = new IPredicate[] { p0, p1, p2, p3, p4, p5 };

		}

        final IPredicate<?>[] runtimeOrder = doTest(preds, null/* constraints */);

        {
            /*
             * Verify that the runtime optimizer produced the expected join
             * path.
             * 
             * Note: This is the correct join ordering for the data set
             * generated by the following command: GenerateBarData 20000 16 8
             */
            
            // after the refactor.
            final int[] expected = new int[]{0, 1, 2, 3, 4, 5};
            
            // before the refactor.
//            final int[] expected = new int[] { 0, 1, 3, 2, 4, 5 };
            
            assertEquals("runtimeOrder", expected, BOpUtility
                    .getPredIds(runtimeOrder));
            
        }

    }

}
