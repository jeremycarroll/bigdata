package com.bigdata.bop.rdf.joinGraph;

import java.io.File;
import java.util.Arrays;
import java.util.Properties;

import junit.framework.TestCase2;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.openrdf.rio.RDFFormat;

import com.bigdata.bop.BOp;
import com.bigdata.bop.BOpContextBase;
import com.bigdata.bop.BOpIdFactory;
import com.bigdata.bop.Constant;
import com.bigdata.bop.IBindingSet;
import com.bigdata.bop.IPredicate;
import com.bigdata.bop.IVariable;
import com.bigdata.bop.NV;
import com.bigdata.bop.PipelineOp;
import com.bigdata.bop.Var;
import com.bigdata.bop.IPredicate.Annotations;
import com.bigdata.bop.controller.JoinGraph;
import com.bigdata.bop.controller.JoinGraph.JGraph;
import com.bigdata.bop.controller.JoinGraph.Path;
import com.bigdata.bop.engine.BOpStats;
import com.bigdata.bop.engine.IRunningQuery;
import com.bigdata.bop.engine.QueryEngine;
import com.bigdata.bop.engine.QueryLog;
import com.bigdata.bop.fed.QueryEngineFactory;
import com.bigdata.journal.ITx;
import com.bigdata.journal.Journal;
import com.bigdata.rdf.model.BigdataLiteral;
import com.bigdata.rdf.model.BigdataURI;
import com.bigdata.rdf.model.BigdataValue;
import com.bigdata.rdf.model.BigdataValueFactory;
import com.bigdata.rdf.spo.SPOPredicate;
import com.bigdata.rdf.store.AbstractTripleStore;
import com.bigdata.rdf.store.DataLoader;
import com.bigdata.rdf.store.LocalTripleStore;
import com.bigdata.rdf.store.DataLoader.ClosureEnum;
import com.bigdata.relation.accesspath.IAsynchronousIterator;
import com.bigdata.relation.rule.IRule;
import com.bigdata.relation.rule.Rule;
import com.bigdata.relation.rule.eval.DefaultEvaluationPlan2;
import com.bigdata.relation.rule.eval.IRangeCountFactory;

/**
 * Unit tests for runtime query optimization using {@link JoinGraph} and the
 * "bar data" test set.
 * <p>
 * Note: When running large queries, be sure to provide a sufficient heap, set
 * the -server flag, etc.
 * 
 * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
 * @version $Id: TestJoinGraph.java 3918 2010-11-08 21:31:17Z thompsonbry $
 */
public class TestJoinGraphOnBarData extends TestCase2 {

    /**
     * 
     */
    public TestJoinGraphOnBarData() {
    }

	/**
	 * @param name
	 */
	public TestJoinGraphOnBarData(String name) {
		super(name);
	}

	@Override
	public Properties getProperties() {

		final Properties p = new Properties(super.getProperties());

//		p.setProperty(Journal.Options.BUFFER_MODE, BufferMode.Transient
//				.toString());

		p.setProperty(AbstractTripleStore.Options.QUADS_MODE, "true");
		
		/*
		 * Don't compute closure in the data loader since it does TM, not
		 * database at once closure.
		 */
		p.setProperty(DataLoader.Options.CLOSURE, ClosureEnum.None.toString());

		return p;

	}

    private Journal jnl;
    
    private AbstractTripleStore database;

    /** The initial sampling limit. */
    private final int limit = 100;
    
    /** The #of edges considered for the initial paths. */
    private final int nedges = 2;

    private QueryEngine queryEngine; 

	private String namespace;

	/**
	 * When true, do a warm up run of the plan generated by the static query
	 * optimizer.
	 */
	private final boolean warmUp = false;
	
	/**
	 * The #of times to run each query. Use N GT ONE (1) if you want to converge
	 * onto the hot query performance.
	 */
	private final int ntrials = 1;

	/**
	 * When <code>true</code> runs the dynamic query optimizer and then evaluates
	 * the generated query plan.
	 */
	private final boolean runRuntimeQueryOptimizer = true;
	
	/**
	 * When <code>true</code> runs the static query optimizer and then evaluates
	 * the generated query plan.
	 */
	private final boolean runStaticQueryOptimizer = true;
	
	/**
	 * Loads LUBM U1 into a triple store.
	 */
	protected void setUp() throws Exception {

//		QueryLog.logTableHeader();
		
		super.setUp();

//		System.err.println(UUID.randomUUID().toString());
//		System.exit(0);
		
		final Properties properties = getProperties();

		final File file;
		{
			/*
			 * Use a specific file generated by some external process.
			 */
			file = new File("/data/bardata/bigdata-bardata.WORM.jnl");
			namespace = "bardata";
		}
		
		properties.setProperty(Journal.Options.FILE, file.toString());

//		properties.setProperty(Journal.Options.BUFFER_MODE,BufferMode.DiskRW.toString());

//		file.delete();
		
		if (!file.exists()) {

			jnl = new Journal(properties);

			final AbstractTripleStore tripleStore = new LocalTripleStore(jnl,
					namespace, ITx.UNISOLATED, properties);

			// Create the KB instance.
			tripleStore.create();

			tripleStore.getDataLoader().loadFiles(
					new File("/root/Desktop/Downloads/barData/barData.trig"),
					null/* baseURI */, RDFFormat.TRIG, null/* defaultGraph */,
					null/* filter */);

			// Truncate the journal (trim its size).
			jnl.truncate();
			
			// Commit the journal.
			jnl.commit();

			// Close the journal.
			jnl.close();
			
		}

		// Open the test resource.
		jnl = new Journal(properties);

		queryEngine = QueryEngineFactory
				.getQueryController(jnl/* indexManager */);

		database = (AbstractTripleStore) jnl.getResourceLocator().locate(
				namespace, jnl.getLastCommitTime());

		if (database == null)
			throw new RuntimeException("Not found: " + namespace);

	}

	protected void tearDown() throws Exception {

		if (database != null) {
			database = null;
		}
		
		if (queryEngine != null) {
			queryEngine.shutdownNow();
			queryEngine = null;
		}

		if(jnl != null) {
			jnl.close();
			jnl = null;
		}
		
		super.tearDown();
		
	}

	/**
	 * Sample query for the synthetic data set. The query is arranged in a known
	 * good order.
	 * <p>
	 * Note: The runtime optimizer estimate of the cardinality of the edge [5 4]
	 * in this query is a lower bound, which makes this an interesting test
	 * case. The runtime optimizer detects this lower bound and replaces [nout]
	 * with the sum of the range count of the as-bound predicates for the join,
	 * which leads to an efficient query plan.
	 * 
	 * <pre>
	 * SELECT ?f (COUNT(?d) AS ?total) WHERE {
	 * ?a <http://test/bar#beverageType> "Beer" .
	 * ?value <http://test/bar#orderItems> ?a.
	 * ?value <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://test/bar#Order> .                            
	 * ?a <http://test/bar#beverageType> ?d.                               
	 * ?value <http://test/bar#employee> ?b.                             
	 * ?b <http://test/bar#employeeNum> ?f.
	 * } GROUP BY ?f
	 * </pre>
	 * 
	 * Note: Mike suggests that it is easier to read the query like this:
	 * 
	 * <pre>
	 * SELECT ?employeeNum (COUNT(?type) AS ?total)
	 * WHERE {
	 *         ?order <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>
	 * <http://test/bar#Order> .
	 *         ?order <http://test/bar#orderItems> ?item .
	 *         ?item <http://test/bar#beverageType> "Beer" .
	 *         ?item <http://test/bar#beverageType> ?type .
	 *       
	 *         ?order <http://test/bar#employee> ?employee .
	 *      
	 *         ?employee <http://test/bar#employeeNum> ?employeeNum .
	 * } GROUP BY ?employeeNum
	 * </pre>
	 * 
	 * @throws Exception
	 */
	public void test_query() throws Exception {

		/*
		 * Resolve terms against the lexicon.
		 */
		final BigdataValueFactory valueFactory = database.getLexiconRelation()
				.getValueFactory();

		final BigdataURI rdfType = valueFactory
				.createURI("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");

		final BigdataLiteral beer = valueFactory.createLiteral("Beer");

		final BigdataURI beverageType = valueFactory
				.createURI("http://test/bar#beverageType");

		final BigdataURI orderItems = valueFactory
				.createURI("http://test/bar#orderItems");

		final BigdataURI Order = valueFactory
				.createURI("http://test/bar#Order");

		final BigdataURI employee = valueFactory
				.createURI("http://test/bar#employee");

		final BigdataURI employeeNum = valueFactory
				.createURI("http://test/bar#employeeNum");

		final BigdataValue[] terms = new BigdataValue[] { rdfType, beer,
				beverageType, orderItems, Order, employee, employeeNum };

		// resolve terms.
		database.getLexiconRelation()
				.addTerms(terms, terms.length, true/* readOnly */);

		{
			for (BigdataValue tmp : terms) {
				System.out.println(tmp + " : " + tmp.getIV());
				if (tmp.getIV() == null)
					throw new RuntimeException("Not defined: " + tmp);
			}
		}

		final IPredicate[] preds;
		final IPredicate p0, p1, p2, p3, p4, p5;
		{
//			a, value, d, b, f
			final IVariable<?> a = Var.var("a");
			final IVariable<?> value = Var.var("value");
			final IVariable<?> d = Var.var("d");
			final IVariable<?> b = Var.var("b");
			final IVariable<?> f = Var.var("f");
			
			final IVariable<?> g0 = Var.var("g0");
			final IVariable<?> g1 = Var.var("g1");
			final IVariable<?> g2 = Var.var("g2");
			final IVariable<?> g3 = Var.var("g3");
			final IVariable<?> g4 = Var.var("g4");
			final IVariable<?> g5 = Var.var("g5");
			

			// The name space for the SPO relation.
			final String[] spoRelation = new String[] { namespace + ".spo" };

			// The name space for the Lexicon relation.
			final String[] lexRelation = new String[] { namespace + ".lex" };

			final long timestamp = jnl.getLastCommitTime();

			int nextId = 0;

//			 ?a <http://test/bar#beverageType> "Beer" .
			p0 = new SPOPredicate(new BOp[] { a,
					new Constant(beverageType.getIV()),
					new Constant(beer.getIV()), g0 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);
						
			// ?value <http://test/bar#orderItems> ?a.
			p1 = new SPOPredicate(new BOp[] { value,
					new Constant(orderItems.getIV()), a, g1 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?value <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://test/bar#Order> .                            
			p2 = new SPOPredicate(new BOp[] { value,
					new Constant(rdfType.getIV()),
					new Constant(Order.getIV()), g2 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?a <http://test/bar#beverageType> ?d.                               
			p3 = new SPOPredicate(new BOp[] { a,
					new Constant(beverageType.getIV()), d, g3 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			  ?value <http://test/bar#employee> ?b.                             
			p4 = new SPOPredicate(new BOp[] { value,
					new Constant(employee.getIV()), b, g4 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

//			 ?b <http://test/bar#employeeNum> ?f.
			p5 = new SPOPredicate(new BOp[] { b,
					new Constant(employeeNum.getIV()), f, g5 },//
					new NV(BOp.Annotations.BOP_ID, nextId++),//
					new NV(Annotations.TIMESTAMP, timestamp),//
					new NV(IPredicate.Annotations.RELATION_NAME, spoRelation)//
			);

			// the vertices of the join graph (the predicates).
			preds = new IPredicate[] { p0, p1, p2, p3, p4, p5 };

		}

		doTest(preds);
		
	} // LUBM_Q9

	/**
	 * 
	 * @param preds
	 * @throws Exception
	 * 
	 * @todo To actually test anything this needs to compare the results (or at
	 *       least the #of result). We could also test for known good join
	 *       orders as generated by the runtime optimizer, but that requires a
	 *       known data set (e.g., U1 or U50) and non-random sampling.
	 * 
	 * @todo This is currently providing a "hot run" comparison by a series of
	 *       trials. This means that the IO costs are effectively being wiped
	 *       away, assuming that the file system cache is larger than the data
	 *       set. The other way to compare performance is a cold cache / cold
	 *       JVM run using the known solutions produced by the runtime versus
	 *       static query optimizers.
	 */
	private void doTest(final IPredicate[] preds) throws Exception {

		if (warmUp)
			runQuery("Warmup", queryEngine, runStaticQueryOptimizer(preds));

		/*
		 * Run the runtime query optimizer once (its cost is not counted
		 * thereafter).
		 */
		final IPredicate[] runtimePredOrder = runRuntimeQueryOptimizer(preds);

		long totalRuntimeTime = 0;
		long totalStaticTime = 0;
		
		for (int i = 0; i < ntrials; i++) {

			final String RUNTIME = getName() + " : runtime["+i+"] :";

			final String STATIC =  getName() + " : static ["+i+"] :";

			final String GIVEN =  getName() + " : given  ["+i+"] :";

			if (true/* originalOrder */) {

				runQuery(GIVEN, queryEngine, preds);
				
			}

			if (runStaticQueryOptimizer) {

				totalStaticTime += runQuery(STATIC, queryEngine,
						runStaticQueryOptimizer(preds));

			}

			if (runRuntimeQueryOptimizer) {

				/*
				 * Run the runtime query optimizer each time (its overhead is
				 * factored into the running comparison of the two query
				 * optimizers).
				 */
//				final IPredicate[] runtimePredOrder = runRuntimeQueryOptimizer(new JGraph(
//						preds));

				// Evaluate the query using the selected join order.
				totalRuntimeTime += runQuery(RUNTIME, queryEngine,
						runtimePredOrder);

			}

		}

		if(runStaticQueryOptimizer&&runRuntimeQueryOptimizer) {
			System.err.println(getName() + " : Total times" + //
					": static=" + totalStaticTime + //
					", runtime=" + totalRuntimeTime + //
					", delta(static-runtime)=" + (totalStaticTime - totalRuntimeTime));
		}

	}
	
	/**
	 * Apply the runtime query optimizer.
	 * <p>
	 * Note: This temporarily raises the {@link QueryLog} log level during
	 * sampling to make the log files cleaner (this can not be done for a
	 * deployed system since the logger level is global and there are concurrent
	 * query mixes).
	 * 
	 * @return The predicates in order as recommended by the runtime query
	 *         optimizer.
	 * 
	 * @throws Exception
	 */
	private IPredicate[] runRuntimeQueryOptimizer(final IPredicate[] preds) throws Exception {

		final Logger tmp = Logger.getLogger(QueryLog.class);
		final Level oldLevel = tmp.getEffectiveLevel();
		tmp.setLevel(Level.WARN);

		try {

			final JGraph g = new JGraph(preds);
			
			final Path p = g.runtimeOptimizer(queryEngine, limit, nedges);

//			System.err.println(getName() + " : runtime optimizer join order "
//					+ Arrays.toString(Path.getVertexIds(p.edges)));

			return p.getPredicates();

		} finally {

			tmp.setLevel(oldLevel);

		}

	}

	/**
	 * Apply the static query optimizer.
	 * 
	 * @return The predicates in order as recommended by the static query
	 *         optimizer.
	 */
	private IPredicate[] runStaticQueryOptimizer(final IPredicate[] preds) {

		final BOpContextBase context = new BOpContextBase(queryEngine);

		final IRule rule = new Rule("tmp", null/* head */, preds, null/* constraints */);

		final DefaultEvaluationPlan2 plan = new DefaultEvaluationPlan2(
				new IRangeCountFactory() {

					public long rangeCount(final IPredicate pred) {
						return context.getRelation(pred).getAccessPath(pred)
								.rangeCount(false);
					}

				}, rule);

		// evaluation plan order.
		final int[] order = plan.getOrder();

		final int[] ids = new int[order.length];
		
		final IPredicate[] out = new IPredicate[order.length];

		for (int i = 0; i < order.length; i++) {

			out[i] = preds[order[i]];
			
			ids[i] = out[i].getId();

		}
		
//		System.err.println(getName() + " :  static optimizer join order "
//				+ Arrays.toString(ids));
		
		return out;
		
	}

	/**
	 * Run a query joining a set of {@link IPredicate}s in the given join order.
	 * 
	 * @return The elapsed query time (ms).
	 */
	private static long runQuery(final String msg,
			final QueryEngine queryEngine, final IPredicate[] predOrder)
			throws Exception {

		final BOpIdFactory idFactory = new BOpIdFactory();

		final int[] ids = new int[predOrder.length];
		
		for(int i=0; i<ids.length; i++) {
		
			final IPredicate<?> p = predOrder[i];
			
			idFactory.reserve(p.getId());
			
			ids[i] = p.getId();
			
		}

		final PipelineOp queryOp = JoinGraph.getQuery(idFactory, predOrder);

		// submit query to runtime optimizer.
		final IRunningQuery q = queryEngine.eval(queryOp);

		// drain the query results.
		long nout = 0;
		long nchunks = 0;
		final IAsynchronousIterator<IBindingSet[]> itr = q.iterator();
		try {
			while (itr.hasNext()) {
				final IBindingSet[] chunk = itr.next();
				nout += chunk.length;
				nchunks++;
			}
		} finally {
			itr.close();
		}

		// check the Future for the query.
		q.get();

		// show the results.
		final BOpStats stats = q.getStats().get(queryOp.getId());

		System.err.println(msg + " : ids=" + Arrays.toString(ids)
				+ ", elapsed=" + q.getElapsed() + ", nout=" + nout
				+ ", nchunks=" + nchunks + ", stats=" + stats);
		
		return q.getElapsed();

	}

}
