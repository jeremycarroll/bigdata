/*

Copyright (C) SYSTAP, LLC 2006-2008.  All rights reserved.

Contact:
     SYSTAP, LLC
     4501 Tower Road
     Greensboro, NC 27410
     licenses@bigdata.com

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; version 2 of the License.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/
/*
 * Created on Aug 20, 2008
 */

package com.bigdata.rdf.rules;

import org.apache.log4j.Logger;
import org.openrdf.model.vocabulary.OWL;
import org.openrdf.model.vocabulary.RDF;
import org.openrdf.model.vocabulary.RDFS;

import com.bigdata.btree.IIndex;
import com.bigdata.btree.ITupleIterator;
import com.bigdata.rdf.inf.BackchainTypeResourceIterator;
import com.bigdata.rdf.inf.OwlSameAsPropertiesExpandingIterator;
import com.bigdata.rdf.spo.ISPO;
import com.bigdata.rdf.spo.SPO;
import com.bigdata.rdf.spo.SPORelation;
import com.bigdata.rdf.store.AbstractTripleStore;
import com.bigdata.rdf.store.IRawTripleStore;
import com.bigdata.rdf.vocab.Vocabulary;
import com.bigdata.relation.accesspath.IAccessPath;
import com.bigdata.relation.accesspath.IElementFilter;
import com.bigdata.relation.rule.IPredicate;
import com.bigdata.striterator.ChunkedWrappedIterator;
import com.bigdata.striterator.IChunkedIterator;
import com.bigdata.striterator.IChunkedOrderedIterator;
import com.bigdata.striterator.IKeyOrder;

/**
 * A read-only {@link IAccessPath} that backchains certain inferences.
 * <p>
 * Note: Low level methods may not behave quite as expected since some elements
 * will be generated by the backchainer and hence present in the underlying
 * {@link SPORelation}. See the notes on the various methods in the API for
 * more details.
 * 
 * @author <a href="mailto:thompsonbry@users.sourceforge.net">Bryan Thompson</a>
 * @version $Id$
 */
public class BackchainAccessPath implements IAccessPath<ISPO> {

    protected static transient final Logger log = Logger
            .getLogger(BackchainAccessPath.class);

    protected final static boolean INFO = log.isInfoEnabled();

    protected final static boolean DEBUG = log.isDebugEnabled();

    private final static transient long NULL = IRawTripleStore.NULL;

    final private AbstractTripleStore database;
    final private IAccessPath<ISPO> accessPath;

    /**
     * 
     * @param database
     *            The database whose entailments will be backchained.
     * @param accessPath
     *            The source {@link IAccessPath}.
     */
    public BackchainAccessPath(AbstractTripleStore database,
            IAccessPath<ISPO> accessPath) {

        if (database == null)
            throw new IllegalArgumentException();

        if (accessPath == null)
            throw new IllegalArgumentException();

        this.database = database;
        
        this.accessPath = accessPath;
        
    }

    /**
     * The source {@link IAccessPath}.
     */
    final public IAccessPath<ISPO> getSource() {
        
        return accessPath;
        
    }
    
    /**
     * The {@link IIndex} for the source {@link IAccessPath}.
     */
    final public IIndex getIndex() {

        return accessPath.getIndex();
        
    }

    final public IKeyOrder<ISPO> getKeyOrder() {
        
        return accessPath.getKeyOrder();
        
    }

    final public IPredicate<ISPO> getPredicate() {
        
        return accessPath.getPredicate();
        
    }

    public boolean isEmpty() {
        
        final IChunkedIterator<ISPO> itr = iterator(1,1);
        
        try {
            
            return ! itr.hasNext();
            
        } finally {
            
            itr.close();
            
        }
        
    }

    /**
     * Visits elements in the source {@link IAccessPath} plus all entailments
     * licensed by the {@link InferenceEngine}.
     */
    public IChunkedOrderedIterator<ISPO> iterator() {
        
        return iterator(0,0);
        
    }

    /**
     * Visits elements in the source {@link IAccessPath} plus all entailments
     * licensed by the {@link InferenceEngine} as configured.
     */
    public IChunkedOrderedIterator<ISPO> iterator(int limit, int capacity) {

        if (INFO) {

            log.info(accessPath.getPredicate().toString());
            
        }
        
        final IPredicate<ISPO> predicate = accessPath.getPredicate();

        final SPO spo = new SPO(predicate);

        final InferenceEngine inf = database.getInferenceEngine();
        
        final Vocabulary vocab = database.getVocabulary();
        
        final long rdfType = vocab.get(RDF.TYPE);

        final long rdfsResource = vocab.get(RDFS.RESOURCE);
        
        final long owlSameAs = vocab.get(OWL.SAMEAS);
        
        final IChunkedOrderedIterator<ISPO> owlSameAsItr;

        if (!database.getAxioms().isOwlSameAs()) {
            
            // no owl:sameAs entailments.
            owlSameAsItr = null;
        
        } else if(inf.forwardChainOwlSameAsClosure && !inf.forwardChainOwlSameAsProperties) {
            
            if (inf.database.getAccessPath(NULL, owlSameAs, NULL).isEmpty()) {

                /*
                 * No owl:sameAs assertions in the KB, so we do not need to
                 * backchain owl:sameAs.
                 */
                
                owlSameAsItr = null;

            } else {

                owlSameAsItr = new OwlSameAsPropertiesExpandingIterator(
                        spo.s, spo.p, spo.o,
                        database, owlSameAs, accessPath.getKeyOrder());
                
            }
            
        } else {
            
            // no owl:sameAs entailments.
            owlSameAsItr = null;
            
        }
        
        /*
         * Wrap it up as a chunked iterator.
         * 
         * Note: If we are not adding any entailments then we just use the
         * source iterator directly.
         * 
         * @todo why is the filter being passed in here? Can the backchaining
         * iterators produce entailments that would violate the filter? If so,
         * then shouldn't the filter be applied by the backchainers themselves
         * so that they do not overgenerate? (This comment also applies for the
         * type resource backchainer, below).
         */

        final IElementFilter<ISPO> filter = predicate.getConstraint();
        
        IChunkedOrderedIterator<ISPO> itr = (owlSameAsItr == null//
                ? accessPath.iterator(limit, capacity) //
                : new ChunkedWrappedIterator<ISPO>(owlSameAsItr,
                        capacity == 0 ? inf.database.chunkCapacity
                                : capacity, null/* keyOrder */, filter)//
        );

        if (!inf.forwardChainRdfTypeRdfsResource) {
            
            /*
             * Backchain (x rdf:type rdfs:Resource ).
             * 
             * @todo pass the filter in here also.
             */
            
            itr = BackchainTypeResourceIterator.newInstance(//
                    itr,//
                    accessPath,//
                    database, //
                    rdfType, //
                    rdfsResource //
                    );
            
        }

        return itr;
        
    }
    
    /*
     * In progress.
    public IChunkedOrderedIterator<ISPO> iterator2(int limit, int capacity) {

        if (log.isInfoEnabled()) {

            log.info(accessPath.getPredicate().toString());
            
        }
        
        // pass the limit and capacity through to the source access path.
        final IChunkedOrderedIterator<ISPO> src = null; 
            // accessPath.iterator(limit, capacity);
        
        final IChunkedOrderedIterator<ISPO> owlSameAsItr;

        final IPredicate<ISPO> predicate = accessPath.getPredicate();

        final SPO spo = new SPO(predicate);

        if (inf.rdfsOnly) {
            
            // no owl:sameAs entailments.
            owlSameAsItr = accessPath.iterator(limit, capacity);
        
        } else if(inf.forwardChainOwlSameAsClosure && !inf.forwardChainOwlSameAsProperties) {
            
            if (inf.database.getAccessPath(NULL, inf.owlSameAs.get(), NULL)
                    .rangeCount(false/*exact*//*) == 0L) {

                /*
                 * No owl:sameAs assertions in the KB, so we do not need to
                 * backchain owl:sameAs.
                 *//*
                
                owlSameAsItr = accessPath.iterator(limit, capacity);

            } else {

                owlSameAsItr = new OwlSameAsPropertiesExpandingIterator(//
                        spo.s, spo.p, spo.o,//
                        inf.database, //
                        inf.owlSameAs.get(), accessPath.getKeyOrder());
            }
            
        } else {
            
            // no owl:sameAs entailments.
            owlSameAsItr = accessPath.iterator(limit, capacity);
            
        }
        
        /*
         * Wrap it up as a chunked iterator.
         * 
         * Note: If we are not adding any entailments then we just use the
         * source iterator directly.
         * 
         * @todo why is the filter being passed in here? Can the backchaining
         * iterators produce entailments that would violate the filter? If so,
         * then shouldn't the filter be applied by the backchainers themselves
         * so that they do not overgenerate? (This comment also applies for the
         * type resource backchainer, below).
         *//*

        final IElementFilter<ISPO> filter = predicate.getConstraint();
        
        IChunkedOrderedIterator<ISPO> itr = (owlSameAsItr instanceof OwlSameAsPropertiesExpandingIterator
                ? new ChunkedWrappedIterator<ISPO>(owlSameAsItr,
                        capacity == 0 ? inf.database.queryBufferCapacity
                                : capacity, null/* keyOrder *//*, filter)//
                : src
        );

        if (!inf.forwardChainRdfTypeRdfsResource) {
            
            /*
             * Backchain (x rdf:type rdfs:Resource ).
             * 
             * @todo pass the filter in here also.
             *//*
            
            itr = BackchainTypeResourceIterator.newInstance(//
                    itr,//
                    accessPath,//
                    inf.database, //
                    inf.rdfType.get(), //
                    inf.rdfsResource.get() //
                    );
            
        }

        return itr;
        
    }
    */

    
    /**
     * When <code>exact == false</code> this does not count the backchained
     * entailments. When <code>exact == true</code> traverses the
     * {@link #iterator()} so as to produce an exact count of the #of elements
     * that would in fact be visited, which combines those from the database
     * with those generated dynamically (NOT efficient).
     */
    public long rangeCount(boolean exact) {

        if (!exact)
            return accessPath.rangeCount(exact);

        log.warn("Will materialize statements and generate inferences");
        
        final IChunkedIterator<ISPO> itr = iterator();

        long n = 0L;

        try {

            while (itr.hasNext()) {

                itr.hasNext();

                n++;

            }

        } finally {

            itr.close();

        }

        return n;
        
    }

    /**
     * Delegated to the source {@link IAccessPath} (does not visit any
     * entailments).
     */
    public ITupleIterator<ISPO> rangeIterator() {
        
        return accessPath.rangeIterator();
        
    }

    /**
     * Delegated to the source {@link IAccessPath}.
     */
    public long removeAll() {

        return accessPath.removeAll();
        
    }
    
}
