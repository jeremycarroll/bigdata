import net.jini.jeri.BasicILFactory;
import net.jini.jeri.BasicJeriExporter;
import net.jini.jeri.tcp.TcpServerEndpoint;

import net.jini.discovery.LookupDiscovery;
import net.jini.core.discovery.LookupLocator;
import net.jini.core.entry.Entry;
import net.jini.lookup.entry.Name;
import net.jini.lookup.entry.Comment;
import net.jini.lookup.entry.Address;
import net.jini.lookup.entry.Location;
import net.jini.lookup.entry.ServiceInfo;
import net.jini.core.lookup.ServiceTemplate;

import java.io.File;
import java.net.InetSocketAddress;
import java.util.UUID;

import com.bigdata.util.NV;
import com.bigdata.journal.Options;
import com.bigdata.journal.BufferMode;
import com.bigdata.jini.lookup.entry.*;
import com.bigdata.service.IBigdataClient;
import com.bigdata.service.jini.*;
import com.bigdata.service.jini.lookup.DataServiceFilter;
import com.bigdata.service.jini.master.ServicesTemplate;
import com.bigdata.jini.start.config.*;
import com.bigdata.jini.util.ConfigMath;

import org.apache.zookeeper.ZooDefs;
import org.apache.zookeeper.data.ACL;
import org.apache.zookeeper.data.Id;

// imports for various options.
import com.bigdata.btree.IndexMetadata;
import com.bigdata.btree.keys.KeyBuilder;
import com.bigdata.rdf.sail.BigdataSail;
import com.bigdata.rdf.spo.SPORelation;
import com.bigdata.rdf.spo.SPOKeyOrder;
import com.bigdata.rdf.lexicon.LexiconRelation;
import com.bigdata.rdf.lexicon.LexiconKeyOrder;
import com.bigdata.rawstore.Bytes;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeUnit.*;

/*
 * This is a sample configuration file for a highly available Journal. A
 * version of this file must be available to each HAJournalServer in the
 * pipeline.  The pipeline depends on the stable assignment of ServiceID
 * to HAJournalServers.  A unique ServiceID must be explicitly assigned to 
 * each HAJournalServer in its configuration entry.  The ordered list of 
 * those ServiceIDs is shared by all services and defines the write 
 * replication pipeline. The first entry in the write replication pipeline
 * is the leader (aka master).  You can use UUID.randomUUID() or GenUUID
 * to create UUIDs.
 *
 * Note: The ServiceUUID Entry MUST be different for each file.  It assigns
 * a ServiceID to the service!
 */

/*
 * Globals.
 */
bigdata {

   private static fedname = "benchmark";
   
   // NanoSparqlServer (http) port.
   private static nssPort = ConfigMath.add(8090,1);
   
   // write replication pipeline port.
   private static haPort = ConfigMath.add(9090,1);
   
   // The #of services in the write pipeline.
   private static replicationFactor = 3;

   // The ServiceID for *this* service.
   private static serviceId = UUID.fromString("a6120400-d63d-40d6-8ddb-3c283d0d5e3c");
   
   // The write replication pipeline.
   private static pipeline = new UUID[] {
      UUID.fromString("3c7e7639-78bf-452c-9ca9-2960caec17dc"),
      UUID.fromString("a6120400-d63d-40d6-8ddb-3c283d0d5e3c"),
      UUID.fromString("d609dcf7-860c-40f1-bd2f-eebdce20556c"),
   };
   
   // service directory.
   private static serviceDir = new File(fedname,""+serviceId);
   
   // journal data directory.
   private static dataDir = serviceDir;

   // one federation, multicast discovery.
   //static private groups = LookupDiscovery.ALL_GROUPS;

   // unicast discovery or multiple setups, MUST specify groups.
   static private groups = new String[]{bigdata.fedname};

    /**
     * One or more unicast URIs of the form <code>jini://host/</code>
     * or <code>jini://host:port/</code> (no default).
     *
     * This MAY be an empty array if you want to use multicast
     * discovery <strong>and</strong> you have specified the groups as
     * LookupDiscovery.ALL_GROUPS (a <code>null</code>).
     */
    static private locators = new LookupLocator[] {

      // runs jini on the localhost using unicast locators.
      new LookupLocator("jini://localhost/")
   
      // runs jini on one or more hosts using unicast locators.
      //new LookupLocator("jini://"+jini1),
      //new LookupLocator("jini://"+jini2),

    };

    /**
     * A common point to set the Zookeeper client's requested
     * sessionTimeout and the jini lease timeout.  The default lease
     * renewal period for jini is 5 minutes while for zookeeper it is
     * more like 5 seconds.  This puts the two systems onto a similar
     * timeout period so that a disconnected client is more likely to
     * be noticed in roughly the same period of time for either
     * system.  A value larger than the zookeeper default helps to
     * prevent client disconnects under sustained heavy load.
     */

    // jini
    static private leaseTimeout = ConfigMath.s2ms(5); 

    // zookeeper
    static private sessionTimeout = (int)ConfigMath.s2ms(5); 

    /*
     * Configuration for default KB.
     */

    private static namespace = "kb";
    
    private static kb = new NV[] {

      /* Setup for QUADS mode without the full text index. */
       
      new NV(BigdataSail.Options.TRUTH_MAINTENANCE, "false" ),
      new NV(BigdataSail.Options.QUADS, "true"),
      new NV(BigdataSail.Options.STATEMENT_IDENTIFIERS, "false"),
      new NV(BigdataSail.Options.TEXT_INDEX, "false"),
      new NV(BigdataSail.Options.AXIOMS_CLASS,"com.bigdata.rdf.axioms.NoAxioms"),
      new NV(BigdataSail.Options.QUERY_TIME_EXPANDER, "false"),

      // Bump up the branching factor for the lexicon indices on the named kb.
      // com.bigdata.namespace.kb.lex.com.bigdata.btree.BTree.branchingFactor=400
      new NV(com.bigdata.config.Configuration.getOverrideProperty
          ( namespace + "." + LexiconRelation.NAME_LEXICON_RELATION,
            IndexMetadata.Options.BTREE_BRANCHING_FACTOR
            ), "400"),

      // Bump up the branching factor for the statement indices on the named kb.
      // com.bigdata.namespace.kb.spo.com.bigdata.btree.BTree.branchingFactor=1024
      new NV(com.bigdata.config.Configuration.getOverrideProperty
          ( namespace + "." + SPORelation.NAME_SPO_RELATION,
            IndexMetadata.Options.BTREE_BRANCHING_FACTOR
            ), "1024"),
    };

}

/*
 * Zookeeper client configuration.
 */
org.apache.zookeeper.ZooKeeper {

    /* Root znode for the federation instance. */
    zroot = "/" + bigdata.fedname;

    /* A comma separated list of host:port pairs, where the port is
     * the CLIENT port for the zookeeper server instance.
     */
    // standalone.
    servers = "localhost:2081";
    // ensemble
//  servers =   bigdata.zoo1+":2181"
//             + ","+bigdata.zoo2+":2181"
//        + ","+bigdata.zoo3+":2181"
//       ;

    /* Session timeout (optional). */
    sessionTimeout = bigdata.sessionTimeout;

    /* 
     * ACL for the zookeeper nodes created by the bigdata federation.
     *
     * Note: zookeeper ACLs are not transmitted over secure channels
     * and are placed into plain text Configuration files by the
     * ServicesManagerServer.
     */
    acl = new ACL[] {

       new ACL(ZooDefs.Perms.ALL, new Id("world", "anyone"))

    };
}

/*
 * You should not have to edit below this line.
 */

/*
 * Jini client configuration.
 * 
 * TODO Only used by ListServices.
 * TODO leaseTimeout ignored by HAJournalServer
 */
com.bigdata.service.jini.JiniClient {

    groups = bigdata.groups;

    locators = bigdata.locators;
    
    jiniOptions = new String[] {

       "net.jini.lookup.JoinManager.maxLeaseDuration="+bigdata.leaseTimeout,

    };

}

/*
 * Server configuration options.
 */
com.bigdata.journal.jini.ha.HAJournalServer {

   serviceDir = bigdata.serviceDir;

   groups = bigdata.groups;
   
   locators = bigdata.locators;

   entries = new Entry[] {
      
      new ServiceUUID(bigdata.serviceId),
      
   };

   // TODO Support this : The lease timeout for jini joins.
   // "net.jini.lookup.JoinManager.maxLeaseDuration="+bigdata.leaseTimeout
   
   // Where the service will expose its write replication listener.
   writePipelineAddr = new InetSocketAddress("localhost",bigdata.haPort);

   /*
   writePipelineAddr = new InetSocketAddress(//
                    InetAddress.getByName(//
                            NicUtil.getIpAddress("default.nic", "default",
                                    false// loopbackOk
                            )), //
                    bigdata.haPort
            );
   */   

   pipelineUUIDs = bigdata.pipeline;

   replicationFactor = bigdata.replicationFactor;

}

/*
 * Journal configuration.
 */
com.bigdata.journal.jini.ha.HAJournal {

   properties = (NV[]) ConfigMath.concat(new NV[] {
   
      new NV(Options.FILE,
         ConfigMath.getAbsolutePath(new File(bigdata.dataDir,"bigdata-ha.jnl"))),
   
      new NV(Options.BUFFER_MODE,""+BufferMode.DiskRW),

      new NV(IndexMetadata.Options.WRITE_RETENTION_QUEUE_CAPACITY,"4000"),

      new NV(IndexMetadata.Options.BTREE_BRANCHING_FACTOR,"128"),

   }, bigdata.kb);

}

/*
 * NanoSparqlServer configuration.
 */
com.bigdata.rdf.sail.webapp.NanoSparqlServer {

    namespace = bigdata.namespace;

    create = true;
    
    queryThreadPoolSize = 16;
    
    describeEachNamedGraph = true;

    port = bigdata.nssPort;
    
}
