# The root of the checked out svn source.  This assumes that you have checked
# out the trunk so that all modules were automatically checked out and are in
# direct subdirectories of the directory containing this properties file and
# the ant build.xml file.
bigdata.dir=.
# Where the generated files will be written.
# build.dir/classes  [compiled classes and misc resources for classpath]
# build.dir/docs     [generated documentation].
# build.dir/docs/api [generated javadoc].
# build.dir/lib      [bundled libraries copied here for easier deployment]
# build.dir/src      [source code copied here for releases]
build.dir=ant-build

##
# javac options
##

# debug=on|off
javac.debug=on
# debuglevel=lines,vars,source (or any combination thereof).
java.debuglevel=lines,vars,source
javac.verbose=off
#javac.target=1.6
#javac.source=1.6
javac.encoding=Cp1252

##
# Properties for installing bigdata.  Many of these properties are both by the
# 'ant install' target and also wind up substituted into the 'bigdataenv' script,
# the main bigdata 'configuration' file, and the logger configuration files.
##

# The name of the bigdata federation instance.
FED=benchmark

# Bigdata-specific directory on a shared volume accessible by all hosts in the
# cluster.
#
# Note: You can create the appropriate permissions by creating the directory
# ahead of time and doing chown to set the user and group and then chmod to give
# the group read/write permissions. 
NAS=/nas/bigdata/${FED}

# Bigdata-specific directory on a local volume.  Each host in the cluster will
# place the persistent state for the bigdata services running on that host within
# this directory.  The user which will execute bigdata MUST be able to read/write
# files on this path on each host.  Therefore, if you are not installing as root
# this will need to be a file within the user's home directory or some directory
# which exists on each host and is writable by that user.
LAS=/var/bigdata/${FED}
#LAS=~/bigdata/${FED}

# The location of the installed JDK that will be used to build / run bigdata.
#JAVA_HOME=C:\\Program Files\\Java\\jdk1.6.0_10
JAVA_HOME=/usr/java/jdk1.6.0_07
#JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64
#JAVA_HOME=/usr/java/jrockit-R27.3.0-jdk1.6.0_01

# The port on which the jini class server will be running.  This class server
# is started on whichever host(s) are configured to run jini.  It is part of
# the set of jini core services which includes reggie, etc.  It is NOT setup
# to expose any classes except those found in the JARs of the jini/lib-dl
# directory. 
JINI_CLASS_SERVER_PORT=8081

# The port on which the load balancer expose an httpd service which makes
# available the aggregated performance counters, events, and index dumps.
LOAD_BALANCER_PORT=8080

# Where the sysstat utilities are found (performance counter reporting for un*x).
#SYSSTAT_HOME=/usr/local/bin
SYSSTAT_HOME=/usr/bin

# Specifies the value of com.sun.jini.jeri.tcp.useNIO.  When true, use NIO for RMI. 
USE_NIO=true

# Where to install the scripts (must by readable by all hosts).
install.bin.dir=${NAS}/bin

# Where to install the documentation.
install.doc.dir=${NAS}/doc

# Where to install the JARs (must be readable by all hosts).
install.lib.dir=${NAS}/lib

# Where to install the configuration files (must be readable by all hosts).
install.config.dir=${NAS}/config

# Where to write the log files.
install.log.dir=${NAS}/log

# The 'install-as' user (defaults to the user running the installer).
#
# @TODO ant lacks sufficient mechanisms to set the user (chown).
# 
# @TODO should this be used to specify the user in the jini service config files? 
install.user=${user.name}

# The group on all hosts that is able to read the scripts, write log files, etc.
# This can be 'users' when trying to share across the hosts when running bigdata
# using a normal user login.  It can be 'wheel' when trying to share across hosts
# using a root login. 
install.group=users
#install.group=wheel

# The file permissions mask used for files that must be read/write for all hosts.
#
# Note: umask uses the following numbers for permissions: 
#
#    0 - read, write and execute
#    1 - read and write
#    2 - read and execute
#    3 - read only
#    4 - write and execute
#    5 - write only
#    6 - execute only
#    7 - no permissions
# 117 := user and group have read-write access
# 177 := user has read-write access, group and other have none.
#
# @todo not used yet - perhaps will never be used.
#
#umask.shared=117
#umask.local=177

# The bigdata subsystem lock file.  The user MUST be able to read/write this file
# on each host.  Therefore, if you are not installing as root this will need to be
# a file within the user's home directory or some directory which exists on each
# host and is writable by that user. 
LOCK_FILE=/var/lock/subsys/bigdata
#LOCK_FILE=${LAS}/lockFile

# The main bigdata configuration file.
bigdata.config=${install.config.dir}/bigdataCluster.config

# The main jini configuration file.
jini.config=${install.config.dir}/jini/startAll.config

# The policy file used to start clients and services.  The default policy
# file is completely open.
policyFile=${install.config.dir}/policy.all

# The host that will run the log4j SimpleSocketLogger and the port on which
# the logger will listen.  This gets written into the bigdata configuration
# file and the log4j.properties file such that the logger daemon will startup
# on this host and the clients and services will log onto a socket appender 
# which logs onto this host.  log4j.properties (the file used by the clients
# and services) is setup to log INFO+ onto this service.  It will also log
# ERROR+ onto the local console in case the socket logger is down.  The socket
# logger is setup in log4jServer.properties.  It logs ERROR+ onto the errorLog
# (see below), INFO+ onto the detailLog (see below), and events onto the 
# eventLog (see below).
#
# Note: java.util.logging messages DO NOT get written onto this logger -- only
# log4j messages.
# 
LOG4J_SOCKET_LOGGER_HOST = XXX
LOG4J_SOCKET_LOGGER_PORT = 4445

# The socket logger uses a DailyRollingFileAppender by default and this 
# specifies the DatePattern property which determines both when the file
# will be rolled over and the name of the rolled over log file.
# 
# Note: You are responsible for pruning old log files!
#
# roll over at midnight.
LOG4J_DATE_PATTERN='.'yyyy-MM-dd'.log'

# The log4j configuration file for the clients and services.  This is used
# to set the log4j.configuration property.
# 
# Note: This is a URL!!!
#
log4j.config=file:${install.config.dir}/log4j.properties

# The log4j configuration file for the SimpleSocketServer.
#
# Note: This is a FILE (not a URL)
#
log4jServer.config=${install.config.dir}/log4jServer.properties

# The java.util.logging configuration file.  (Jini uses java.util.logging).
#
# Note: The java.util.logging system DOES NOT use the simple socket logger.
# You have to look at the console output or otherwise configure log message
# aggregation for java.util.logging separately.
#
logging.config=${install.config.dir}/logging.properties

# Bigdata messages at ERROR or above are logged on this file.
errorLog=${install.log.dir}/error.log

# Bigdata messages at INFO or above (or as configured) are logged on this file.
detailLog=${install.log.dir}/detail.log

# Bigdata events are logged on this file. 
eventLog=${install.log.dir}/event.log

# Messages from the bigdata script are written here when it is run by cron. This
# file must be writable by all hosts.
#
# @todo are concurrent appends on this file getting lost?
stateLog=${install.log.dir}/state.log

# When cron or a similar process is used to periodically execute the 'bigdata'
# script, the script can be invoked with the name of this file and the value in
# the file will be interpreted as the goal state for the script.  The value in
# the file is initially 'status'.  It is changed to 'start' to bring up the
# bigdata federation.  This file must be readable by all hosts.  Writes may be
# restricted to a specific user.
stateFile=${NAS}/state

# Boolean option.  When true, 'bigdata stop' and 'bigdata destroy' will use
# 'killall -9 java' to provide a sure kill for ALL java processes on the host.
# Needless to say, this option does not play well with other java components
# running on the same host (at least, running as the same user on the same
# host).  This value is written into bigdataenv as an environment variable
# named "FORCE_KILL_ALL" so you can change the behavior after the install.
forceKillAll=true

##
# Properties for creating a release.
##

# Where the releases will be written.
release.dir=ant-release

# The build version.
build.ver=0.8b

# Set true to do a snapshot build.  This changes the value of ${version} to
# include the date.
snapshot=true

# Javadoc build may be disabled using this property.  The javadoc target will
# not be executed unless this property is defined (its value does not matter).
# Note: The javadoc goes quite quickly on a server class machine, but can take
# forever and then runs out of memory on a laptop.
#javadoc=
# The SCP program to use when uploading javadoc or releases.
ssh.scp=C:/Program Files/PuTTY/pscp

##
# Properties for the 'analysis' target.
##

# You MUST specify this property
analysis.dir=e:/DPP/cluster16/U100000b/run3/run3

# The directory containing the logged performance counters to be extracted for
# analysis.
analysis.counters.dir=${analysis.dir}/counters

# The directory where the extracted performance counters will be written.
analysis.out.dir=${analysis.dir}/output

##
# Properties for the "install-lubm" target (optional).
##

# Basic install directory (scripts will go into [install.bin.dir]).
install.lubm.dir=${NAS}/lubm
# Where to install the JAR.
install.lubm.lib.dir=${install.lubm.dir}/lib
# Where to install the ontology and configuration files
install.lubm.config.dir=${install.lubm.dir}/config

# Note: but sure to choose a port that is not already in use by the
# load balancer, by the jini core services class server, etc.  You
# MUST specify the same port in the java.rmi.server.codebase property
# (this is done automatically below).
LUBM_CLASS_SERVER_PORT = 8082

# The name of the host on which the class server is running.  This must
# be the host on which you run the 'ant install' target since the class
# server is configured to serve up classes from the ant-build/classes
# directory.
LUBM_CLASS_SERVER_HOSTNAME = XXX

# The java.rmi.server.codebase for lubmMaster.sh.  You can use wget to verify
# that the class server is working (once you start it using classServer.sh).
# 
# wget -o /dev/null --no-cache ${LUBM_RMI_CODEBASE_URL}edu/lehigh/swat/bench/ubt/bigdata/LubmGeneratorMaster.class
#
LUBM_RMI_CODEBASE_URL = http://${LUBM_CLASS_SERVER_HOSTNAME}:${LUBM_CLASS_SERVER_PORT}/

# The LUBM configuration files and the ontology can be found on the installed system.
LUBM_ONTOLOGY_DIR=$NAS/lubm