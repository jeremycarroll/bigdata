<html>
<head>
<title>BigData</title>
</head>
<body>
<!-- 

Priority list:

User Application layer

x. workflow process for semantic merging
x. XML view of GOM for RESTful navigation

Database Application layer

x. Outrageous RDF(S) performance with quad store
x. full text indexing (lucene integration and generic property indexing).
x. xpath indexing (formulas that use xpath to index into generic properties)
x. Job scripting model
x. Job scheduler
x. C# bindings for GOM and extser packages.

GOM layer

x. clustered indices
x. multiple schema
x. high concurrency using state-based validation and merge rules
x. optimized data record
x. synchronization option for native transactions
x. correlated link sets? (free when using clustered indices)

Message layer

x. distributed transactions with batched async updates.

Distributed database layer

x. network protocol
x. load monitoring instrumentation
x. segment assignment protocol for load balancing
x. specification of load balancing policies
x. update buffering and routing (writes chain through replicas).
x. robustness under failures  
x. 3-phase commit.
x. co-existence with other applications
x. grid enabled, rock-n-roll.

Store layer

x. journal (persistent object buffer)
x. object index integrated with journal.
x. rw store (clustered data access)
x. btree support (from jdbm)
x. migration from journal to rw store
x.   when migration is allowable
x.   history retention support (retention in data record)
x. full isolation support 

Hardware layer

x. test server platform

@see http://www.javaperformancetuning.com/tips/patterns.shtml,
     http://www.ddj.com/184405016 (prototypes in Java)

@todo Segment size and scaling strategy.  Use a write through object
journal to buffer writes since random updates on a read-write DB are
to expensive.  Use lots of small segments to manage load and reduce
the scale problems associated with any single segment.  Depending on
the access pattern, either scan from disk or wire the segment into
memory on a host.  Cluster data judiciously so that not all segments
are required all the time.  Write large objects, e.g., video streams,
through directly into the file system or into specially provisioned
segments with a large page size and without an object buffer.  Large
objects segments are never wired into memory since repeat reads are
rare and they are too big to move around all the time.  Instead, large
objects are read directly from disk and large object reads are not
cached (but index structures for the DB SHOULD be cached).

In a way, this greatly simplifies the design since we can use RAM for
hot segments and we can avoid the scale up problems that we have seen
with very large segments (having to do with the cost of managing the
object index).  This does, of course, presume a distributed database
architecture and load balancing.

With this approach, we can use the object index mechanisms that Martyn
has been using to provide full transactional isolation.  If we wire
segments into RAM, then data locality does not matter, but it would be
a good idea to make the RW store have good locality (clustering) so
that the system can degrade smoothly if there is not enough RAM for
the access patterns.  This suggests that we still need a new RW store
design, but that we could go a long way by buffering writes with a
journal and wiring the RW store into RAM.

So, there are still issues to solve with RW store design and with
mechanisms to release historical object states that can no longer be
read by any current transaction.

@todo Clustered indices.  A clustered index is where the rows are
organized on disk according to some key found in or computed for each
row.  Clustered indices provides maximum read rates when scanning data
in key order and they can be used to effectively pre-fetch rows when a
known key range is being scanned.  Unfortunately clustered indices are
at odds with object identifiers (OIDs) since the object identity must
be the basis for referencing (and dereferencing) objects.  This means
that we must generalize the notion of object identity.  I am thinking
of allowing two kinds of OIDs: the existing 64-bit long integers and
{index,byte[]} tuples.  The byte[] can probably be generalized as a
(possibly computed) simple Java object for which tuned serialization
has ideally been specified.  The key could be a property or a computed
property.  Either the properties that go into the key are implictly
'final' or the data model must accomodate identity change for such
objects.  The index would include a comparator function and probably
should use strongly typed keys.  Locating an object by key then
requires dereferencing the index (using its 64-bit long OID), locating
the index node containing that key, and finally locating the object
within that index node.  The most obvious kind of index is a btree,
but really other data structures (persistent hash maps, rtrees, etc.)
are also viable.  Depending on the kind of index used objects within
the index may have some navigation options in terms of the index
topology.  Again, the most obvious is the prior or next object in a
btree.  A hash map might not define any local navigation options.  An
rtree could define options for scanning spatial neighbors.  When
object identity is based on an index, the API should share some
abstractions across the set of members in an index and a link set.
This abstraction would facilitate navigation but also make it possible
to maintain secondary indices on objects clustered by a primary
index. See [clusteredIndices.txt] for some code analysis on the scope
of changes (relatively extension).

@todo The use of expected counters on native transactions means that
concurrent threads can not operate at the native transaction level w/o
a locking mechanism.  If you want concurrency within a native
transaction then you must sync before entering the native transaction
and join on commit/rollback.

@todo Latency and transience.  I think that we need to capture two
additional pieces of metadata for link sets, perhaps on a per-link set
basis as well as on a per property class that is used to create that
link set.  One is latency. This is clearly an important tradeoff for
bigdata as low latency means more hosts are required.  The other is
whether the link set is transient or not - right now GOM lacks a means
to declare that something is the GOM equivalent of a temporary table.
Different SQL implementations actually have different sense of
temporary tables: generally they are memory resident (latency) but can
spill over to disk; also, some in some models the table is scoped by
the Connection to the database, not by the transaction.  This last is
quite useful for building up complex results.  However, a temporary
table with a longer lived lease is extremely good for caching things
such as search results.  In the past I have explicitly managed
relational tables with a lease for this purpose.  

  Generic objects are often interlinked.  It can easily occur that one
  end of the link is transient data and the other end is persistent
  data.  We need to manage that situation efficiently, e.g., by never
  storing the link to transient data in a persistent object.  This
  might imply that supporting transient data in GOM requires a
  parallel generic data record for transient data.  On the other hand,
  very large scale transient data can not be handled that way.  It
  needs to use the same persistence mechanisms.  At the same time,
  applications need a mechanism for decoupling large scale transient
  data from persistent data.  One such mechanism is to reference by
  value rather than identity, e.g., the transient data is like a table
  with foreign keys.  Another is to simply forsake referential
  integrity for the transient data and only store the link targets,
  but not thread the link sets within the persistent data (or move the
  threading information local to the transient data so that it can be
  easily deleted with the transient data).

@todo Work out an efficient data structure for maintaining full text
indices (inverted term indices), ideally for use with a lucene
integration.

@todo Add interface that can be used to customize merge rules for
objects when they are determined to be identical in their identifying
attributes, e.g., they have the same key in a clustered index.

@todo Rename interfaces IOI (object identifier), IOM (object manager),
IPO (persistent object), IGPO (generic persistent object).

@todo Rename packages into com.bigdata.gom?

@todo Run with BCE skins created on access and update property
versions using timestamps (bitcoding distinct timestamps like OIDs).
This lets us know which fields have been changed so that we can create
diffs on write.

@todo Client cache update policies.  A distributed database
architecture where there are large numbers of clients can benefit from
a row-based cache update policy in which clients send or receieve
patches to pages in their cache.  However, a system like bigtable uses
a different approach in that all operations occur local to the data,
and in fact there is only one host running any given segment.  Under
this model there is no requirement for row-based cache updates since
there are no remote clients of the data.  bigdata probably still
requires row-based updates in order to support clients that are not
mapping behaviors across data, but using the more general GOM
mechanisms.  However, it might be possible to distribute the
transaction across the hosts such that the GOM model executed in a
distributed environment - and always close to the data.  The tradeoffs
here demand more careful thinking as the ability to run at a remove
from the data goes hand in hand with higher costs while the
requirement to run only close to the data is clearly more efficient,
if more restricted.

@todo Correlated link sets.  One thing that bigtable attempts to do is
to gain the advantages of a column store (ala the recent C-Store by
Stonebreaker et al).  My hypothesis is that their column families
allow them to define data structures that can be mapped onto different
storage segments, providing fast access to specific subsets of the
data.

I have a notion that the same advantage can be captured in GOM using
"correlated link sets".  In the simplest case, a correlated link set
would impose a one-to-one constraint between members of two link sets
and would order their data on pages of "share-nothing" segments in a
correlated order.  This would provide for very rapid scan of any of
the correlated link sets, or very rapid parallel scan of all mutually
correlated link sets.  (There may or may not be a requirement for a
variant for blobs.)

From an object model perspective, this is saying that we have two
objects with a one-to-one correspondence.  Rather than combining their
properties into a single object, we maintain a link between the
objects and each object has only its portion of the properties.  We
then add a declaration to the link property, indicating both a 1:1
constraint and that the link sets should be correlated.  This is used
to inform the storage layer, which allocates the objects onto
correlated page sequences for fast scans.

GOM would also support an alternative where a single object is
validated against multiple schemas, in which case all properties are
stored on the single object.

Google is also providing history retention policies (last N version or
all versions in the last M units of time) and access control policies
on a per column family basis.  Without commenting on access control
policies, I think that history retention is most easily treated on a
per object basis, which could be a good reason to divide an object
into correlated link sets if you wanted different history policies for
different parts of the schema.

It is clear that we could handle history with the object journal and
an object index into the journal so that objects were expunged from
the journal once their history policy had been exceeded and only one
version, probably the most recent version, of the object was migrated
onto the database.  However, this could result in very large object
journals.  An alternative is to move the object version information
into the serialized state or the on page slot map.  The allocator for
slots on the page would have to be aware of the history policy in
order to leave enough room on the page for historical versions to
accumulate without strong likelihood of overflowing onto continuation
pages.

Most literature that I see on distributed databases uses relatively
small segments, perhaps because they can be wired into memory on a
server, much like I expect that Google does with a tablet.  If we hold
this assumption, then some of the design issues for scale change since
scale is achieved through having more segments, each of which is
smaller.

Finally, Google appears quite concerned with helping programmers to
have good intuition for locality.  They use the primary key index for
a table to organize rows so that they have good locality with respect
to the key.  This is a bit hard to do in GOM since we have object
identifiers, not primary keys, but this is definitely something that I
want to think about more.

@todo Below is a somewhat rambling summary of some points from the
conversation with MartynC.  It outlines an approach to support
federated query at scale in the bigdata architecture.  Based on
discussions with MartynC and MikeP, it appears that higher write rates
can be achieved using an append-only object journal to buffer writes,
that high read rates are maintained using an update in place database,
and that very large federated graphs are supported using state-based
validation techniques to provide very high concurrency with
compensating actions during the commit.  MartynC and I are still
working through the details to support full-transactional isolation
with this model.  The object journal uses an object index to provide a
consistent view (full isolation) of the database per transaction, but
we need to work through the policy that will permit efficient
migration from the object journal to the update-in-place database.

The notion is to use object journal for very fast writes and an OID
translation tree for indexing into the journal.  An index hit is the
most current consistent state of the object in the journal.  An index
miss means that the object is in the database, which is organized for
read performance, especially with row or link set scans.  The index is
wired into memory and reloaded on restart.  The journal retains
historical states of objects while they are required by concurrent
transactions (or notionally by a declared history retention policy).
Journal slots that are no longer required are marked as inactive.  The
journal is logically append only and writes are buffered for maximum
IO performance.  The actual implementation may be a ring buffer on
disk (ala dbCache) or a wandering journal (aka ReiserFS).

The index can be used to read the journal in a historically consistent
state, which is how CTC supports fully isolated transactions (never
overwrite data while the database is running and use the object index
to thread a consistent view of the persistent state).  However, I
think that we need to blend in some MVCC semantics so that objects may
be updated (in place) on the database and deleted on the journal.

Updates on the database may require installation reads.  Depending on
the load balancing policy, the segment may be wired into memory, in
which case installation reads are not an issue.  Installation reads
are most likely to be an issue when there are large numbers of clients
reading through a large amount of data from multiple segments on the
same machine.  In this case the system is essentially overburdened and
must read the page from the database before writing the melded back
back on the database.  However, installation reads can also be
required when a large number of objects are written on the journal
before updating the database.  This situation arises because we want
to minimize the #of random IOs, so we would like to maximize the #of
objects that we migrate from the journal to a given page of the
database at a time.  When there are only a few objects in the journal
to update on a given page, the update may be deferred to minimize IOs.

Very large graph models, e.g., RDFS databases, would be supported
using state-based validation for very high concurrency.  There are a
few cases that need to be treated.  One is index race conditions.
This occurs both when inserting a lexical form into an index to map it
to the corresponding persistent object, e.g., a URI or Literal.  This
also occurs when inserting statements into the store.  In either case
it is possible for concurrency (either within or across transactions)
to result in violations of uniqueness constraints.  E.g., there can
only be one object for a given URI and there can be only one object
for a given SPO or SPOC.  These violations will be treated by melding
the objects during the transaction commit.  One object will be choosen
as the survivor and duplicate objects will be melded.  Melding
requires that we chase references to melded objects, updating those
references to point at the survivor.  This is easy to do for the GOM
since back-references are maintained for all forward references (this
is the principle behind the link set).

The second place in which state-based validation is required is the
link set membership (head, tail, and size).  This is already supported
in the CTC GOM.  However, there may be advantages (higher concurrency)
to supporting data-type specific state-based validation rules for
generic objects based on their declared class.


@todo Consider use of custom data structures for very high performance
on specialized data models, e.g., quads/quints or inverted term
indices (e.g., lucene).  Investigate whether the proposed storage /
oid model is ammenable to such data structures and how they can be
made to interoperate with the standard storage model - perhaps by
making the choice of how to interpret and manage the data on a per
segment basis?  Consider whether such high performance data structures
loose out over the long term to more generalized mechanisms with their
flexible ad-hoc data models and query mechanisms.  Finally, consider
very large (multi-segment) consistent data structures as an
alternative to segmenting data on load and federating on query.

@todo Support automagic smart data partitioning.  E.g., allocating by
segment for a very large link sets and supporting "DROP" semantics by
facoring dependencies into the object collecting the link set.  Sets
may span segments, so "consistent" add/remove semantics require a
special handling for non-local updates to the object collecting the
link set.

@todo talk about tradeoffs that can be made with respect to QOS.
E.g., concurrent reads can be distributed across replications of a
segment to obtain very high IO rates - higher than are possible with a
single machine.  Replicated segments can also serve concurrent readers
by timesharing the replicated segments across the readers.  Look at
QOS paper and see how it trades off these dimensions.

@todo Provide a security feature for operations on a segment and
provide for partitioning a database where the segments in each
partition allow different principles.  This provides a means to share
the resources of a cluster across customers in a data 2.0 service.
Each partition is secured and the customers must be unable to sniff
packets for the page server protocol from their filters (code running
on the page server hosts).  Customer threads need resource management
to avoid malicious consumption of resources.  This is a degenerate
case of the broader concern of job scheduling.  Data 2.0 can be
delivered as a high performance media and streaming media service
(streaming media requires special cache logic since the most recently
read page typically will not be re-read), as GOM (custom computing
service vs utility computing?), as relational data (with SQL+ language
with extensions for GOM), as a federated RDFS database, or as a web
cache capable of handling a network blitze (requires massive RAM cache
ala squid).

@todo Examine the literature on the use of bitmaps for free space or
other purposes.  This could play a role in a persistent object journal
(vs the page journal used by dbCache).  Note that the BFIM for append
operations on the store do not need to be logged, since they are
logically non-existent, if a reversable trace of their allocation is
made.

@todo Examine a policy using translation pages in which they are
allocated in blocks (e.g. 20 pages at a time) and loaded into memory
when the store is opened or incrementally as a translation page in
each block is accessed.  The point is to explore the design tradeoffs
between an on page slot map and the use of translation pages.  The on
page slot map is clearly more efficient when records do not grow over
time, but might degrade performance if frequently used records were
migrated onto overflow pages.  If the translation pages fit nicely
into cache for a store (test in worksheet) then there is really no
performance cost for their use.  This design choice also interacts
with the choice of whether or not to update records in place vs
creating MROW semantics by never overwriting committed data during a
transaction.  The latter requires a means to provide different oid
resolution for the last committed state of the store and all
transactions begun from that state.  A record update by a transaction
must be installed onto a different slot and the translation from oid
to slot must be scoped to the transaction.  If we accept that we will
hold a hash map for each _pre-existing_ record _updated_ by a
transaction having MROW semantics, then we can use that map to resolve
the oids of updated records to their new locations.  Very long running
transactions that are inserting new records do not pose an overhead
since new records are installed whereever we like and updated in place
or moved around as space constraints require.  The only case that
would impose a significant memory burden is updating large numbers of
pre-existing records.  E.g., a row scan in which we compute x++.  In
this case, disabling MROW semantics might be an option.  Readers would
be forced to accept dirty reads to operate concurrently in a segment
locked by a non-MROW writer.

@todo migrating between versions or from other stores requires the
ability to accept arbitrary logical oids, either with or without
translation to new logical oids in the target store.  migration with
oid translation is must be done at the application layer since records
are opaque (well, unless you use extser, store all pointers in a
designated part of the record ala Texas, etc).  migration without
translation may not be possible since logical oids may be assigned
using incompatible schemes.  For example, if logical oids are assigned
one up then you can not import them into a store in which they are
assigned based on the segment and page# in which the record is stored.
In fact, logical oid translation at the application layer during
migration may be the only valid approach when migrating to a
distributed database since the source oids will never be legal for the
distributed database.

@todo consider per-segment consistent data structures that could be
used to achieve MROW semantics.  The necessary trick is that updates
either move the records they replace or are never written into the
same location as the records that they replace.  CTC does this on a
record level, but other stores do this on a page level.  Update in
place is required to maintain clustering while moving the data results
in twice as much IO. dbCache allows MROW until a transaction becomes
very long lived, at which point the before images from the DB are
stored in the log.  Supporting MROW concurrent with very long
transactions either requires logging AFIMs or using a translation map
for the log so that BFIM pages can be located.

@todo Compute the tree depth for per row and per page logical to
physical translation maps and compare with expectations of #s of rows
and segment size for bigdata.  This sort of scheme can support MROW
semantics, but it may cost too much for translation for large #s of
objects or pages.

@todo The page cache needs to be scan resistant so that linear scans
of pages do not cause the page cache to be flushed. See
http://linux-mm.org/MemoryHierarchy and
http://linux-mm.org/AdvancedPageReplacement

@todo update to define handling for long records.  there are two options:
(1) force people to explicitly define data structures that can scale over
more than one page, e.g., by managing head/tail/count distributed lists,
jump tables, etc.  (2) support chaining of long records. 

jdbm appears to handle this by flowing long records over a page boundaries.
I believe that the jdbm record allocator is constrained so that at most one
long record starts on a given data page and that page.next is always the
continuation of the record starting at the first offset after the page header.
I think that a starting record on page offset of zero is used to flag that
condition, but I am not clear what happens if subsequent records are then
allocated on the overflow page.  I am assuming that the record growth strategy
is such that a record that grows long is forced (by updating its translation
table entry) to an allocation on a new page.  All of this needs to be better
documented in jdbm and some row scanners need to be written.

@todo talk about index support.  the basic access path will be btrees that
support concurrent traversal and modification (b-link trees).  the indices
need to support smart allocation strategies to distribute the data over and
within segments and to cluster nodes and values with nodes.  key range scans
can read ahead, optionally resolving values.  read ahead with concurrent 
modification is the trickest case.  the jdbm btree support can be reused for
this with b-link modifications and suitable feature adds.  persistent hash
tables are a secondary feature.

@todo talk about distributed client cache.  this provides a massive RAM
cache that also reduces server burdens.  discuss two forms of a page: the
page image and the slot map view.  the latter allows us to send only the
rows of interest to a client, e.g., from a filtered row scan, do to cache
updates on the row level, etc.

@todo talk about clustering and effect of clustering index nodes with the
indexed values (clustered index).

@todo review decision for connecting to a host vs a segment in light of
UDP vs TCP performance and write all available requirement.  Do more 
benchmarks here to identify a scalable design.  If we connect to a host
then the host needs to map requests onto the segment and redirect if the
segment is not available (either because it is not on the host or because
it has been temporarily shed for load balancing purposes).  A segment that
has been shed temporarily should NOT be closed on the host since writes will
still have to write through.  The page cache should be per host not per
segment so that we get the maximum benefit of the servers memory focused on
the hot segments.

@todo review decision for page oriented vs row oriented protocol.  The main
drawback of the row oriented protocol is that it requires more features to
support a store, e.g., named roots per segment, and that object insertion
rates may be dragged down unless they can be performed locally (which should
be possible).  A row view of page images could be supported as well using
Buffer views, but the client will have to be knowledgable about handling of
long rows.

@todo handle parallelism in link sets using a two level data
structure.  A link set of segments in which there are link sets local
to that segment.  The segment-local link sets can be scanned
concurrently.  For even higher concurrent each segment-local link set
could be split either in half and scanned front to back and back to
front on different copies of the same segment or split by a table of
jump points into the middle of the link set (generalizing from head +
tail to N+2 entries, or simply increase N by one for every M link set
members).  E.g., if there are 10k link set members, and M is 1k, then
the jump table would have 1(head)+10 places from which concurrent
foward scans could be started Concurrent modification of link sets
with generalized jump tables will require more sophistication in the
iterators and some of the entries may have more than M entries.  In
fact, we probably need to track the #of entries in each part of the
jump table with head/tail/count so that we can easily rebalance the
jump table whether or not it is ordered.

An alternative data structure that may be worth exploring is skip
lists.  Skip lists provide an ordered linked list data structure with
more opportunities for concurrency and parallel scans (high IO
concurrency).  Skip lists might be a viable alternative to btrees for
some applications, e.g., the SPO index for an RDF graph.

An simpler approach would use Page, Segment and Partition layers above
the normal doubly linked list.  The segment layer is the obvious win
and enables concurrent scans over multiple segments, which implies
multiple hosts with redundent segments.  While the parition layer
might enable faster branchout of the scan and the page layer might
enable more concurrent within a segment, those layers are less obvious
wins.

 -->

<p>Welcome to BigData. BigData is a scalable persistence platform for
Data 2.0 applications. It provides high availability and hot backup on
commodity hardware. BigData uses jini for service discovery,
non-blocking I/O and client cache sharing for performance, and
replication for high availability and hot backup. If things get too hot,
segments are tranparently replicated and the load is redistributed. If a
server goes down, your data stays up. If you need more capacity, just
add more hardware.</p>
<p>BigData provides a single coherent view with ACID semantics for a
distributed database. Locking is performed at a coarse grained level
(the segment) to minimize the overhead of distributed concurrency
control. A Read One Write All Available (ROWAA) strategy provides higher
availability than quorum-based models and should out-perform
quorum-based models unless the update rate is 80-90% of all
transactions. BigData provides a 64-bit address space and can scale to
thousands of machines and petabytes of data.</p>
<p>BigData operates at several granularities. They are:
<dl>
	<dt>partition</dt>
	<dd>A namespace for segments. Partitions may be used for a variety of
	purposes but they have no intrinsic semantics. There may be 65535
	partitions in a database.</dd>
	<dt>segment</dt>
	<dd>A random access channel containing up to 65535 pages and supporting
	atomic state change using a two phase commit protocol.</dd>
	<dt>page</dt>
	<dd>A block of data. Page size may vary by segment up to 65535 bytes.
	All pages in the same segment (and in all copies of that segment) have
	the same page size.</dd>
	<dt>slot</dt>
	<dd>A row identifier on a page. A page may have up to 65535 slots. The
	page is divided into a slot map and rows. The slot map is dense, is
	maintained by an insertion sort, and is allocated from the top down. A
	slot maps a slot identifer to a row offset or optionally to a slot on
	another page. The rows are dense and are allocated from the bottom
	(offset zero) up. There are many possible orderings of rows on a page
	and all such orderings are <i>consistent</i>. <br>
	A slot may redirect to another page, but redirections may not be
	chained. Redirection is a technique to handle overflow when the rows on
	a page grow beyond the space available on the page. When a row is on
	the same page, it may be read in a single operation. When the slot is
	redirected, an additional I/O is required. A request for a slot that
	has been redirected will trigger prefetch of the page containing the
	row. Prefetched pages may be piggybacked with requested pages or arrive
	asynchronously.<br>
	A slot counter is maintained as part of the slot map. When a new slot
	is required, the value of the counter provides the new slot identifer
	and the counter is incremented. A check is made to verify that the
	identified slot is not defined in the slot map. If it is, then the
	counter is read again and incremented and the check is repeated until
	an available slot is identified. The counter will eventually overflow
	and be reset to zero. Depending on the requirements of the application,
	deleted slots may be left in the slot map and marked as deleted. This
	has minimal storage impact on the page and makes it possible to
	differentiate between a slot which was never created, one that exists,
	and one that has been deleted.<br>
	A segment maintains page lists based on the amount of space free on the
	page. A page with no data is handled just like a page with only 100
	bytes of free space. In each case the page shows up on the appropriate
	free list. Allocators pop off the first page from the free list that
	provides the best fit for an allocation request. After the allocation
	request the page is placed onto the appropriate free list based on the
	remaining free space on the page. One of the free lists contains pages
	that are filled within a minimum allocation threshold and the allocator
	never attempts to place new allocation requests on those pages.</dd>
</dl>
These distinctions are directly captured by the object identifier, which
is a 64-bit unsigned long integer. The 64-bit long integer is divided
into four 16-bit unsigned integer components corresponding to the
Partition, the Segment, the Page, and the Slot. Object identifers may be
written as a dotted quad much like IP addresses, e.g., 12.99.3.18. The
long value zero (0) is reserved to indicate a null reference and is
never a legal object identifier.
</p>
<!-- Consider having the client connect to the host instead and the host
(de)mux for the segments on that host.  This is fewer sockets and allows
reuse of server cache for the active segments. -->
<p>Clients communicate directly with segment servers. A segment server
uses non-blocking I/O to provide high throughput and handle large
numbers of concurrent connections. Clients locate segment servers using
the catalog. Segment servers report statistics to a load balancer. If
the load grows too heavy for a server, the server will temporarily shed
clients for less hot segments and focus its resources on requests for
the hotter segments. Clients that are redirected can query the load
balancer for another copy of the segment. (This applies to reads only.
BigData writes all available copies of a segement.) From time to time a
server may shed a segment entirely. If there is sufficient redundency
the copy of the segment is simply deleted. Otherwise it is first
replicated on another server.</p>
<!-- elaborate on passing the transaction context among clients. -->
<!-- elaborate on map/reduce (filtered scan) and relation to tx, clients,
and sending rows rather than pages. -->
<p>Clients are responsible for obtaining locks from the lock server. A
client must provide a lock when connecting to a segment server. Segment
servers allow write operations iff the client connects with a write lock
or upgrades to a write lock after connecting. The lock server handles
deadlock detection and can abort a transactions whose lock requests
conflict with existing locks by other transactions.</p>
<p>A BigData client that registers as a jini server can particpate in a
distributed caching protocol. Distributed caching leverages RAM in
clients to reduce server load and disk I/O. If a page is available in
RAM in another BigData client, then the page is fetched over the network
rather than reading it from disk on a server. Distributed page caching
makes it possible to reduce the page cache on servers. Without
distributed page cache the number of live pages requested by clients can
quickly defeat server page caches and lead to disk thrashing.</p>
<p>Applications may be written directly over BigData. A BigData client
is implemented for Java, but the page server protocol can be implemented
for other languages as well. Higher level APIs are available from the
following sources:
<dl>
	<dt><a href="http://www.sourceforge.net/projects/jdbm"> jdbm </a></dt>
	<dd>jdbm provides a simple API for serializing Java objects and
	supports persistent b+trees and hash tables. jdbm treats Java objects
	as opaque records and applications must manage their own indices.</dd>
	<dt><a
		href="http://proto.cognitiveweb.org/projects/cweb/multiproject/cweb-generic-native/index.html">
	GOM</a></dt>
	<dd>The Generic Object Model provides a high performance data
	extensible and schema flexible object oriented framework. Applications
	work with <em>generic data objects</em>. A generic object may have any
	number of attributes, and each attribute may have any data type.
	Generic objects may be collected in scalable collections known as link
	sets and indices may be registered over attributes or computed formulas
	for collection members. Constraints may be imposed on property clases
	or collections.</dd>
</dl>
</p>
<p>
<dl>
	<dt><b>Version: </b></dt>
	<dd>$Id$</dd>
	<dt><b>Author: </b></dt>
	<dd><a href="mailto:thompsonbry@users.sourceforce.net">Bryan Thompson</a></dd>
</dl>
</p>
</body>
</html>
